{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:06:02.100169Z",
     "start_time": "2024-05-22T18:05:59.547989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import random"
   ],
   "id": "b10883462b527219",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load dataset",
   "id": "341e1487ebb71811"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:33:56.736265Z",
     "start_time": "2024-05-22T21:33:56.726971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path to your dataset\n",
    "dataset_path = r'C:\\Users\\dzmit\\Downloads\\cat_faces\\Cat-faces-dataset-master'"
   ],
   "id": "3f10b3d19164ed8c",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:33:57.945825Z",
     "start_time": "2024-05-22T21:33:57.772391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((64, 64)),  # Resize all images to 64x64\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "# dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)"
   ],
   "id": "ebdc6330df45d27b",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:33:59.044967Z",
     "start_time": "2024-05-22T21:33:59.036168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DataLoader\n",
    "batch_size = 128  # Batch size"
   ],
   "id": "63731794a1fcc00",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:33:59.760836Z",
     "start_time": "2024-05-22T21:33:59.747330Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)",
   "id": "460c215c96b56ded",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:15:36.545241Z",
     "start_time": "2024-05-22T18:15:36.532243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size, ngf, output_channels_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(latent_size, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, output_channels_size, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (output_channels_size) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ],
   "id": "9cd0e609b0d9e763",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:15:39.659748Z",
     "start_time": "2024-05-22T18:15:39.642008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, output_channels_size, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (output_channels_size) x 64 x 64\n",
    "            nn.Conv2d(output_channels_size, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ],
   "id": "b4ec03cf704289bd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Latent vector",
   "id": "a09e7c8e0ab3fbd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:15:23.776586Z",
     "start_time": "2024-05-22T18:15:23.763586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_noise(size):\n",
    "    # Generate random noise directly with specified mean and std\n",
    "    center = 0\n",
    "    std = 0.2 \n",
    "    \n",
    "    return torch.normal(center, std, size=(size, latent_size, 1, 1)).to(device)"
   ],
   "id": "c40166c5f755c46f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:42:25.421456Z",
     "start_time": "2024-05-22T18:42:25.395226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def sample_spherical(npoints, ndim=3):\n",
    "    vec = np.random.randn(ndim, npoints)\n",
    "    vec /= np.linalg.norm(vec, axis=0)\n",
    "    return vec\n",
    "\n",
    "def interpolate_along_great_circle(latent_dim, num_steps, device='cpu'):\n",
    "    \"\"\"\n",
    "    Generates a series of latent vectors interpolated along a great circle in the latent space.\n",
    "    \n",
    "    Parameters:\n",
    "        latent_dim (int): Dimension of the latent space.\n",
    "        num_steps (int): Number of interpolation steps along the great circle.\n",
    "        device (str): Device to which the latent vectors will be sent ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Interpolated latent vectors shaped (num_steps, latent_dim, 1, 1).\n",
    "    \"\"\"\n",
    "    # Generate two points on the unit sphere in latent space\n",
    "    points = torch.tensor(sample_spherical(2, latent_dim), dtype=torch.float, device=device).t()\n",
    "    start, end = points[0], points[1]\n",
    "    \n",
    "    # Compute the angle between them\n",
    "    dot = torch.dot(start, end)\n",
    "    theta = torch.acos(dot)\n",
    "    \n",
    "    # Generate the steps\n",
    "    steps = torch.linspace(0, 1, num_steps, device=device)\n",
    "    sin_t = torch.sin(theta)\n",
    "    \n",
    "    # Perform the interpolation\n",
    "    latent_vectors = []\n",
    "    for step in steps:\n",
    "        alpha = torch.sin((1 - step) * theta) / sin_t\n",
    "        beta = torch.sin(step * theta) / sin_t\n",
    "        interpolated_point = alpha * start + beta * end\n",
    "        latent_vectors.append(interpolated_point.unsqueeze(0).unsqueeze(-1).unsqueeze(-1))\n",
    "    \n",
    "    # Concatenate all interpolated points\n",
    "    return torch.cat(latent_vectors, dim=0)\n"
   ],
   "id": "1bb75c552d860282",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device",
   "id": "a4e1e6a4a9dbc453"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:15:27.994526Z",
     "start_time": "2024-05-22T18:15:27.443970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if CUDA is available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ],
   "id": "a2c6b74b77c58978",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:15:28.009527Z",
     "start_time": "2024-05-22T18:15:27.996526Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "e193b77c5f2fc5b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the model",
   "id": "c06399e5245aed9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:15:30.830420Z",
     "start_time": "2024-05-22T18:15:30.819822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "latent_size = 100\n",
    "ngf = 64\n",
    "output_channels_size = 3\n",
    "ndf = 64"
   ],
   "id": "269286cf391eb06f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:34:07.292602Z",
     "start_time": "2024-05-22T21:34:07.218298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generator = Generator(latent_size, ngf, output_channels_size).to(device)\n",
    "discriminator = Discriminator(output_channels_size, ndf).to(device)"
   ],
   "id": "b2f05555c8f75738",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:15:59.058600Z",
     "start_time": "2024-05-22T18:15:50.164213Z"
    }
   },
   "cell_type": "code",
   "source": "discriminator(torch.randn(1, 3, 64, 64, device=device))",
   "id": "65d184e53af4329a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6423]]]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:46:51.399063Z",
     "start_time": "2024-05-22T18:46:51.382063Z"
    }
   },
   "cell_type": "code",
   "source": "create_noise(3).shape",
   "id": "dfb2fdc51f5a06a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:46:41.393954Z",
     "start_time": "2024-05-22T18:46:41.382710Z"
    }
   },
   "cell_type": "code",
   "source": "generator(create_noise(3)).shape",
   "id": "cb2a8da9065df6fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 64, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:46:58.948983Z",
     "start_time": "2024-05-22T18:46:58.934982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "num_steps = 10  # Number of interpolation steps\n",
    "latent_vectors = interpolate_along_great_circle(latent_size, 3, device)"
   ],
   "id": "ee5a1ce7b0fa3d69",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:46:59.357072Z",
     "start_time": "2024-05-22T18:46:59.347073Z"
    }
   },
   "cell_type": "code",
   "source": "latent_vectors.shape",
   "id": "80f2ecf15f04fc24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T18:47:00.233883Z",
     "start_time": "2024-05-22T18:47:00.224340Z"
    }
   },
   "cell_type": "code",
   "source": "generator(latent_vectors).shape",
   "id": "3b44ff3fffe3230f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 64, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimizers",
   "id": "17e57702f9cb05ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:34:11.410202Z",
     "start_time": "2024-05-22T21:34:11.405177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()"
   ],
   "id": "79e3ca6230018c26",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the checkpoint",
   "id": "f1522e71b0d8009"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T07:44:57.988013Z",
     "start_time": "2024-05-22T07:44:57.980115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# checkpoint = torch.load('GAN_cat_299.pth')\n",
    "# \n",
    "# # Assuming the generator and discriminator are already instantiated as per the saved model architecture\n",
    "# generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "# discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "# \n",
    "# # Assuming the optimizers are already instantiated with the parameters of their respective models\n",
    "# optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "# optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
    "# \n",
    "# # If you saved the epoch number, you can also load this to know where to resume training\n",
    "# epoch = checkpoint['epoch']\n"
   ],
   "id": "45b9a74ae7638170",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T07:44:58.003201Z",
     "start_time": "2024-05-22T07:44:57.993573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for param_group in optimizer_G.param_groups:\n",
    "#     param_group['lr'] *= 0.1\n",
    "# \n",
    "# for param_group in optimizer_D.param_groups:\n",
    "#     param_group['lr'] *= 0.1"
   ],
   "id": "a2ec4a4d62a148e0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotting functions",
   "id": "b8dda8fae9cd518b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T19:21:42.365703Z",
     "start_time": "2024-05-22T19:21:41.594080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def save_images(fake_images, epoch, prefix='gan', folder='generated_images', n_images=25):\n",
    "    \"\"\"\n",
    "    Saves a grid of generated images to a file.\n",
    "\n",
    "    Parameters:\n",
    "    - fake_images: Tensor of images generated by the GAN.\n",
    "    - epoch: Current epoch number, used for naming the output file.\n",
    "    - prefix: Prefix string for the filename.\n",
    "    - folder: Output directory for saving the images.\n",
    "    - n_images: Number of images to save. Default is 25.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Select the first n_images from the batch\n",
    "    images_to_save = fake_images[:n_images]\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 5, figsize=(10, 10))  # Setting up a 5x5 grid\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, img in enumerate(images_to_save):\n",
    "        img = img.to('cpu').detach().numpy()  # Convert tensor to numpy array\n",
    "        # if img.shape[0] == 3:  # If there are 3 channels (RGB)\n",
    "        img = img.transpose(1, 2, 0)  # Change from CxHxW to HxWxC\n",
    "        # else:\n",
    "        #     img = img.squeeze(0)  # If grayscale, remove channel dimension\n",
    "        \n",
    "        # Normalize image to [0, 1]\n",
    "        img = (img + 1) / 2\n",
    "        img = img.clip(0, 1)  # Ensure pixel values are within the [0, 1] range\n",
    "        \n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].axis('off')  # Hide axes to enhance visual appeal\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Construct the filename using the prefix and epoch\n",
    "    filename = f\"{prefix}_epoch_{epoch}.png\"\n",
    "    plt.savefig(os.path.join(folder, filename))\n",
    "    plt.close(fig)  # Close the plot to free memory\n",
    "\n",
    "# Example usage (assuming `fake_images` is your batch of generated images and `epoch` is your current epoch):\n",
    "# save_images(fake_images, epoch, prefix='myGAN', folder='my_images')\n"
   ],
   "id": "bf027ac48f09730b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T07:45:00.736901Z",
     "start_time": "2024-05-22T07:45:00.724902Z"
    }
   },
   "cell_type": "code",
   "source": "# generate_and_plot_images(n_images=25, epoch=200)",
   "id": "e26c9972161b12e2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Clear cache",
   "id": "bb958409548b2dab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:30:24.854369Z",
     "start_time": "2024-05-22T21:30:24.848413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import gc\n",
    "# \n",
    "# torch.cuda.empty_cache()  # Clear cache\n",
    "# gc.collect()  # Collect garbage\n",
    "# generator.to('cpu')\n",
    "# discriminator.to('cpu')\n",
    "# \n",
    "# del generator, discriminator, optimizer_G, optimizer_D"
   ],
   "id": "db4be72ff0c55575",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:34:19.250484Z",
     "start_time": "2024-05-22T21:34:19.239832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 300\n",
    "\n",
    "d_losses = []\n",
    "g_losses = []"
   ],
   "id": "11a1971908ad53d7",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T00:19:26.632802Z",
     "start_time": "2024-05-22T21:34:36.481062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'generator' and 'discriminator' are your models\n",
    "# 'optimizer_G' and 'optimizer_D' are the respective optimizers\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    try:\n",
    "        for batch_number, (real_images, _) in enumerate(dataloader):\n",
    "    \n",
    "            real_images = real_images.to(device)\n",
    "            \n",
    "            batch_size = real_images.size(0)\n",
    "            # Add tiny random noise around 0.9 for the real labels\n",
    "            noise_epsilon = 0.01  # Standard deviation of noise\n",
    "            real_labels = torch.full((batch_size,), 0.9, device=device) + torch.randn(batch_size, device=device) * noise_epsilon\n",
    "            fake_labels = torch.zeros(batch_size, device=device) + torch.randn(batch_size, device=device) * noise_epsilon\n",
    "    \n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            outputs_real = discriminator(real_images)\n",
    "            loss_real = -torch.mean(torch.log(outputs_real + 1e-8))\n",
    "            loss_real.backward()\n",
    "    \n",
    "            # noise = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "            latent_vector = interpolate_along_great_circle(latent_size, batch_size, device)\n",
    "\n",
    "            fake_images = generator(latent_vector)\n",
    "            \n",
    "            outputs_fake = discriminator(fake_images.detach())\n",
    "            loss_fake = -torch.mean(torch.log(1 - outputs_fake + 1e-8))\n",
    "            loss_fake.backward()\n",
    "            optimizer_D.step()\n",
    "    \n",
    "            # Train Generator with possible label flipping\n",
    "            optimizer_G.zero_grad()\n",
    "            # Randomly decide whether to flip labels\n",
    "            flip = np.random.rand() < 0.1  # 10% chance to flip labels\n",
    "            if flip:\n",
    "                # Train generator to produce 'fake' labeled as 'real', but use 'fake' label\n",
    "                gen_labels = fake_labels\n",
    "            else:\n",
    "                # Normal training, train generator to produce 'fake' labeled as 'real'\n",
    "                gen_labels = real_labels\n",
    "    \n",
    "            outputs_fake_for_gen = discriminator(fake_images).squeeze()\n",
    "            # print(outputs_fake_for_gen.shape, gen_labels.shape)\n",
    "            loss_G = criterion(outputs_fake_for_gen, gen_labels)\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # Logging and validation here (if applicable)\n",
    "            if (batch_number + 1) % 20 == 0:\n",
    "                d_losses.append(loss_real.item() + loss_fake.item())\n",
    "                g_losses.append(loss_G.item())\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_number + 1}/{len(dataloader)}], '\n",
    "                      f'D Loss: {loss_real.item() + loss_fake.item():.4f}, '\n",
    "                      f'G Loss: {loss_G.item():.4f}'\n",
    "                      f'; D Loss Real: {loss_real.item():.4f}, '\n",
    "                      f'; D Loss Fake: {loss_fake.item():.4f}, '\n",
    "                      )\n",
    "    \n",
    "        # if (epoch + 1) % 1 == 0:\n",
    "            # check_output(fake_images[0], epoch)\n",
    "        save_images(fake_images, epoch, prefix='gan', folder='generated_images', n_images=25)\n",
    "            \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint = {\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "                'epoch': epoch  # Optional, if you want to also save the epoch number\n",
    "            }\n",
    "            \n",
    "            torch.save(checkpoint, f'dcgan_cat_{epoch}.pth')\n",
    "            \n",
    "    except OSError:\n",
    "        print(f\"An error occurred while processing the image. Epoch: {epoch}, batch: {batch_number}\")\n",
    "        continue"
   ],
   "id": "702f6ea99ea50073",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [20/234], D Loss: 0.1642, G Loss: 5.8180; D Loss Real: 0.1574, ; D Loss Fake: 0.0068, \n",
      "Epoch [1/300], Step [40/234], D Loss: 0.0745, G Loss: 7.7050; D Loss Real: 0.0707, ; D Loss Fake: 0.0038, \n",
      "Epoch [1/300], Step [60/234], D Loss: 0.0674, G Loss: 11.1617; D Loss Real: 0.0674, ; D Loss Fake: 0.0000, \n",
      "Epoch [1/300], Step [80/234], D Loss: 2.2898, G Loss: -0.0137; D Loss Real: 0.0078, ; D Loss Fake: 2.2820, \n",
      "Epoch [1/300], Step [100/234], D Loss: 0.0629, G Loss: 11.0330; D Loss Real: 0.0629, ; D Loss Fake: 0.0000, \n",
      "Epoch [1/300], Step [120/234], D Loss: 0.4125, G Loss: 15.0104; D Loss Real: 0.4125, ; D Loss Fake: 0.0000, \n",
      "Epoch [1/300], Step [140/234], D Loss: 0.0765, G Loss: 13.3617; D Loss Real: 0.0765, ; D Loss Fake: 0.0000, \n",
      "Epoch [1/300], Step [160/234], D Loss: 0.0086, G Loss: 9.9969; D Loss Real: 0.0085, ; D Loss Fake: 0.0000, \n",
      "Epoch [1/300], Step [180/234], D Loss: 0.0519, G Loss: 5.0293; D Loss Real: 0.0266, ; D Loss Fake: 0.0253, \n",
      "Epoch [1/300], Step [200/234], D Loss: 0.0306, G Loss: 4.5571; D Loss Real: 0.0134, ; D Loss Fake: 0.0172, \n",
      "Epoch [1/300], Step [220/234], D Loss: 0.0437, G Loss: 11.4316; D Loss Real: 0.0437, ; D Loss Fake: 0.0000, \n",
      "Epoch [2/300], Step [20/234], D Loss: 0.0145, G Loss: 5.1680; D Loss Real: 0.0072, ; D Loss Fake: 0.0073, \n",
      "Epoch [2/300], Step [40/234], D Loss: 0.0341, G Loss: 5.0864; D Loss Real: 0.0091, ; D Loss Fake: 0.0249, \n",
      "Epoch [2/300], Step [60/234], D Loss: 6.6015, G Loss: 11.1623; D Loss Real: 6.6015, ; D Loss Fake: 0.0000, \n",
      "Epoch [2/300], Step [80/234], D Loss: 0.5137, G Loss: 5.4092; D Loss Real: 0.4142, ; D Loss Fake: 0.0995, \n",
      "Epoch [2/300], Step [100/234], D Loss: 0.1499, G Loss: 5.0733; D Loss Real: 0.1460, ; D Loss Fake: 0.0039, \n",
      "Epoch [2/300], Step [120/234], D Loss: 0.1296, G Loss: 4.6694; D Loss Real: 0.0751, ; D Loss Fake: 0.0544, \n",
      "Epoch [2/300], Step [140/234], D Loss: 0.5152, G Loss: 6.4542; D Loss Real: 0.0504, ; D Loss Fake: 0.4647, \n",
      "Epoch [2/300], Step [160/234], D Loss: 0.2154, G Loss: 5.0741; D Loss Real: 0.2121, ; D Loss Fake: 0.0033, \n",
      "Epoch [2/300], Step [180/234], D Loss: 0.0909, G Loss: 4.8611; D Loss Real: 0.0558, ; D Loss Fake: 0.0350, \n",
      "Epoch [2/300], Step [200/234], D Loss: 0.1530, G Loss: 6.3405; D Loss Real: 0.1518, ; D Loss Fake: 0.0012, \n",
      "Epoch [2/300], Step [220/234], D Loss: 0.3436, G Loss: 8.8630; D Loss Real: 0.3436, ; D Loss Fake: 0.0001, \n",
      "Epoch [3/300], Step [20/234], D Loss: 0.0674, G Loss: 3.9481; D Loss Real: 0.0433, ; D Loss Fake: 0.0240, \n",
      "Epoch [3/300], Step [40/234], D Loss: 0.3259, G Loss: 6.1351; D Loss Real: 0.1024, ; D Loss Fake: 0.2235, \n",
      "Epoch [3/300], Step [60/234], D Loss: 0.8612, G Loss: 7.3431; D Loss Real: 0.8609, ; D Loss Fake: 0.0003, \n",
      "Epoch [3/300], Step [80/234], D Loss: 1.1730, G Loss: 7.1664; D Loss Real: 0.0303, ; D Loss Fake: 1.1427, \n",
      "Epoch [3/300], Step [100/234], D Loss: 0.3346, G Loss: 5.2295; D Loss Real: 0.3285, ; D Loss Fake: 0.0062, \n",
      "Epoch [3/300], Step [120/234], D Loss: 0.1657, G Loss: 4.7704; D Loss Real: 0.1557, ; D Loss Fake: 0.0100, \n",
      "Epoch [3/300], Step [140/234], D Loss: 0.3850, G Loss: 6.4842; D Loss Real: 0.0517, ; D Loss Fake: 0.3333, \n",
      "Epoch [3/300], Step [160/234], D Loss: 1.1535, G Loss: 6.5896; D Loss Real: 0.0359, ; D Loss Fake: 1.1175, \n",
      "Epoch [3/300], Step [180/234], D Loss: 0.1357, G Loss: 3.2254; D Loss Real: 0.0435, ; D Loss Fake: 0.0922, \n",
      "Epoch [3/300], Step [200/234], D Loss: 0.5305, G Loss: 5.9320; D Loss Real: 0.0686, ; D Loss Fake: 0.4619, \n",
      "Epoch [3/300], Step [220/234], D Loss: 0.0669, G Loss: 0.0145; D Loss Real: 0.0416, ; D Loss Fake: 0.0253, \n",
      "Epoch [4/300], Step [20/234], D Loss: 0.7460, G Loss: 5.2731; D Loss Real: 0.7455, ; D Loss Fake: 0.0005, \n",
      "Epoch [4/300], Step [40/234], D Loss: 0.1198, G Loss: 3.3394; D Loss Real: 0.0293, ; D Loss Fake: 0.0904, \n",
      "Epoch [4/300], Step [60/234], D Loss: 0.5802, G Loss: 5.2145; D Loss Real: 0.5774, ; D Loss Fake: 0.0028, \n",
      "Epoch [4/300], Step [80/234], D Loss: 0.8639, G Loss: 4.9455; D Loss Real: 0.1860, ; D Loss Fake: 0.6779, \n",
      "Epoch [4/300], Step [100/234], D Loss: 0.1972, G Loss: 2.8295; D Loss Real: 0.1057, ; D Loss Fake: 0.0915, \n",
      "Epoch [4/300], Step [120/234], D Loss: 0.2175, G Loss: 4.6670; D Loss Real: 0.2098, ; D Loss Fake: 0.0076, \n",
      "Epoch [4/300], Step [140/234], D Loss: 0.1015, G Loss: 4.7953; D Loss Real: 0.0955, ; D Loss Fake: 0.0060, \n",
      "Epoch [4/300], Step [160/234], D Loss: 0.1042, G Loss: 3.0764; D Loss Real: 0.0363, ; D Loss Fake: 0.0678, \n",
      "Epoch [4/300], Step [180/234], D Loss: 0.2260, G Loss: 3.0390; D Loss Real: 0.1612, ; D Loss Fake: 0.0648, \n",
      "Epoch [4/300], Step [200/234], D Loss: 0.3023, G Loss: 4.2361; D Loss Real: 0.2932, ; D Loss Fake: 0.0090, \n",
      "Epoch [4/300], Step [220/234], D Loss: 0.0824, G Loss: 4.4780; D Loss Real: 0.0784, ; D Loss Fake: 0.0040, \n",
      "Epoch [5/300], Step [20/234], D Loss: 0.8743, G Loss: 5.6959; D Loss Real: 0.0662, ; D Loss Fake: 0.8081, \n",
      "Epoch [5/300], Step [40/234], D Loss: 0.5672, G Loss: -0.0002; D Loss Real: 0.1216, ; D Loss Fake: 0.4456, \n",
      "Epoch [5/300], Step [60/234], D Loss: 0.1454, G Loss: 3.6309; D Loss Real: 0.1365, ; D Loss Fake: 0.0089, \n",
      "Epoch [5/300], Step [80/234], D Loss: 0.2483, G Loss: 3.1947; D Loss Real: 0.1001, ; D Loss Fake: 0.1483, \n",
      "Epoch [5/300], Step [100/234], D Loss: 0.4176, G Loss: 4.0873; D Loss Real: 0.3910, ; D Loss Fake: 0.0265, \n",
      "Epoch [5/300], Step [120/234], D Loss: 0.6459, G Loss: 5.4207; D Loss Real: 0.0814, ; D Loss Fake: 0.5645, \n",
      "Epoch [5/300], Step [140/234], D Loss: 0.1376, G Loss: 3.6025; D Loss Real: 0.0823, ; D Loss Fake: 0.0553, \n",
      "Epoch [5/300], Step [160/234], D Loss: 0.1256, G Loss: 3.5421; D Loss Real: 0.0851, ; D Loss Fake: 0.0405, \n",
      "Epoch [5/300], Step [180/234], D Loss: 0.1172, G Loss: 3.6473; D Loss Real: 0.0554, ; D Loss Fake: 0.0619, \n",
      "Epoch [5/300], Step [200/234], D Loss: 0.2656, G Loss: 2.9627; D Loss Real: 0.0614, ; D Loss Fake: 0.2042, \n",
      "Epoch [5/300], Step [220/234], D Loss: 1.4763, G Loss: 8.6103; D Loss Real: 0.0691, ; D Loss Fake: 1.4072, \n",
      "Epoch [6/300], Step [20/234], D Loss: 0.0482, G Loss: 5.3625; D Loss Real: 0.0374, ; D Loss Fake: 0.0108, \n",
      "Epoch [6/300], Step [40/234], D Loss: 0.3598, G Loss: 0.0049; D Loss Real: 0.0689, ; D Loss Fake: 0.2909, \n",
      "Epoch [6/300], Step [60/234], D Loss: 0.2912, G Loss: 7.3516; D Loss Real: 0.2911, ; D Loss Fake: 0.0002, \n",
      "Epoch [6/300], Step [80/234], D Loss: 0.1925, G Loss: 3.6056; D Loss Real: 0.0909, ; D Loss Fake: 0.1017, \n",
      "Epoch [6/300], Step [100/234], D Loss: 0.1708, G Loss: 8.1656; D Loss Real: 0.1707, ; D Loss Fake: 0.0001, \n",
      "Epoch [6/300], Step [120/234], D Loss: 0.1405, G Loss: 3.8561; D Loss Real: 0.1170, ; D Loss Fake: 0.0235, \n",
      "Epoch [6/300], Step [140/234], D Loss: 0.4569, G Loss: 8.3469; D Loss Real: 0.4568, ; D Loss Fake: 0.0000, \n",
      "Epoch [6/300], Step [160/234], D Loss: 0.0658, G Loss: 5.1457; D Loss Real: 0.0631, ; D Loss Fake: 0.0027, \n",
      "Epoch [6/300], Step [180/234], D Loss: 0.1704, G Loss: 4.7535; D Loss Real: 0.1242, ; D Loss Fake: 0.0462, \n",
      "Epoch [6/300], Step [200/234], D Loss: 0.0760, G Loss: 0.0142; D Loss Real: 0.0513, ; D Loss Fake: 0.0247, \n",
      "Epoch [6/300], Step [220/234], D Loss: 0.7687, G Loss: 5.4560; D Loss Real: 0.0851, ; D Loss Fake: 0.6836, \n",
      "Epoch [7/300], Step [20/234], D Loss: 0.0458, G Loss: 4.0225; D Loss Real: 0.0145, ; D Loss Fake: 0.0314, \n",
      "Epoch [7/300], Step [40/234], D Loss: 0.0610, G Loss: 0.0034; D Loss Real: 0.0607, ; D Loss Fake: 0.0003, \n",
      "Epoch [7/300], Step [60/234], D Loss: 0.5591, G Loss: 7.6678; D Loss Real: 0.5591, ; D Loss Fake: 0.0000, \n",
      "Epoch [7/300], Step [80/234], D Loss: 0.0836, G Loss: 3.0766; D Loss Real: 0.0639, ; D Loss Fake: 0.0197, \n",
      "Epoch [7/300], Step [100/234], D Loss: 0.5169, G Loss: 6.9328; D Loss Real: 0.5139, ; D Loss Fake: 0.0030, \n",
      "Epoch [7/300], Step [120/234], D Loss: 0.1744, G Loss: 0.0106; D Loss Real: 0.1734, ; D Loss Fake: 0.0011, \n",
      "Epoch [7/300], Step [140/234], D Loss: 0.0589, G Loss: 3.9454; D Loss Real: 0.0263, ; D Loss Fake: 0.0326, \n",
      "Epoch [7/300], Step [160/234], D Loss: 0.0773, G Loss: 5.6526; D Loss Real: 0.0757, ; D Loss Fake: 0.0016, \n",
      "Epoch [7/300], Step [180/234], D Loss: 0.1539, G Loss: 2.1492; D Loss Real: 0.0921, ; D Loss Fake: 0.0618, \n",
      "Epoch [7/300], Step [200/234], D Loss: 0.1931, G Loss: 4.9831; D Loss Real: 0.0256, ; D Loss Fake: 0.1674, \n",
      "Epoch [7/300], Step [220/234], D Loss: 2.3991, G Loss: 6.9136; D Loss Real: 0.0404, ; D Loss Fake: 2.3587, \n",
      "Epoch [8/300], Step [20/234], D Loss: 0.4605, G Loss: 4.0667; D Loss Real: 0.0466, ; D Loss Fake: 0.4139, \n",
      "Epoch [8/300], Step [40/234], D Loss: 1.1999, G Loss: 8.4836; D Loss Real: 0.0516, ; D Loss Fake: 1.1482, \n",
      "Epoch [8/300], Step [60/234], D Loss: 0.0836, G Loss: 3.9789; D Loss Real: 0.0280, ; D Loss Fake: 0.0556, \n",
      "Epoch [8/300], Step [80/234], D Loss: 0.5294, G Loss: 5.2059; D Loss Real: 0.0418, ; D Loss Fake: 0.4876, \n",
      "Epoch [8/300], Step [100/234], D Loss: 0.8629, G Loss: 8.0606; D Loss Real: 0.8626, ; D Loss Fake: 0.0003, \n",
      "Epoch [8/300], Step [120/234], D Loss: 0.3083, G Loss: 8.4711; D Loss Real: 0.3082, ; D Loss Fake: 0.0001, \n",
      "Epoch [8/300], Step [140/234], D Loss: 0.1666, G Loss: 5.1431; D Loss Real: 0.1638, ; D Loss Fake: 0.0028, \n",
      "Epoch [8/300], Step [160/234], D Loss: 0.2196, G Loss: 4.3396; D Loss Real: 0.1751, ; D Loss Fake: 0.0445, \n",
      "Epoch [8/300], Step [180/234], D Loss: 0.2594, G Loss: 3.5941; D Loss Real: 0.1318, ; D Loss Fake: 0.1276, \n",
      "Epoch [8/300], Step [200/234], D Loss: 0.1588, G Loss: 5.7997; D Loss Real: 0.0456, ; D Loss Fake: 0.1133, \n",
      "Epoch [8/300], Step [220/234], D Loss: 0.1063, G Loss: 6.0545; D Loss Real: 0.1013, ; D Loss Fake: 0.0050, \n",
      "Epoch [9/300], Step [20/234], D Loss: 0.2275, G Loss: 5.9236; D Loss Real: 0.2232, ; D Loss Fake: 0.0043, \n",
      "Epoch [9/300], Step [40/234], D Loss: 1.1768, G Loss: 7.2748; D Loss Real: 0.0151, ; D Loss Fake: 1.1617, \n",
      "Epoch [9/300], Step [60/234], D Loss: 0.0505, G Loss: 6.9495; D Loss Real: 0.0488, ; D Loss Fake: 0.0017, \n",
      "Epoch [9/300], Step [80/234], D Loss: 0.3001, G Loss: 7.2416; D Loss Real: 0.0270, ; D Loss Fake: 0.2731, \n",
      "Epoch [9/300], Step [100/234], D Loss: 0.3755, G Loss: 5.7720; D Loss Real: 0.0264, ; D Loss Fake: 0.3491, \n",
      "Epoch [9/300], Step [120/234], D Loss: 0.9349, G Loss: 11.1629; D Loss Real: 0.0177, ; D Loss Fake: 0.9172, \n",
      "Epoch [9/300], Step [140/234], D Loss: 0.3110, G Loss: 5.2271; D Loss Real: 0.0311, ; D Loss Fake: 0.2799, \n",
      "Epoch [9/300], Step [160/234], D Loss: 0.5791, G Loss: 4.7542; D Loss Real: 0.5641, ; D Loss Fake: 0.0150, \n",
      "Epoch [9/300], Step [180/234], D Loss: 0.1720, G Loss: 4.9701; D Loss Real: 0.1613, ; D Loss Fake: 0.0107, \n",
      "Epoch [9/300], Step [200/234], D Loss: 0.2474, G Loss: 4.4677; D Loss Real: 0.0135, ; D Loss Fake: 0.2339, \n",
      "Epoch [9/300], Step [220/234], D Loss: 0.2883, G Loss: 4.6885; D Loss Real: 0.2842, ; D Loss Fake: 0.0042, \n",
      "Epoch [10/300], Step [20/234], D Loss: 0.5015, G Loss: 9.5985; D Loss Real: 0.2283, ; D Loss Fake: 0.2732, \n",
      "Epoch [10/300], Step [40/234], D Loss: 0.1422, G Loss: 4.8473; D Loss Real: 0.0372, ; D Loss Fake: 0.1050, \n",
      "Epoch [10/300], Step [60/234], D Loss: 0.1360, G Loss: 3.8547; D Loss Real: 0.0652, ; D Loss Fake: 0.0708, \n",
      "Epoch [10/300], Step [80/234], D Loss: 0.2152, G Loss: 7.0208; D Loss Real: 0.2148, ; D Loss Fake: 0.0004, \n",
      "Epoch [10/300], Step [100/234], D Loss: 0.2166, G Loss: 3.8143; D Loss Real: 0.2055, ; D Loss Fake: 0.0110, \n",
      "Epoch [10/300], Step [120/234], D Loss: 0.0129, G Loss: 5.5817; D Loss Real: 0.0070, ; D Loss Fake: 0.0059, \n",
      "Epoch [10/300], Step [140/234], D Loss: 0.9825, G Loss: 9.0869; D Loss Real: 0.1172, ; D Loss Fake: 0.8654, \n",
      "Epoch [10/300], Step [160/234], D Loss: 0.0347, G Loss: 5.8055; D Loss Real: 0.0310, ; D Loss Fake: 0.0037, \n",
      "Epoch [10/300], Step [180/234], D Loss: 0.0280, G Loss: 7.1846; D Loss Real: 0.0274, ; D Loss Fake: 0.0006, \n",
      "Epoch [10/300], Step [200/234], D Loss: 0.1121, G Loss: 3.9977; D Loss Real: 0.1035, ; D Loss Fake: 0.0086, \n",
      "Epoch [10/300], Step [220/234], D Loss: 0.2421, G Loss: 5.2515; D Loss Real: 0.0921, ; D Loss Fake: 0.1500, \n",
      "Epoch [11/300], Step [20/234], D Loss: 0.0750, G Loss: 5.4158; D Loss Real: 0.0725, ; D Loss Fake: 0.0025, \n",
      "Epoch [11/300], Step [40/234], D Loss: 0.1604, G Loss: 4.9702; D Loss Real: 0.1297, ; D Loss Fake: 0.0307, \n",
      "Epoch [11/300], Step [60/234], D Loss: 0.2464, G Loss: 5.5038; D Loss Real: 0.0302, ; D Loss Fake: 0.2162, \n",
      "Epoch [11/300], Step [80/234], D Loss: 0.0639, G Loss: 4.4982; D Loss Real: 0.0048, ; D Loss Fake: 0.0591, \n",
      "Epoch [11/300], Step [100/234], D Loss: 0.5906, G Loss: 10.3678; D Loss Real: 0.0133, ; D Loss Fake: 0.5773, \n",
      "Epoch [11/300], Step [120/234], D Loss: 0.5560, G Loss: 5.4231; D Loss Real: 0.5551, ; D Loss Fake: 0.0010, \n",
      "Epoch [11/300], Step [140/234], D Loss: 0.3627, G Loss: 5.5343; D Loss Real: 0.3626, ; D Loss Fake: 0.0001, \n",
      "Epoch [11/300], Step [160/234], D Loss: 0.0568, G Loss: 4.7990; D Loss Real: 0.0525, ; D Loss Fake: 0.0043, \n",
      "Epoch [11/300], Step [180/234], D Loss: 0.1479, G Loss: 5.3498; D Loss Real: 0.0197, ; D Loss Fake: 0.1282, \n",
      "Epoch [11/300], Step [200/234], D Loss: 0.0778, G Loss: 3.5459; D Loss Real: 0.0341, ; D Loss Fake: 0.0436, \n",
      "Epoch [11/300], Step [220/234], D Loss: 0.1460, G Loss: 6.7293; D Loss Real: 0.1437, ; D Loss Fake: 0.0023, \n",
      "Epoch [12/300], Step [20/234], D Loss: 0.2732, G Loss: 5.9469; D Loss Real: 0.2727, ; D Loss Fake: 0.0005, \n",
      "Epoch [12/300], Step [40/234], D Loss: 0.0423, G Loss: 4.7971; D Loss Real: 0.0168, ; D Loss Fake: 0.0255, \n",
      "Epoch [12/300], Step [60/234], D Loss: 0.0813, G Loss: 9.3958; D Loss Real: 0.0809, ; D Loss Fake: 0.0004, \n",
      "Epoch [12/300], Step [80/234], D Loss: 0.1128, G Loss: 5.0616; D Loss Real: 0.1080, ; D Loss Fake: 0.0048, \n",
      "Epoch [12/300], Step [100/234], D Loss: 0.0410, G Loss: 5.2970; D Loss Real: 0.0070, ; D Loss Fake: 0.0340, \n",
      "Epoch [12/300], Step [120/234], D Loss: 0.1394, G Loss: 5.2584; D Loss Real: 0.1377, ; D Loss Fake: 0.0016, \n",
      "Epoch [12/300], Step [140/234], D Loss: 0.0309, G Loss: 3.7907; D Loss Real: 0.0071, ; D Loss Fake: 0.0239, \n",
      "Epoch [12/300], Step [160/234], D Loss: 0.1048, G Loss: 4.5955; D Loss Real: 0.0879, ; D Loss Fake: 0.0168, \n",
      "Epoch [12/300], Step [180/234], D Loss: 0.6308, G Loss: 9.4600; D Loss Real: 0.6308, ; D Loss Fake: 0.0001, \n",
      "Epoch [12/300], Step [200/234], D Loss: 0.2152, G Loss: 3.8956; D Loss Real: 0.1925, ; D Loss Fake: 0.0227, \n",
      "Epoch [12/300], Step [220/234], D Loss: 0.1247, G Loss: -0.0018; D Loss Real: 0.0065, ; D Loss Fake: 0.1182, \n",
      "Epoch [13/300], Step [20/234], D Loss: 0.2291, G Loss: 0.0269; D Loss Real: 0.2237, ; D Loss Fake: 0.0055, \n",
      "Epoch [13/300], Step [40/234], D Loss: 0.0784, G Loss: 5.6938; D Loss Real: 0.0649, ; D Loss Fake: 0.0135, \n",
      "Epoch [13/300], Step [60/234], D Loss: 0.3530, G Loss: 5.9916; D Loss Real: 0.3527, ; D Loss Fake: 0.0003, \n",
      "Epoch [13/300], Step [80/234], D Loss: 1.2493, G Loss: 9.3044; D Loss Real: 0.0105, ; D Loss Fake: 1.2388, \n",
      "Epoch [13/300], Step [100/234], D Loss: 1.4021, G Loss: 7.9606; D Loss Real: 0.2548, ; D Loss Fake: 1.1473, \n",
      "Epoch [13/300], Step [120/234], D Loss: 0.2563, G Loss: 6.2033; D Loss Real: 0.0264, ; D Loss Fake: 0.2299, \n",
      "Epoch [13/300], Step [140/234], D Loss: 0.2082, G Loss: 4.0434; D Loss Real: 0.0484, ; D Loss Fake: 0.1597, \n",
      "Epoch [13/300], Step [160/234], D Loss: 0.1608, G Loss: 4.1918; D Loss Real: 0.0529, ; D Loss Fake: 0.1079, \n",
      "Epoch [13/300], Step [180/234], D Loss: 0.2632, G Loss: 2.8672; D Loss Real: 0.1757, ; D Loss Fake: 0.0875, \n",
      "Epoch [13/300], Step [200/234], D Loss: 0.2350, G Loss: 3.3204; D Loss Real: 0.1727, ; D Loss Fake: 0.0623, \n",
      "Epoch [13/300], Step [220/234], D Loss: 0.2465, G Loss: 6.5063; D Loss Real: 0.1162, ; D Loss Fake: 0.1303, \n",
      "Epoch [14/300], Step [20/234], D Loss: 0.1454, G Loss: 6.9933; D Loss Real: 0.1295, ; D Loss Fake: 0.0158, \n",
      "Epoch [14/300], Step [40/234], D Loss: 0.3277, G Loss: 7.6574; D Loss Real: 0.1438, ; D Loss Fake: 0.1839, \n",
      "Epoch [14/300], Step [60/234], D Loss: 0.0394, G Loss: 4.3055; D Loss Real: 0.0106, ; D Loss Fake: 0.0287, \n",
      "Epoch [14/300], Step [80/234], D Loss: 0.4437, G Loss: 7.9263; D Loss Real: 0.0177, ; D Loss Fake: 0.4260, \n",
      "Epoch [14/300], Step [100/234], D Loss: 0.0193, G Loss: 5.7310; D Loss Real: 0.0145, ; D Loss Fake: 0.0048, \n",
      "Epoch [14/300], Step [120/234], D Loss: 0.1658, G Loss: 4.9537; D Loss Real: 0.0658, ; D Loss Fake: 0.1000, \n",
      "Epoch [14/300], Step [140/234], D Loss: 0.4997, G Loss: 7.4056; D Loss Real: 0.0070, ; D Loss Fake: 0.4927, \n",
      "Epoch [14/300], Step [160/234], D Loss: 0.0739, G Loss: 4.8591; D Loss Real: 0.0686, ; D Loss Fake: 0.0053, \n",
      "Epoch [14/300], Step [180/234], D Loss: 0.1714, G Loss: 6.7632; D Loss Real: 0.0906, ; D Loss Fake: 0.0807, \n",
      "Epoch [14/300], Step [200/234], D Loss: 0.0368, G Loss: -0.0081; D Loss Real: 0.0367, ; D Loss Fake: 0.0001, \n",
      "Epoch [14/300], Step [220/234], D Loss: 0.0423, G Loss: 5.0980; D Loss Real: 0.0307, ; D Loss Fake: 0.0116, \n",
      "Epoch [15/300], Step [20/234], D Loss: 0.6603, G Loss: 8.1805; D Loss Real: 0.6600, ; D Loss Fake: 0.0003, \n",
      "Epoch [15/300], Step [40/234], D Loss: 0.1100, G Loss: 6.6640; D Loss Real: 0.0027, ; D Loss Fake: 0.1073, \n",
      "Epoch [15/300], Step [60/234], D Loss: 0.3261, G Loss: 6.3785; D Loss Real: 0.0072, ; D Loss Fake: 0.3189, \n",
      "Epoch [15/300], Step [80/234], D Loss: 0.4140, G Loss: 6.9541; D Loss Real: 0.0084, ; D Loss Fake: 0.4056, \n",
      "Epoch [15/300], Step [100/234], D Loss: 0.0535, G Loss: 5.7611; D Loss Real: 0.0516, ; D Loss Fake: 0.0019, \n",
      "Epoch [15/300], Step [120/234], D Loss: 0.0222, G Loss: 8.8892; D Loss Real: 0.0222, ; D Loss Fake: 0.0000, \n",
      "Epoch [15/300], Step [140/234], D Loss: 0.2528, G Loss: 0.0053; D Loss Real: 0.2522, ; D Loss Fake: 0.0006, \n",
      "Epoch [15/300], Step [160/234], D Loss: 0.0636, G Loss: 5.7705; D Loss Real: 0.0604, ; D Loss Fake: 0.0031, \n",
      "Epoch [15/300], Step [180/234], D Loss: 0.0175, G Loss: 5.2760; D Loss Real: 0.0070, ; D Loss Fake: 0.0105, \n",
      "Epoch [15/300], Step [200/234], D Loss: 0.0200, G Loss: 5.3093; D Loss Real: 0.0120, ; D Loss Fake: 0.0081, \n",
      "Epoch [15/300], Step [220/234], D Loss: 0.0215, G Loss: 5.3600; D Loss Real: 0.0110, ; D Loss Fake: 0.0105, \n",
      "Epoch [16/300], Step [20/234], D Loss: 1.2041, G Loss: 11.6602; D Loss Real: 1.2041, ; D Loss Fake: 0.0000, \n",
      "Epoch [16/300], Step [40/234], D Loss: 0.1714, G Loss: -0.0001; D Loss Real: 0.0425, ; D Loss Fake: 0.1288, \n",
      "Epoch [16/300], Step [60/234], D Loss: 0.1725, G Loss: 9.4451; D Loss Real: 0.1725, ; D Loss Fake: 0.0000, \n",
      "Epoch [16/300], Step [80/234], D Loss: 0.0267, G Loss: 9.0695; D Loss Real: 0.0266, ; D Loss Fake: 0.0000, \n",
      "Epoch [16/300], Step [100/234], D Loss: 0.0110, G Loss: 0.0024; D Loss Real: 0.0108, ; D Loss Fake: 0.0002, \n",
      "Epoch [16/300], Step [120/234], D Loss: 0.0511, G Loss: 6.7699; D Loss Real: 0.0483, ; D Loss Fake: 0.0028, \n",
      "Epoch [16/300], Step [140/234], D Loss: 0.1402, G Loss: 6.7024; D Loss Real: 0.1164, ; D Loss Fake: 0.0237, \n",
      "Epoch [16/300], Step [160/234], D Loss: 0.2509, G Loss: 6.4168; D Loss Real: 0.0200, ; D Loss Fake: 0.2309, \n",
      "Epoch [16/300], Step [180/234], D Loss: 0.0191, G Loss: 7.2433; D Loss Real: 0.0080, ; D Loss Fake: 0.0111, \n",
      "Epoch [16/300], Step [200/234], D Loss: 0.0771, G Loss: 5.8645; D Loss Real: 0.0758, ; D Loss Fake: 0.0014, \n",
      "Epoch [16/300], Step [220/234], D Loss: 0.0133, G Loss: 5.6938; D Loss Real: 0.0016, ; D Loss Fake: 0.0117, \n",
      "Epoch [17/300], Step [20/234], D Loss: 0.5655, G Loss: 10.1455; D Loss Real: 0.0415, ; D Loss Fake: 0.5240, \n",
      "Epoch [17/300], Step [40/234], D Loss: 0.0731, G Loss: 4.3406; D Loss Real: 0.0370, ; D Loss Fake: 0.0361, \n",
      "Epoch [17/300], Step [60/234], D Loss: 0.0135, G Loss: 4.9809; D Loss Real: 0.0022, ; D Loss Fake: 0.0113, \n",
      "Epoch [17/300], Step [80/234], D Loss: 0.4167, G Loss: 15.8300; D Loss Real: 0.0099, ; D Loss Fake: 0.4068, \n",
      "Epoch [17/300], Step [100/234], D Loss: 0.0064, G Loss: 7.0806; D Loss Real: 0.0060, ; D Loss Fake: 0.0004, \n",
      "Epoch [17/300], Step [120/234], D Loss: 0.0994, G Loss: 11.9246; D Loss Real: 0.0994, ; D Loss Fake: 0.0000, \n",
      "Epoch [17/300], Step [140/234], D Loss: 0.0065, G Loss: 7.1329; D Loss Real: 0.0060, ; D Loss Fake: 0.0006, \n",
      "Epoch [17/300], Step [160/234], D Loss: 0.0233, G Loss: 4.8714; D Loss Real: 0.0103, ; D Loss Fake: 0.0130, \n",
      "Epoch [17/300], Step [180/234], D Loss: 0.0634, G Loss: 5.9427; D Loss Real: 0.0140, ; D Loss Fake: 0.0495, \n",
      "Epoch [17/300], Step [200/234], D Loss: 0.0869, G Loss: 5.7405; D Loss Real: 0.0051, ; D Loss Fake: 0.0818, \n",
      "Epoch [17/300], Step [220/234], D Loss: 1.3524, G Loss: 14.9548; D Loss Real: 0.0082, ; D Loss Fake: 1.3442, \n",
      "Epoch [18/300], Step [20/234], D Loss: 0.3411, G Loss: 8.6346; D Loss Real: 0.0087, ; D Loss Fake: 0.3325, \n",
      "Epoch [18/300], Step [40/234], D Loss: 0.1623, G Loss: 5.7960; D Loss Real: 0.0287, ; D Loss Fake: 0.1337, \n",
      "Epoch [18/300], Step [60/234], D Loss: 0.1318, G Loss: 8.1320; D Loss Real: 0.0177, ; D Loss Fake: 0.1140, \n",
      "Epoch [18/300], Step [80/234], D Loss: 0.2313, G Loss: 6.7761; D Loss Real: 0.0375, ; D Loss Fake: 0.1937, \n",
      "Epoch [18/300], Step [100/234], D Loss: 0.1640, G Loss: 8.5388; D Loss Real: 0.1238, ; D Loss Fake: 0.0403, \n",
      "Epoch [18/300], Step [120/234], D Loss: 0.0839, G Loss: 7.0744; D Loss Real: 0.0831, ; D Loss Fake: 0.0008, \n",
      "Epoch [18/300], Step [140/234], D Loss: 0.0909, G Loss: 4.9946; D Loss Real: 0.0051, ; D Loss Fake: 0.0857, \n",
      "Epoch [18/300], Step [160/234], D Loss: 0.0814, G Loss: 4.6230; D Loss Real: 0.0025, ; D Loss Fake: 0.0789, \n",
      "Epoch [18/300], Step [180/234], D Loss: 0.1248, G Loss: 7.6419; D Loss Real: 0.1238, ; D Loss Fake: 0.0009, \n",
      "Epoch [18/300], Step [200/234], D Loss: 0.2034, G Loss: 10.0299; D Loss Real: 0.2028, ; D Loss Fake: 0.0006, \n",
      "Epoch [18/300], Step [220/234], D Loss: 0.1433, G Loss: 5.5977; D Loss Real: 0.0121, ; D Loss Fake: 0.1312, \n",
      "Epoch [19/300], Step [20/234], D Loss: 0.1119, G Loss: 6.3170; D Loss Real: 0.0264, ; D Loss Fake: 0.0856, \n",
      "Epoch [19/300], Step [40/234], D Loss: 0.0707, G Loss: 0.0103; D Loss Real: 0.0539, ; D Loss Fake: 0.0169, \n",
      "Epoch [19/300], Step [60/234], D Loss: 0.1003, G Loss: 5.6175; D Loss Real: 0.0980, ; D Loss Fake: 0.0023, \n",
      "Epoch [19/300], Step [80/234], D Loss: 0.0654, G Loss: 6.4723; D Loss Real: 0.0637, ; D Loss Fake: 0.0017, \n",
      "Epoch [19/300], Step [100/234], D Loss: 0.0455, G Loss: 11.5834; D Loss Real: 0.0455, ; D Loss Fake: 0.0000, \n",
      "Epoch [19/300], Step [120/234], D Loss: 0.0658, G Loss: 4.9839; D Loss Real: 0.0490, ; D Loss Fake: 0.0168, \n",
      "Epoch [19/300], Step [140/234], D Loss: 0.0765, G Loss: 7.4050; D Loss Real: 0.0577, ; D Loss Fake: 0.0188, \n",
      "Epoch [19/300], Step [160/234], D Loss: 0.0387, G Loss: 4.3507; D Loss Real: 0.0029, ; D Loss Fake: 0.0358, \n",
      "Epoch [19/300], Step [180/234], D Loss: 0.0492, G Loss: 0.0136; D Loss Real: 0.0092, ; D Loss Fake: 0.0400, \n",
      "Epoch [19/300], Step [200/234], D Loss: 0.0404, G Loss: 5.5557; D Loss Real: 0.0242, ; D Loss Fake: 0.0162, \n",
      "Epoch [19/300], Step [220/234], D Loss: 0.0081, G Loss: 4.8937; D Loss Real: 0.0043, ; D Loss Fake: 0.0038, \n",
      "Epoch [20/300], Step [20/234], D Loss: 0.0180, G Loss: 8.8540; D Loss Real: 0.0179, ; D Loss Fake: 0.0001, \n",
      "Epoch [20/300], Step [40/234], D Loss: 0.0228, G Loss: 6.6821; D Loss Real: 0.0220, ; D Loss Fake: 0.0008, \n",
      "Epoch [20/300], Step [60/234], D Loss: 0.0020, G Loss: 7.0119; D Loss Real: 0.0005, ; D Loss Fake: 0.0015, \n",
      "Epoch [20/300], Step [80/234], D Loss: 0.0646, G Loss: 5.2346; D Loss Real: 0.0023, ; D Loss Fake: 0.0624, \n",
      "Epoch [20/300], Step [100/234], D Loss: 0.0218, G Loss: 6.9620; D Loss Real: 0.0201, ; D Loss Fake: 0.0017, \n",
      "Epoch [20/300], Step [120/234], D Loss: 0.0072, G Loss: 6.4779; D Loss Real: 0.0062, ; D Loss Fake: 0.0010, \n",
      "Epoch [20/300], Step [140/234], D Loss: 0.0373, G Loss: 4.5017; D Loss Real: 0.0051, ; D Loss Fake: 0.0322, \n",
      "Epoch [20/300], Step [160/234], D Loss: 2.2433, G Loss: 2.7509; D Loss Real: 2.2432, ; D Loss Fake: 0.0001, \n",
      "Epoch [20/300], Step [180/234], D Loss: 0.7704, G Loss: 13.4310; D Loss Real: 0.0098, ; D Loss Fake: 0.7606, \n",
      "Epoch [20/300], Step [200/234], D Loss: 0.0473, G Loss: 5.1853; D Loss Real: 0.0299, ; D Loss Fake: 0.0174, \n",
      "Epoch [20/300], Step [220/234], D Loss: 0.0726, G Loss: -0.0087; D Loss Real: 0.0725, ; D Loss Fake: 0.0001, \n",
      "Epoch [21/300], Step [20/234], D Loss: 0.0776, G Loss: 6.9363; D Loss Real: 0.0742, ; D Loss Fake: 0.0033, \n",
      "Epoch [21/300], Step [40/234], D Loss: 0.0155, G Loss: 5.3882; D Loss Real: 0.0082, ; D Loss Fake: 0.0072, \n",
      "Epoch [21/300], Step [60/234], D Loss: 0.0061, G Loss: -0.0071; D Loss Real: 0.0058, ; D Loss Fake: 0.0004, \n",
      "Epoch [21/300], Step [80/234], D Loss: 0.1875, G Loss: 8.3938; D Loss Real: 0.1482, ; D Loss Fake: 0.0394, \n",
      "Epoch [21/300], Step [100/234], D Loss: 0.0126, G Loss: -0.0034; D Loss Real: 0.0123, ; D Loss Fake: 0.0004, \n",
      "Epoch [21/300], Step [120/234], D Loss: 0.0458, G Loss: 5.5113; D Loss Real: 0.0429, ; D Loss Fake: 0.0029, \n",
      "Epoch [21/300], Step [140/234], D Loss: 0.0047, G Loss: 6.1429; D Loss Real: 0.0023, ; D Loss Fake: 0.0024, \n",
      "Epoch [21/300], Step [160/234], D Loss: 0.0885, G Loss: 12.0451; D Loss Real: 0.0885, ; D Loss Fake: 0.0000, \n",
      "Epoch [21/300], Step [180/234], D Loss: 0.1098, G Loss: 4.9531; D Loss Real: 0.0301, ; D Loss Fake: 0.0797, \n",
      "Epoch [21/300], Step [200/234], D Loss: 0.1760, G Loss: 4.6246; D Loss Real: 0.1724, ; D Loss Fake: 0.0036, \n",
      "Epoch [21/300], Step [220/234], D Loss: 0.0422, G Loss: 5.9865; D Loss Real: 0.0350, ; D Loss Fake: 0.0072, \n",
      "Epoch [22/300], Step [20/234], D Loss: 0.0365, G Loss: 7.7131; D Loss Real: 0.0235, ; D Loss Fake: 0.0130, \n",
      "Epoch [22/300], Step [40/234], D Loss: 0.0377, G Loss: 6.5192; D Loss Real: 0.0117, ; D Loss Fake: 0.0261, \n",
      "Epoch [22/300], Step [60/234], D Loss: 1.2003, G Loss: 7.8881; D Loss Real: 1.2003, ; D Loss Fake: 0.0000, \n",
      "Epoch [22/300], Step [80/234], D Loss: 0.0157, G Loss: 4.4565; D Loss Real: 0.0014, ; D Loss Fake: 0.0143, \n",
      "Epoch [22/300], Step [100/234], D Loss: 0.0907, G Loss: 7.2594; D Loss Real: 0.0458, ; D Loss Fake: 0.0449, \n",
      "Epoch [22/300], Step [120/234], D Loss: 0.0100, G Loss: 5.1451; D Loss Real: 0.0046, ; D Loss Fake: 0.0053, \n",
      "Epoch [22/300], Step [140/234], D Loss: 0.0167, G Loss: 4.4962; D Loss Real: 0.0075, ; D Loss Fake: 0.0092, \n",
      "Epoch [22/300], Step [160/234], D Loss: 0.2126, G Loss: 7.4468; D Loss Real: 0.0050, ; D Loss Fake: 0.2076, \n",
      "Epoch [22/300], Step [180/234], D Loss: 0.1823, G Loss: 3.4615; D Loss Real: 0.1245, ; D Loss Fake: 0.0577, \n",
      "Epoch [22/300], Step [200/234], D Loss: 0.0362, G Loss: 4.5690; D Loss Real: 0.0038, ; D Loss Fake: 0.0325, \n",
      "Epoch [22/300], Step [220/234], D Loss: 0.0083, G Loss: 9.0856; D Loss Real: 0.0082, ; D Loss Fake: 0.0001, \n",
      "Epoch [23/300], Step [20/234], D Loss: 0.0304, G Loss: 6.0215; D Loss Real: 0.0143, ; D Loss Fake: 0.0161, \n",
      "Epoch [23/300], Step [40/234], D Loss: 0.0071, G Loss: 6.9270; D Loss Real: 0.0024, ; D Loss Fake: 0.0047, \n",
      "Epoch [23/300], Step [60/234], D Loss: 0.0189, G Loss: 9.2571; D Loss Real: 0.0183, ; D Loss Fake: 0.0006, \n",
      "Epoch [23/300], Step [80/234], D Loss: 0.0287, G Loss: 6.4797; D Loss Real: 0.0269, ; D Loss Fake: 0.0018, \n",
      "Epoch [23/300], Step [100/234], D Loss: 0.5527, G Loss: 12.6185; D Loss Real: 0.0010, ; D Loss Fake: 0.5517, \n",
      "Epoch [23/300], Step [120/234], D Loss: 0.0598, G Loss: 5.7656; D Loss Real: 0.0582, ; D Loss Fake: 0.0016, \n",
      "Epoch [23/300], Step [140/234], D Loss: 0.0172, G Loss: 5.3241; D Loss Real: 0.0009, ; D Loss Fake: 0.0164, \n",
      "Epoch [23/300], Step [160/234], D Loss: 0.0175, G Loss: 8.6940; D Loss Real: 0.0174, ; D Loss Fake: 0.0001, \n",
      "Epoch [23/300], Step [180/234], D Loss: 0.0488, G Loss: 5.1104; D Loss Real: 0.0278, ; D Loss Fake: 0.0210, \n",
      "Epoch [23/300], Step [200/234], D Loss: 0.0129, G Loss: 7.1367; D Loss Real: 0.0110, ; D Loss Fake: 0.0018, \n",
      "Epoch [23/300], Step [220/234], D Loss: 0.0376, G Loss: 4.9704; D Loss Real: 0.0154, ; D Loss Fake: 0.0222, \n",
      "Epoch [24/300], Step [20/234], D Loss: 0.0218, G Loss: 5.8928; D Loss Real: 0.0110, ; D Loss Fake: 0.0109, \n",
      "Epoch [24/300], Step [40/234], D Loss: 0.0141, G Loss: 6.1155; D Loss Real: 0.0101, ; D Loss Fake: 0.0040, \n",
      "Epoch [24/300], Step [60/234], D Loss: 0.1784, G Loss: 4.6971; D Loss Real: 0.1060, ; D Loss Fake: 0.0724, \n",
      "Epoch [24/300], Step [80/234], D Loss: 0.0732, G Loss: 10.4404; D Loss Real: 0.0731, ; D Loss Fake: 0.0002, \n",
      "Epoch [24/300], Step [100/234], D Loss: 0.0836, G Loss: 4.6555; D Loss Real: 0.0716, ; D Loss Fake: 0.0119, \n",
      "Epoch [24/300], Step [120/234], D Loss: 0.0330, G Loss: 5.4063; D Loss Real: 0.0128, ; D Loss Fake: 0.0201, \n",
      "Epoch [24/300], Step [140/234], D Loss: 0.2244, G Loss: 3.7640; D Loss Real: 0.1917, ; D Loss Fake: 0.0327, \n",
      "Epoch [24/300], Step [160/234], D Loss: 0.0243, G Loss: 6.4032; D Loss Real: 0.0193, ; D Loss Fake: 0.0051, \n",
      "Epoch [24/300], Step [180/234], D Loss: 0.0901, G Loss: 7.6486; D Loss Real: 0.0029, ; D Loss Fake: 0.0872, \n",
      "Epoch [24/300], Step [200/234], D Loss: 0.0078, G Loss: 6.9509; D Loss Real: 0.0069, ; D Loss Fake: 0.0009, \n",
      "Epoch [24/300], Step [220/234], D Loss: 0.0319, G Loss: 6.6313; D Loss Real: 0.0292, ; D Loss Fake: 0.0026, \n",
      "Epoch [25/300], Step [20/234], D Loss: 0.2187, G Loss: -0.0196; D Loss Real: 0.2187, ; D Loss Fake: 0.0000, \n",
      "Epoch [25/300], Step [40/234], D Loss: 0.0106, G Loss: 6.0572; D Loss Real: 0.0053, ; D Loss Fake: 0.0052, \n",
      "Epoch [25/300], Step [60/234], D Loss: 0.0148, G Loss: 6.1247; D Loss Real: 0.0089, ; D Loss Fake: 0.0059, \n",
      "Epoch [25/300], Step [80/234], D Loss: 0.0237, G Loss: 4.4981; D Loss Real: 0.0057, ; D Loss Fake: 0.0180, \n",
      "Epoch [25/300], Step [100/234], D Loss: 0.0359, G Loss: 5.1897; D Loss Real: 0.0328, ; D Loss Fake: 0.0031, \n",
      "Epoch [25/300], Step [120/234], D Loss: 0.0591, G Loss: 8.8202; D Loss Real: 0.0560, ; D Loss Fake: 0.0032, \n",
      "Epoch [25/300], Step [140/234], D Loss: 0.1564, G Loss: 11.7997; D Loss Real: 0.1563, ; D Loss Fake: 0.0000, \n",
      "Epoch [25/300], Step [160/234], D Loss: 0.0083, G Loss: 7.5590; D Loss Real: 0.0047, ; D Loss Fake: 0.0036, \n",
      "Epoch [25/300], Step [180/234], D Loss: 0.0350, G Loss: 5.2609; D Loss Real: 0.0042, ; D Loss Fake: 0.0308, \n",
      "Epoch [25/300], Step [200/234], D Loss: 0.0036, G Loss: 10.4343; D Loss Real: 0.0036, ; D Loss Fake: 0.0000, \n",
      "Epoch [25/300], Step [220/234], D Loss: 0.1188, G Loss: 0.0112; D Loss Real: 0.0156, ; D Loss Fake: 0.1032, \n",
      "Epoch [26/300], Step [20/234], D Loss: 0.0131, G Loss: 6.6836; D Loss Real: 0.0125, ; D Loss Fake: 0.0006, \n",
      "Epoch [26/300], Step [40/234], D Loss: 0.0078, G Loss: 8.5919; D Loss Real: 0.0076, ; D Loss Fake: 0.0001, \n",
      "Epoch [26/300], Step [60/234], D Loss: 0.0333, G Loss: 5.6177; D Loss Real: 0.0134, ; D Loss Fake: 0.0199, \n",
      "Epoch [26/300], Step [80/234], D Loss: 0.6546, G Loss: 11.3579; D Loss Real: 0.0011, ; D Loss Fake: 0.6535, \n",
      "Epoch [26/300], Step [100/234], D Loss: 0.0747, G Loss: 5.6799; D Loss Real: 0.0229, ; D Loss Fake: 0.0518, \n",
      "Epoch [26/300], Step [120/234], D Loss: 0.1496, G Loss: 6.5911; D Loss Real: 0.0061, ; D Loss Fake: 0.1435, \n",
      "Epoch [26/300], Step [140/234], D Loss: 0.0680, G Loss: 0.0031; D Loss Real: 0.0491, ; D Loss Fake: 0.0189, \n",
      "Epoch [26/300], Step [160/234], D Loss: 0.3598, G Loss: 11.6933; D Loss Real: 0.0050, ; D Loss Fake: 0.3548, \n",
      "Epoch [26/300], Step [180/234], D Loss: 0.0207, G Loss: 0.0023; D Loss Real: 0.0071, ; D Loss Fake: 0.0136, \n",
      "Epoch [26/300], Step [200/234], D Loss: 0.0953, G Loss: 5.0297; D Loss Real: 0.0132, ; D Loss Fake: 0.0821, \n",
      "Epoch [26/300], Step [220/234], D Loss: 0.0100, G Loss: 5.9894; D Loss Real: 0.0052, ; D Loss Fake: 0.0048, \n",
      "Epoch [27/300], Step [20/234], D Loss: 0.0375, G Loss: 4.8007; D Loss Real: 0.0314, ; D Loss Fake: 0.0061, \n",
      "Epoch [27/300], Step [40/234], D Loss: 0.0466, G Loss: 6.9344; D Loss Real: 0.0462, ; D Loss Fake: 0.0004, \n",
      "Epoch [27/300], Step [60/234], D Loss: 0.0149, G Loss: 4.7620; D Loss Real: 0.0055, ; D Loss Fake: 0.0095, \n",
      "Epoch [27/300], Step [80/234], D Loss: 0.0456, G Loss: 4.6137; D Loss Real: 0.0039, ; D Loss Fake: 0.0416, \n",
      "Epoch [27/300], Step [100/234], D Loss: 0.0783, G Loss: 9.6260; D Loss Real: 0.0782, ; D Loss Fake: 0.0001, \n",
      "Epoch [27/300], Step [120/234], D Loss: 0.1486, G Loss: 3.9152; D Loss Real: 0.1325, ; D Loss Fake: 0.0160, \n",
      "Epoch [27/300], Step [140/234], D Loss: 0.0403, G Loss: 6.1149; D Loss Real: 0.0372, ; D Loss Fake: 0.0031, \n",
      "Epoch [27/300], Step [160/234], D Loss: 0.0054, G Loss: 10.3162; D Loss Real: 0.0054, ; D Loss Fake: 0.0000, \n",
      "Epoch [27/300], Step [180/234], D Loss: 0.0414, G Loss: 6.4485; D Loss Real: 0.0397, ; D Loss Fake: 0.0017, \n",
      "Epoch [27/300], Step [200/234], D Loss: 0.0808, G Loss: 4.9234; D Loss Real: 0.0402, ; D Loss Fake: 0.0406, \n",
      "Epoch [27/300], Step [220/234], D Loss: 0.1441, G Loss: 4.6835; D Loss Real: 0.1418, ; D Loss Fake: 0.0023, \n",
      "Epoch [28/300], Step [20/234], D Loss: 0.0704, G Loss: 5.3030; D Loss Real: 0.0090, ; D Loss Fake: 0.0614, \n",
      "Epoch [28/300], Step [40/234], D Loss: 0.0169, G Loss: 6.6351; D Loss Real: 0.0021, ; D Loss Fake: 0.0148, \n",
      "Epoch [28/300], Step [60/234], D Loss: 0.0373, G Loss: 4.1782; D Loss Real: 0.0018, ; D Loss Fake: 0.0355, \n",
      "Epoch [28/300], Step [80/234], D Loss: 0.0388, G Loss: 6.5378; D Loss Real: 0.0377, ; D Loss Fake: 0.0010, \n",
      "Epoch [28/300], Step [100/234], D Loss: 1.4001, G Loss: 3.4468; D Loss Real: 1.4001, ; D Loss Fake: 0.0000, \n",
      "Epoch [28/300], Step [120/234], D Loss: 0.0628, G Loss: -0.0001; D Loss Real: 0.0080, ; D Loss Fake: 0.0547, \n",
      "Epoch [28/300], Step [140/234], D Loss: 0.1321, G Loss: 6.7444; D Loss Real: 0.0004, ; D Loss Fake: 0.1317, \n",
      "Epoch [28/300], Step [160/234], D Loss: 0.0385, G Loss: 4.9124; D Loss Real: 0.0053, ; D Loss Fake: 0.0333, \n",
      "Epoch [28/300], Step [180/234], D Loss: 0.0017, G Loss: 10.8452; D Loss Real: 0.0017, ; D Loss Fake: 0.0001, \n",
      "Epoch [28/300], Step [200/234], D Loss: 0.0258, G Loss: 6.7076; D Loss Real: 0.0243, ; D Loss Fake: 0.0015, \n",
      "Epoch [28/300], Step [220/234], D Loss: 0.0461, G Loss: 6.6137; D Loss Real: 0.0448, ; D Loss Fake: 0.0013, \n",
      "Epoch [29/300], Step [20/234], D Loss: 0.0328, G Loss: 5.1914; D Loss Real: 0.0246, ; D Loss Fake: 0.0082, \n",
      "Epoch [29/300], Step [40/234], D Loss: 1.6016, G Loss: 6.1182; D Loss Real: 1.6014, ; D Loss Fake: 0.0002, \n",
      "Epoch [29/300], Step [60/234], D Loss: 0.1405, G Loss: 4.7811; D Loss Real: 0.1061, ; D Loss Fake: 0.0344, \n",
      "Epoch [29/300], Step [80/234], D Loss: 0.0524, G Loss: 4.9209; D Loss Real: 0.0276, ; D Loss Fake: 0.0248, \n",
      "Epoch [29/300], Step [100/234], D Loss: 0.0193, G Loss: 8.3872; D Loss Real: 0.0191, ; D Loss Fake: 0.0002, \n",
      "Epoch [29/300], Step [120/234], D Loss: 0.0540, G Loss: 7.5484; D Loss Real: 0.0536, ; D Loss Fake: 0.0004, \n",
      "Epoch [29/300], Step [140/234], D Loss: 0.0771, G Loss: 4.4966; D Loss Real: 0.0147, ; D Loss Fake: 0.0624, \n",
      "Epoch [29/300], Step [160/234], D Loss: 0.7979, G Loss: 12.5208; D Loss Real: 0.0087, ; D Loss Fake: 0.7892, \n",
      "Epoch [29/300], Step [180/234], D Loss: 0.1348, G Loss: 5.6275; D Loss Real: 0.1313, ; D Loss Fake: 0.0036, \n",
      "Epoch [29/300], Step [200/234], D Loss: 0.0315, G Loss: -0.0093; D Loss Real: 0.0301, ; D Loss Fake: 0.0014, \n",
      "Epoch [29/300], Step [220/234], D Loss: 0.0363, G Loss: 3.7720; D Loss Real: 0.0045, ; D Loss Fake: 0.0318, \n",
      "Epoch [30/300], Step [20/234], D Loss: 0.0213, G Loss: 6.6205; D Loss Real: 0.0045, ; D Loss Fake: 0.0168, \n",
      "Epoch [30/300], Step [40/234], D Loss: 0.0319, G Loss: -0.0036; D Loss Real: 0.0318, ; D Loss Fake: 0.0001, \n",
      "Epoch [30/300], Step [60/234], D Loss: 0.5481, G Loss: 9.7588; D Loss Real: 0.5480, ; D Loss Fake: 0.0001, \n",
      "Epoch [30/300], Step [80/234], D Loss: 0.0170, G Loss: 4.7198; D Loss Real: 0.0051, ; D Loss Fake: 0.0119, \n",
      "Epoch [30/300], Step [100/234], D Loss: 0.0428, G Loss: 5.5951; D Loss Real: 0.0095, ; D Loss Fake: 0.0333, \n",
      "Epoch [30/300], Step [120/234], D Loss: 0.0115, G Loss: -0.0020; D Loss Real: 0.0106, ; D Loss Fake: 0.0009, \n",
      "Epoch [30/300], Step [140/234], D Loss: 0.0357, G Loss: 5.5064; D Loss Real: 0.0318, ; D Loss Fake: 0.0039, \n",
      "Epoch [30/300], Step [160/234], D Loss: 0.0201, G Loss: 6.2001; D Loss Real: 0.0008, ; D Loss Fake: 0.0193, \n",
      "Epoch [30/300], Step [180/234], D Loss: 0.0380, G Loss: 7.5122; D Loss Real: 0.0375, ; D Loss Fake: 0.0005, \n",
      "Epoch [30/300], Step [200/234], D Loss: 0.0215, G Loss: 5.0591; D Loss Real: 0.0084, ; D Loss Fake: 0.0131, \n",
      "Epoch [30/300], Step [220/234], D Loss: 0.0392, G Loss: 11.2884; D Loss Real: 0.0392, ; D Loss Fake: 0.0000, \n",
      "Epoch [31/300], Step [20/234], D Loss: 0.0230, G Loss: 4.7758; D Loss Real: 0.0009, ; D Loss Fake: 0.0221, \n",
      "Epoch [31/300], Step [40/234], D Loss: 0.1139, G Loss: 5.3928; D Loss Real: 0.0269, ; D Loss Fake: 0.0870, \n",
      "Epoch [31/300], Step [60/234], D Loss: 0.0188, G Loss: 7.0723; D Loss Real: 0.0175, ; D Loss Fake: 0.0013, \n",
      "Epoch [31/300], Step [80/234], D Loss: 0.0479, G Loss: 4.7729; D Loss Real: 0.0084, ; D Loss Fake: 0.0396, \n",
      "Epoch [31/300], Step [100/234], D Loss: 0.0295, G Loss: 11.2847; D Loss Real: 0.0295, ; D Loss Fake: 0.0000, \n",
      "Epoch [31/300], Step [120/234], D Loss: 0.1036, G Loss: 6.4237; D Loss Real: 0.0015, ; D Loss Fake: 0.1021, \n",
      "Epoch [31/300], Step [140/234], D Loss: 0.0275, G Loss: 5.8449; D Loss Real: 0.0046, ; D Loss Fake: 0.0229, \n",
      "Epoch [31/300], Step [160/234], D Loss: 0.0027, G Loss: 9.9692; D Loss Real: 0.0026, ; D Loss Fake: 0.0001, \n",
      "Epoch [31/300], Step [180/234], D Loss: 0.0065, G Loss: 12.9807; D Loss Real: 0.0065, ; D Loss Fake: 0.0000, \n",
      "Epoch [31/300], Step [200/234], D Loss: 0.0027, G Loss: 14.0947; D Loss Real: 0.0027, ; D Loss Fake: 0.0000, \n",
      "Epoch [31/300], Step [220/234], D Loss: 0.0033, G Loss: 6.8842; D Loss Real: 0.0026, ; D Loss Fake: 0.0007, \n",
      "Epoch [32/300], Step [20/234], D Loss: 0.0790, G Loss: 17.1439; D Loss Real: 0.0790, ; D Loss Fake: 0.0000, \n",
      "Epoch [32/300], Step [40/234], D Loss: 0.0598, G Loss: 7.5064; D Loss Real: 0.0047, ; D Loss Fake: 0.0551, \n",
      "Epoch [32/300], Step [60/234], D Loss: 0.0050, G Loss: 7.3141; D Loss Real: 0.0033, ; D Loss Fake: 0.0017, \n",
      "Epoch [32/300], Step [80/234], D Loss: 0.0177, G Loss: 5.7104; D Loss Real: 0.0156, ; D Loss Fake: 0.0022, \n",
      "Epoch [32/300], Step [100/234], D Loss: 0.0119, G Loss: 5.2828; D Loss Real: 0.0061, ; D Loss Fake: 0.0059, \n",
      "Epoch [32/300], Step [120/234], D Loss: 0.0950, G Loss: 4.1866; D Loss Real: 0.0266, ; D Loss Fake: 0.0684, \n",
      "Epoch [32/300], Step [140/234], D Loss: 0.0839, G Loss: 5.0708; D Loss Real: 0.0403, ; D Loss Fake: 0.0436, \n",
      "Epoch [32/300], Step [160/234], D Loss: 1.1593, G Loss: -0.0255; D Loss Real: 0.0035, ; D Loss Fake: 1.1557, \n",
      "Epoch [32/300], Step [180/234], D Loss: 0.2629, G Loss: 6.1986; D Loss Real: 0.2626, ; D Loss Fake: 0.0003, \n",
      "Epoch [32/300], Step [200/234], D Loss: 0.0430, G Loss: 4.6258; D Loss Real: 0.0025, ; D Loss Fake: 0.0405, \n",
      "Epoch [32/300], Step [220/234], D Loss: 0.1943, G Loss: 5.4519; D Loss Real: 0.1757, ; D Loss Fake: 0.0187, \n",
      "Epoch [33/300], Step [20/234], D Loss: 0.0266, G Loss: 4.9144; D Loss Real: 0.0206, ; D Loss Fake: 0.0061, \n",
      "Epoch [33/300], Step [40/234], D Loss: 0.2354, G Loss: 8.1481; D Loss Real: 0.0083, ; D Loss Fake: 0.2271, \n",
      "Epoch [33/300], Step [60/234], D Loss: 0.0437, G Loss: 9.1520; D Loss Real: 0.0434, ; D Loss Fake: 0.0003, \n",
      "Epoch [33/300], Step [80/234], D Loss: 0.0049, G Loss: 6.4461; D Loss Real: 0.0041, ; D Loss Fake: 0.0009, \n",
      "Epoch [33/300], Step [100/234], D Loss: 0.0033, G Loss: 0.0048; D Loss Real: 0.0033, ; D Loss Fake: 0.0000, \n",
      "Epoch [33/300], Step [120/234], D Loss: 0.0327, G Loss: -0.0025; D Loss Real: 0.0318, ; D Loss Fake: 0.0009, \n",
      "Epoch [33/300], Step [140/234], D Loss: 0.0265, G Loss: 6.2183; D Loss Real: 0.0148, ; D Loss Fake: 0.0118, \n",
      "Epoch [33/300], Step [160/234], D Loss: 0.0322, G Loss: 10.4281; D Loss Real: 0.0322, ; D Loss Fake: 0.0000, \n",
      "Epoch [33/300], Step [180/234], D Loss: 0.0080, G Loss: 7.0166; D Loss Real: 0.0075, ; D Loss Fake: 0.0005, \n",
      "Epoch [33/300], Step [200/234], D Loss: 0.0303, G Loss: 6.9648; D Loss Real: 0.0017, ; D Loss Fake: 0.0286, \n",
      "Epoch [33/300], Step [220/234], D Loss: 0.0580, G Loss: 4.0520; D Loss Real: 0.0421, ; D Loss Fake: 0.0159, \n",
      "Epoch [34/300], Step [20/234], D Loss: 0.5691, G Loss: -0.0081; D Loss Real: 0.5691, ; D Loss Fake: 0.0000, \n",
      "Epoch [34/300], Step [40/234], D Loss: 0.0017, G Loss: 9.6281; D Loss Real: 0.0016, ; D Loss Fake: 0.0000, \n",
      "Epoch [34/300], Step [60/234], D Loss: 0.1110, G Loss: 7.8609; D Loss Real: 0.0207, ; D Loss Fake: 0.0903, \n",
      "Epoch [34/300], Step [80/234], D Loss: 0.1125, G Loss: 5.6854; D Loss Real: 0.0007, ; D Loss Fake: 0.1118, \n",
      "Epoch [34/300], Step [100/234], D Loss: 0.3971, G Loss: 0.0035; D Loss Real: 0.3968, ; D Loss Fake: 0.0003, \n",
      "Epoch [34/300], Step [120/234], D Loss: 0.1112, G Loss: 6.1816; D Loss Real: 0.0047, ; D Loss Fake: 0.1066, \n",
      "Epoch [34/300], Step [140/234], D Loss: 0.0075, G Loss: 10.7353; D Loss Real: 0.0057, ; D Loss Fake: 0.0018, \n",
      "Epoch [34/300], Step [160/234], D Loss: 0.0186, G Loss: 7.3993; D Loss Real: 0.0172, ; D Loss Fake: 0.0014, \n",
      "Epoch [34/300], Step [180/234], D Loss: 0.0248, G Loss: 9.4351; D Loss Real: 0.0248, ; D Loss Fake: 0.0000, \n",
      "Epoch [34/300], Step [200/234], D Loss: 0.0444, G Loss: 4.0082; D Loss Real: 0.0005, ; D Loss Fake: 0.0439, \n",
      "Epoch [34/300], Step [220/234], D Loss: 0.0088, G Loss: 8.6054; D Loss Real: 0.0087, ; D Loss Fake: 0.0001, \n",
      "Epoch [35/300], Step [20/234], D Loss: 0.1846, G Loss: 8.9635; D Loss Real: 0.1845, ; D Loss Fake: 0.0001, \n",
      "Epoch [35/300], Step [40/234], D Loss: 0.0076, G Loss: 8.5406; D Loss Real: 0.0076, ; D Loss Fake: 0.0000, \n",
      "Epoch [35/300], Step [60/234], D Loss: 0.4375, G Loss: 9.2638; D Loss Real: 0.1016, ; D Loss Fake: 0.3359, \n",
      "Epoch [35/300], Step [80/234], D Loss: 0.2933, G Loss: 12.0548; D Loss Real: 0.2933, ; D Loss Fake: 0.0000, \n",
      "Epoch [35/300], Step [100/234], D Loss: 0.2567, G Loss: 3.9478; D Loss Real: 0.1675, ; D Loss Fake: 0.0892, \n",
      "Epoch [35/300], Step [120/234], D Loss: 0.0082, G Loss: 9.1116; D Loss Real: 0.0081, ; D Loss Fake: 0.0001, \n",
      "Epoch [35/300], Step [140/234], D Loss: 0.0478, G Loss: 4.9049; D Loss Real: 0.0297, ; D Loss Fake: 0.0181, \n",
      "Epoch [35/300], Step [160/234], D Loss: 0.0468, G Loss: 4.5925; D Loss Real: 0.0147, ; D Loss Fake: 0.0321, \n",
      "Epoch [35/300], Step [180/234], D Loss: 0.0494, G Loss: 4.9438; D Loss Real: 0.0085, ; D Loss Fake: 0.0409, \n",
      "Epoch [35/300], Step [200/234], D Loss: 0.0092, G Loss: -0.0053; D Loss Real: 0.0006, ; D Loss Fake: 0.0086, \n",
      "Epoch [35/300], Step [220/234], D Loss: 0.0039, G Loss: 6.6545; D Loss Real: 0.0010, ; D Loss Fake: 0.0030, \n",
      "Epoch [36/300], Step [20/234], D Loss: 0.3152, G Loss: 6.8790; D Loss Real: 0.0624, ; D Loss Fake: 0.2528, \n",
      "Epoch [36/300], Step [40/234], D Loss: 0.0045, G Loss: 8.4269; D Loss Real: 0.0042, ; D Loss Fake: 0.0002, \n",
      "Epoch [36/300], Step [60/234], D Loss: 0.0584, G Loss: 4.9833; D Loss Real: 0.0070, ; D Loss Fake: 0.0514, \n",
      "Epoch [36/300], Step [80/234], D Loss: 0.0094, G Loss: 6.1769; D Loss Real: 0.0028, ; D Loss Fake: 0.0066, \n",
      "Epoch [36/300], Step [100/234], D Loss: 0.0418, G Loss: 12.4653; D Loss Real: 0.0417, ; D Loss Fake: 0.0000, \n",
      "Epoch [36/300], Step [120/234], D Loss: 0.4959, G Loss: 11.6694; D Loss Real: 0.0006, ; D Loss Fake: 0.4954, \n",
      "Epoch [36/300], Step [140/234], D Loss: 0.2839, G Loss: -0.0055; D Loss Real: 0.0050, ; D Loss Fake: 0.2788, \n",
      "Epoch [36/300], Step [160/234], D Loss: 0.0581, G Loss: 7.1157; D Loss Real: 0.0562, ; D Loss Fake: 0.0020, \n",
      "Epoch [36/300], Step [180/234], D Loss: 0.0206, G Loss: 4.4489; D Loss Real: 0.0031, ; D Loss Fake: 0.0174, \n",
      "Epoch [36/300], Step [200/234], D Loss: 0.0051, G Loss: 7.4827; D Loss Real: 0.0045, ; D Loss Fake: 0.0006, \n",
      "Epoch [36/300], Step [220/234], D Loss: 0.0304, G Loss: 5.2939; D Loss Real: 0.0030, ; D Loss Fake: 0.0274, \n",
      "Epoch [37/300], Step [20/234], D Loss: 0.0109, G Loss: 7.3500; D Loss Real: 0.0103, ; D Loss Fake: 0.0006, \n",
      "Epoch [37/300], Step [40/234], D Loss: 0.0157, G Loss: 13.8402; D Loss Real: 0.0157, ; D Loss Fake: 0.0000, \n",
      "Epoch [37/300], Step [60/234], D Loss: 0.0030, G Loss: 6.0948; D Loss Real: 0.0009, ; D Loss Fake: 0.0022, \n",
      "Epoch [37/300], Step [80/234], D Loss: 0.0023, G Loss: 8.5478; D Loss Real: 0.0021, ; D Loss Fake: 0.0002, \n",
      "Epoch [37/300], Step [100/234], D Loss: 0.0455, G Loss: 4.5271; D Loss Real: 0.0324, ; D Loss Fake: 0.0131, \n",
      "Epoch [37/300], Step [120/234], D Loss: 0.0127, G Loss: 8.8777; D Loss Real: 0.0126, ; D Loss Fake: 0.0001, \n",
      "Epoch [37/300], Step [140/234], D Loss: 0.0959, G Loss: 5.7268; D Loss Real: 0.0006, ; D Loss Fake: 0.0953, \n",
      "Epoch [37/300], Step [160/234], D Loss: 0.0043, G Loss: 5.8331; D Loss Real: 0.0004, ; D Loss Fake: 0.0039, \n",
      "Epoch [37/300], Step [180/234], D Loss: 0.0097, G Loss: 5.3321; D Loss Real: 0.0016, ; D Loss Fake: 0.0081, \n",
      "Epoch [37/300], Step [200/234], D Loss: 0.0049, G Loss: 5.5499; D Loss Real: 0.0021, ; D Loss Fake: 0.0027, \n",
      "Epoch [37/300], Step [220/234], D Loss: 0.0049, G Loss: 6.6660; D Loss Real: 0.0023, ; D Loss Fake: 0.0027, \n",
      "Epoch [38/300], Step [20/234], D Loss: 0.0080, G Loss: 5.4105; D Loss Real: 0.0048, ; D Loss Fake: 0.0032, \n",
      "Epoch [38/300], Step [40/234], D Loss: 0.0076, G Loss: 5.6019; D Loss Real: 0.0025, ; D Loss Fake: 0.0051, \n",
      "Epoch [38/300], Step [60/234], D Loss: 0.0372, G Loss: 4.5140; D Loss Real: 0.0066, ; D Loss Fake: 0.0306, \n",
      "Epoch [38/300], Step [80/234], D Loss: 0.0657, G Loss: 5.0003; D Loss Real: 0.0090, ; D Loss Fake: 0.0567, \n",
      "Epoch [38/300], Step [100/234], D Loss: 0.0043, G Loss: 7.6511; D Loss Real: 0.0038, ; D Loss Fake: 0.0005, \n",
      "Epoch [38/300], Step [120/234], D Loss: 0.0915, G Loss: 13.0826; D Loss Real: 0.0915, ; D Loss Fake: 0.0000, \n",
      "Epoch [38/300], Step [140/234], D Loss: 0.0087, G Loss: 5.0405; D Loss Real: 0.0049, ; D Loss Fake: 0.0038, \n",
      "Epoch [38/300], Step [160/234], D Loss: 0.0167, G Loss: 8.6375; D Loss Real: 0.0164, ; D Loss Fake: 0.0003, \n",
      "Epoch [38/300], Step [180/234], D Loss: 0.0453, G Loss: 4.6994; D Loss Real: 0.0061, ; D Loss Fake: 0.0392, \n",
      "Epoch [38/300], Step [200/234], D Loss: 0.0233, G Loss: 7.0571; D Loss Real: 0.0227, ; D Loss Fake: 0.0006, \n",
      "Epoch [38/300], Step [220/234], D Loss: 0.0062, G Loss: 5.3242; D Loss Real: 0.0009, ; D Loss Fake: 0.0052, \n",
      "Epoch [39/300], Step [20/234], D Loss: 0.0096, G Loss: 5.8993; D Loss Real: 0.0060, ; D Loss Fake: 0.0036, \n",
      "Epoch [39/300], Step [40/234], D Loss: 0.1216, G Loss: 4.5860; D Loss Real: 0.0268, ; D Loss Fake: 0.0948, \n",
      "Epoch [39/300], Step [60/234], D Loss: 0.0012, G Loss: 0.0021; D Loss Real: 0.0012, ; D Loss Fake: 0.0000, \n",
      "Epoch [39/300], Step [80/234], D Loss: 0.1253, G Loss: 0.0216; D Loss Real: 0.0874, ; D Loss Fake: 0.0379, \n",
      "Epoch [39/300], Step [100/234], D Loss: 0.0208, G Loss: 9.1160; D Loss Real: 0.0208, ; D Loss Fake: 0.0000, \n",
      "Epoch [39/300], Step [120/234], D Loss: 0.1769, G Loss: 9.5333; D Loss Real: 0.1768, ; D Loss Fake: 0.0001, \n",
      "Epoch [39/300], Step [140/234], D Loss: 0.0032, G Loss: 5.9809; D Loss Real: 0.0001, ; D Loss Fake: 0.0030, \n",
      "Epoch [39/300], Step [160/234], D Loss: 0.4154, G Loss: 10.0636; D Loss Real: 0.4154, ; D Loss Fake: 0.0000, \n",
      "Epoch [39/300], Step [180/234], D Loss: 0.1141, G Loss: 3.9017; D Loss Real: 0.0877, ; D Loss Fake: 0.0264, \n",
      "Epoch [39/300], Step [200/234], D Loss: 0.0669, G Loss: -0.0040; D Loss Real: 0.0081, ; D Loss Fake: 0.0588, \n",
      "Epoch [39/300], Step [220/234], D Loss: 0.1327, G Loss: 7.2096; D Loss Real: 0.0027, ; D Loss Fake: 0.1299, \n",
      "Epoch [40/300], Step [20/234], D Loss: 0.1141, G Loss: 5.7376; D Loss Real: 0.1090, ; D Loss Fake: 0.0050, \n",
      "Epoch [40/300], Step [40/234], D Loss: 0.0425, G Loss: 4.5838; D Loss Real: 0.0133, ; D Loss Fake: 0.0292, \n",
      "Epoch [40/300], Step [60/234], D Loss: 0.0648, G Loss: 7.0646; D Loss Real: 0.0644, ; D Loss Fake: 0.0004, \n",
      "Epoch [40/300], Step [80/234], D Loss: 0.0225, G Loss: 4.7100; D Loss Real: 0.0131, ; D Loss Fake: 0.0094, \n",
      "Epoch [40/300], Step [100/234], D Loss: 0.0330, G Loss: 5.8056; D Loss Real: 0.0315, ; D Loss Fake: 0.0015, \n",
      "Epoch [40/300], Step [120/234], D Loss: 0.0056, G Loss: 6.6820; D Loss Real: 0.0044, ; D Loss Fake: 0.0012, \n",
      "Epoch [40/300], Step [140/234], D Loss: 0.0291, G Loss: 10.1208; D Loss Real: 0.0290, ; D Loss Fake: 0.0000, \n",
      "Epoch [40/300], Step [160/234], D Loss: 0.0391, G Loss: 7.1749; D Loss Real: 0.0383, ; D Loss Fake: 0.0008, \n",
      "Epoch [40/300], Step [180/234], D Loss: 0.0198, G Loss: 6.1258; D Loss Real: 0.0172, ; D Loss Fake: 0.0026, \n",
      "Epoch [40/300], Step [200/234], D Loss: 0.0202, G Loss: 5.4265; D Loss Real: 0.0011, ; D Loss Fake: 0.0192, \n",
      "Epoch [40/300], Step [220/234], D Loss: 0.0038, G Loss: 8.3448; D Loss Real: 0.0037, ; D Loss Fake: 0.0001, \n",
      "Epoch [41/300], Step [20/234], D Loss: 0.0058, G Loss: 9.2398; D Loss Real: 0.0057, ; D Loss Fake: 0.0001, \n",
      "Epoch [41/300], Step [40/234], D Loss: 0.0248, G Loss: 5.2817; D Loss Real: 0.0057, ; D Loss Fake: 0.0191, \n",
      "Epoch [41/300], Step [60/234], D Loss: 0.0797, G Loss: 0.0002; D Loss Real: 0.0749, ; D Loss Fake: 0.0048, \n",
      "Epoch [41/300], Step [80/234], D Loss: 0.0269, G Loss: 6.2496; D Loss Real: 0.0258, ; D Loss Fake: 0.0011, \n",
      "Epoch [41/300], Step [100/234], D Loss: 0.0607, G Loss: 6.1354; D Loss Real: 0.0018, ; D Loss Fake: 0.0589, \n",
      "Epoch [41/300], Step [120/234], D Loss: 0.0731, G Loss: 6.1562; D Loss Real: 0.0004, ; D Loss Fake: 0.0727, \n",
      "Epoch [41/300], Step [140/234], D Loss: 0.0390, G Loss: 14.2060; D Loss Real: 0.0389, ; D Loss Fake: 0.0000, \n",
      "Epoch [41/300], Step [160/234], D Loss: 0.9396, G Loss: 16.3943; D Loss Real: 0.0001, ; D Loss Fake: 0.9395, \n",
      "Epoch [41/300], Step [180/234], D Loss: 0.0442, G Loss: 9.0515; D Loss Real: 0.0441, ; D Loss Fake: 0.0001, \n",
      "Epoch [41/300], Step [200/234], D Loss: 0.0045, G Loss: 6.5041; D Loss Real: 0.0028, ; D Loss Fake: 0.0017, \n",
      "Epoch [41/300], Step [220/234], D Loss: 0.0754, G Loss: 8.3983; D Loss Real: 0.0746, ; D Loss Fake: 0.0008, \n",
      "Epoch [42/300], Step [20/234], D Loss: 0.0705, G Loss: 4.8896; D Loss Real: 0.0615, ; D Loss Fake: 0.0090, \n",
      "Epoch [42/300], Step [40/234], D Loss: 0.0146, G Loss: 0.0096; D Loss Real: 0.0145, ; D Loss Fake: 0.0001, \n",
      "Epoch [42/300], Step [60/234], D Loss: 0.0035, G Loss: 7.3214; D Loss Real: 0.0021, ; D Loss Fake: 0.0014, \n",
      "Epoch [42/300], Step [80/234], D Loss: 0.0193, G Loss: 6.2778; D Loss Real: 0.0186, ; D Loss Fake: 0.0007, \n",
      "Epoch [42/300], Step [100/234], D Loss: 0.0004, G Loss: 12.2282; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [42/300], Step [120/234], D Loss: 0.0148, G Loss: 5.9998; D Loss Real: 0.0119, ; D Loss Fake: 0.0029, \n",
      "Epoch [42/300], Step [140/234], D Loss: 0.0015, G Loss: -0.0083; D Loss Real: 0.0015, ; D Loss Fake: 0.0000, \n",
      "Epoch [42/300], Step [160/234], D Loss: 0.0021, G Loss: 9.1971; D Loss Real: 0.0019, ; D Loss Fake: 0.0002, \n",
      "Epoch [42/300], Step [180/234], D Loss: 0.0469, G Loss: 0.0032; D Loss Real: 0.0465, ; D Loss Fake: 0.0004, \n",
      "Epoch [42/300], Step [200/234], D Loss: 0.1774, G Loss: 7.9406; D Loss Real: 0.0210, ; D Loss Fake: 0.1564, \n",
      "Epoch [42/300], Step [220/234], D Loss: 0.1657, G Loss: 6.5853; D Loss Real: 0.1645, ; D Loss Fake: 0.0011, \n",
      "Epoch [43/300], Step [20/234], D Loss: 0.1043, G Loss: 6.6778; D Loss Real: 0.0003, ; D Loss Fake: 0.1040, \n",
      "Epoch [43/300], Step [40/234], D Loss: 0.0025, G Loss: 6.9159; D Loss Real: 0.0003, ; D Loss Fake: 0.0022, \n",
      "Epoch [43/300], Step [60/234], D Loss: 0.0668, G Loss: 4.1067; D Loss Real: 0.0013, ; D Loss Fake: 0.0655, \n",
      "Epoch [43/300], Step [80/234], D Loss: 0.0083, G Loss: 3.2806; D Loss Real: 0.0017, ; D Loss Fake: 0.0066, \n",
      "Epoch [43/300], Step [100/234], D Loss: 0.5560, G Loss: 11.9888; D Loss Real: 0.0006, ; D Loss Fake: 0.5554, \n",
      "Epoch [43/300], Step [120/234], D Loss: 0.0823, G Loss: 6.2696; D Loss Real: 0.0815, ; D Loss Fake: 0.0007, \n",
      "Epoch [43/300], Step [140/234], D Loss: 0.1382, G Loss: 7.7083; D Loss Real: 0.0011, ; D Loss Fake: 0.1371, \n",
      "Epoch [43/300], Step [160/234], D Loss: 0.0149, G Loss: 11.2638; D Loss Real: 0.0149, ; D Loss Fake: 0.0000, \n",
      "Epoch [43/300], Step [180/234], D Loss: 0.0048, G Loss: -0.0040; D Loss Real: 0.0048, ; D Loss Fake: 0.0000, \n",
      "Epoch [43/300], Step [200/234], D Loss: 0.0516, G Loss: 0.0038; D Loss Real: 0.0502, ; D Loss Fake: 0.0014, \n",
      "Epoch [43/300], Step [220/234], D Loss: 0.0010, G Loss: 7.4121; D Loss Real: 0.0007, ; D Loss Fake: 0.0003, \n",
      "Epoch [44/300], Step [20/234], D Loss: 0.0022, G Loss: 6.2592; D Loss Real: 0.0007, ; D Loss Fake: 0.0014, \n",
      "Epoch [44/300], Step [40/234], D Loss: 0.0472, G Loss: 5.3328; D Loss Real: 0.0013, ; D Loss Fake: 0.0459, \n",
      "Epoch [44/300], Step [60/234], D Loss: 0.0195, G Loss: 5.5700; D Loss Real: 0.0097, ; D Loss Fake: 0.0098, \n",
      "Epoch [44/300], Step [80/234], D Loss: 0.0058, G Loss: 14.1653; D Loss Real: 0.0058, ; D Loss Fake: 0.0000, \n",
      "Epoch [44/300], Step [100/234], D Loss: 0.0004, G Loss: 9.8139; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [44/300], Step [120/234], D Loss: 0.0042, G Loss: 7.1623; D Loss Real: 0.0038, ; D Loss Fake: 0.0004, \n",
      "Epoch [44/300], Step [140/234], D Loss: 0.0140, G Loss: 6.0613; D Loss Real: 0.0051, ; D Loss Fake: 0.0089, \n",
      "Epoch [44/300], Step [160/234], D Loss: 0.2837, G Loss: 11.5520; D Loss Real: 0.0065, ; D Loss Fake: 0.2772, \n",
      "Epoch [44/300], Step [180/234], D Loss: 0.0096, G Loss: 7.3996; D Loss Real: 0.0045, ; D Loss Fake: 0.0051, \n",
      "Epoch [44/300], Step [200/234], D Loss: 0.0637, G Loss: 7.1077; D Loss Real: 0.0622, ; D Loss Fake: 0.0015, \n",
      "Epoch [44/300], Step [220/234], D Loss: 0.1009, G Loss: 5.0041; D Loss Real: 0.0997, ; D Loss Fake: 0.0013, \n",
      "Epoch [45/300], Step [20/234], D Loss: 0.0089, G Loss: 8.1935; D Loss Real: 0.0086, ; D Loss Fake: 0.0003, \n",
      "Epoch [45/300], Step [40/234], D Loss: 0.0015, G Loss: 8.5022; D Loss Real: 0.0014, ; D Loss Fake: 0.0002, \n",
      "Epoch [45/300], Step [60/234], D Loss: 0.0372, G Loss: 6.4507; D Loss Real: 0.0000, ; D Loss Fake: 0.0372, \n",
      "Epoch [45/300], Step [80/234], D Loss: 0.0070, G Loss: 5.6089; D Loss Real: 0.0018, ; D Loss Fake: 0.0051, \n",
      "Epoch [45/300], Step [100/234], D Loss: 0.0146, G Loss: 9.4828; D Loss Real: 0.0145, ; D Loss Fake: 0.0000, \n",
      "Epoch [45/300], Step [120/234], D Loss: 0.1625, G Loss: 8.8582; D Loss Real: 0.0024, ; D Loss Fake: 0.1600, \n",
      "Epoch [45/300], Step [140/234], D Loss: 0.2997, G Loss: 4.8614; D Loss Real: 0.2993, ; D Loss Fake: 0.0004, \n",
      "Epoch [45/300], Step [160/234], D Loss: 0.1518, G Loss: 9.9943; D Loss Real: 0.0019, ; D Loss Fake: 0.1499, \n",
      "Epoch [45/300], Step [180/234], D Loss: 0.0085, G Loss: 6.6580; D Loss Real: 0.0065, ; D Loss Fake: 0.0019, \n",
      "Epoch [45/300], Step [200/234], D Loss: 0.0421, G Loss: 6.0017; D Loss Real: 0.0384, ; D Loss Fake: 0.0037, \n",
      "Epoch [45/300], Step [220/234], D Loss: 0.0208, G Loss: 4.6960; D Loss Real: 0.0012, ; D Loss Fake: 0.0197, \n",
      "Epoch [46/300], Step [20/234], D Loss: 0.0015, G Loss: 7.3891; D Loss Real: 0.0004, ; D Loss Fake: 0.0010, \n",
      "Epoch [46/300], Step [40/234], D Loss: 0.0105, G Loss: 5.6671; D Loss Real: 0.0006, ; D Loss Fake: 0.0099, \n",
      "Epoch [46/300], Step [60/234], D Loss: 0.0088, G Loss: 6.6046; D Loss Real: 0.0077, ; D Loss Fake: 0.0010, \n",
      "Epoch [46/300], Step [80/234], D Loss: 0.0098, G Loss: -0.0092; D Loss Real: 0.0011, ; D Loss Fake: 0.0087, \n",
      "Epoch [46/300], Step [100/234], D Loss: 0.0049, G Loss: 6.0097; D Loss Real: 0.0032, ; D Loss Fake: 0.0017, \n",
      "Epoch [46/300], Step [120/234], D Loss: 0.0234, G Loss: 5.2518; D Loss Real: 0.0186, ; D Loss Fake: 0.0048, \n",
      "Epoch [46/300], Step [140/234], D Loss: 0.0649, G Loss: 7.5972; D Loss Real: 0.0012, ; D Loss Fake: 0.0638, \n",
      "Epoch [46/300], Step [160/234], D Loss: 0.6874, G Loss: 16.1746; D Loss Real: 0.0010, ; D Loss Fake: 0.6864, \n",
      "Epoch [46/300], Step [180/234], D Loss: 0.0171, G Loss: -0.0088; D Loss Real: 0.0171, ; D Loss Fake: 0.0000, \n",
      "Epoch [46/300], Step [200/234], D Loss: 0.0299, G Loss: 5.2454; D Loss Real: 0.0009, ; D Loss Fake: 0.0290, \n",
      "Epoch [46/300], Step [220/234], D Loss: 0.0066, G Loss: 0.0057; D Loss Real: 0.0041, ; D Loss Fake: 0.0024, \n",
      "Epoch [47/300], Step [20/234], D Loss: 0.0032, G Loss: 9.0549; D Loss Real: 0.0018, ; D Loss Fake: 0.0014, \n",
      "Epoch [47/300], Step [40/234], D Loss: 1.4263, G Loss: 0.0010; D Loss Real: 0.0244, ; D Loss Fake: 1.4019, \n",
      "Epoch [47/300], Step [60/234], D Loss: 0.0618, G Loss: 10.1269; D Loss Real: 0.0617, ; D Loss Fake: 0.0001, \n",
      "Epoch [47/300], Step [80/234], D Loss: 0.0085, G Loss: 0.0053; D Loss Real: 0.0057, ; D Loss Fake: 0.0028, \n",
      "Epoch [47/300], Step [100/234], D Loss: 0.0009, G Loss: 7.8333; D Loss Real: 0.0006, ; D Loss Fake: 0.0003, \n",
      "Epoch [47/300], Step [120/234], D Loss: 0.0707, G Loss: 0.0061; D Loss Real: 0.0048, ; D Loss Fake: 0.0659, \n",
      "Epoch [47/300], Step [140/234], D Loss: 0.0183, G Loss: 5.8158; D Loss Real: 0.0148, ; D Loss Fake: 0.0036, \n",
      "Epoch [47/300], Step [160/234], D Loss: 0.0036, G Loss: 15.2766; D Loss Real: 0.0036, ; D Loss Fake: 0.0000, \n",
      "Epoch [47/300], Step [180/234], D Loss: 0.0727, G Loss: 4.9458; D Loss Real: 0.0548, ; D Loss Fake: 0.0179, \n",
      "Epoch [47/300], Step [200/234], D Loss: 0.1347, G Loss: 5.7690; D Loss Real: 0.0077, ; D Loss Fake: 0.1270, \n",
      "Epoch [47/300], Step [220/234], D Loss: 0.0179, G Loss: 5.0064; D Loss Real: 0.0023, ; D Loss Fake: 0.0156, \n",
      "Epoch [48/300], Step [20/234], D Loss: 0.0536, G Loss: 4.9178; D Loss Real: 0.0436, ; D Loss Fake: 0.0100, \n",
      "Epoch [48/300], Step [40/234], D Loss: 0.0678, G Loss: 4.3657; D Loss Real: 0.0195, ; D Loss Fake: 0.0483, \n",
      "Epoch [48/300], Step [60/234], D Loss: 0.0861, G Loss: 7.4081; D Loss Real: 0.0859, ; D Loss Fake: 0.0002, \n",
      "Epoch [48/300], Step [80/234], D Loss: 0.0218, G Loss: 0.0090; D Loss Real: 0.0044, ; D Loss Fake: 0.0174, \n",
      "Epoch [48/300], Step [100/234], D Loss: 0.0125, G Loss: 7.9179; D Loss Real: 0.0123, ; D Loss Fake: 0.0002, \n",
      "Epoch [48/300], Step [120/234], D Loss: 0.0157, G Loss: 4.9961; D Loss Real: 0.0040, ; D Loss Fake: 0.0117, \n",
      "Epoch [48/300], Step [140/234], D Loss: 0.0046, G Loss: 0.0083; D Loss Real: 0.0024, ; D Loss Fake: 0.0022, \n",
      "Epoch [48/300], Step [160/234], D Loss: 0.0561, G Loss: 7.4811; D Loss Real: 0.0559, ; D Loss Fake: 0.0002, \n",
      "Epoch [48/300], Step [180/234], D Loss: 0.0642, G Loss: 4.8442; D Loss Real: 0.0087, ; D Loss Fake: 0.0555, \n",
      "Epoch [48/300], Step [200/234], D Loss: 0.0124, G Loss: 0.0014; D Loss Real: 0.0122, ; D Loss Fake: 0.0003, \n",
      "Epoch [48/300], Step [220/234], D Loss: 0.0369, G Loss: 4.9711; D Loss Real: 0.0268, ; D Loss Fake: 0.0100, \n",
      "Epoch [49/300], Step [20/234], D Loss: 0.0392, G Loss: 7.0439; D Loss Real: 0.0009, ; D Loss Fake: 0.0383, \n",
      "Epoch [49/300], Step [40/234], D Loss: 0.0037, G Loss: 6.7552; D Loss Real: 0.0023, ; D Loss Fake: 0.0013, \n",
      "Epoch [49/300], Step [60/234], D Loss: 0.1191, G Loss: 8.7779; D Loss Real: 0.1141, ; D Loss Fake: 0.0050, \n",
      "Epoch [49/300], Step [80/234], D Loss: 0.0944, G Loss: 6.2534; D Loss Real: 0.0915, ; D Loss Fake: 0.0029, \n",
      "Epoch [49/300], Step [100/234], D Loss: 0.0444, G Loss: 5.0766; D Loss Real: 0.0043, ; D Loss Fake: 0.0401, \n",
      "Epoch [49/300], Step [120/234], D Loss: 0.0292, G Loss: 5.7808; D Loss Real: 0.0040, ; D Loss Fake: 0.0253, \n",
      "Epoch [49/300], Step [140/234], D Loss: 0.4615, G Loss: 0.0065; D Loss Real: 0.0056, ; D Loss Fake: 0.4559, \n",
      "Epoch [49/300], Step [160/234], D Loss: 0.0396, G Loss: 8.3107; D Loss Real: 0.0393, ; D Loss Fake: 0.0003, \n",
      "Epoch [49/300], Step [180/234], D Loss: 0.0178, G Loss: 0.0025; D Loss Real: 0.0034, ; D Loss Fake: 0.0144, \n",
      "Epoch [49/300], Step [200/234], D Loss: 0.0576, G Loss: 4.6219; D Loss Real: 0.0362, ; D Loss Fake: 0.0214, \n",
      "Epoch [49/300], Step [220/234], D Loss: 0.0748, G Loss: 4.9914; D Loss Real: 0.0602, ; D Loss Fake: 0.0146, \n",
      "Epoch [50/300], Step [20/234], D Loss: 0.0107, G Loss: 6.3485; D Loss Real: 0.0016, ; D Loss Fake: 0.0091, \n",
      "Epoch [50/300], Step [40/234], D Loss: 0.0222, G Loss: 4.2092; D Loss Real: 0.0005, ; D Loss Fake: 0.0216, \n",
      "Epoch [50/300], Step [60/234], D Loss: 0.0088, G Loss: 10.6026; D Loss Real: 0.0088, ; D Loss Fake: 0.0000, \n",
      "Epoch [50/300], Step [80/234], D Loss: 0.0274, G Loss: 5.1840; D Loss Real: 0.0040, ; D Loss Fake: 0.0234, \n",
      "Epoch [50/300], Step [100/234], D Loss: 0.1330, G Loss: 6.1626; D Loss Real: 0.0013, ; D Loss Fake: 0.1317, \n",
      "Epoch [50/300], Step [120/234], D Loss: 0.0126, G Loss: 6.8995; D Loss Real: 0.0117, ; D Loss Fake: 0.0009, \n",
      "Epoch [50/300], Step [140/234], D Loss: 0.0746, G Loss: 7.8879; D Loss Real: 0.0742, ; D Loss Fake: 0.0004, \n",
      "Epoch [50/300], Step [160/234], D Loss: 0.0829, G Loss: 4.6536; D Loss Real: 0.0081, ; D Loss Fake: 0.0748, \n",
      "Epoch [50/300], Step [180/234], D Loss: 0.0403, G Loss: 5.3025; D Loss Real: 0.0028, ; D Loss Fake: 0.0375, \n",
      "Epoch [50/300], Step [200/234], D Loss: 0.0121, G Loss: 0.0162; D Loss Real: 0.0121, ; D Loss Fake: 0.0000, \n",
      "Epoch [50/300], Step [220/234], D Loss: 0.0037, G Loss: 7.9667; D Loss Real: 0.0035, ; D Loss Fake: 0.0002, \n",
      "Epoch [51/300], Step [20/234], D Loss: 0.0517, G Loss: 5.0675; D Loss Real: 0.0033, ; D Loss Fake: 0.0484, \n",
      "Epoch [51/300], Step [40/234], D Loss: 0.0219, G Loss: 0.0089; D Loss Real: 0.0015, ; D Loss Fake: 0.0204, \n",
      "Epoch [51/300], Step [60/234], D Loss: 0.0038, G Loss: 8.5180; D Loss Real: 0.0037, ; D Loss Fake: 0.0001, \n",
      "Epoch [51/300], Step [80/234], D Loss: 0.0088, G Loss: 8.9754; D Loss Real: 0.0085, ; D Loss Fake: 0.0003, \n",
      "Epoch [51/300], Step [100/234], D Loss: 0.0313, G Loss: 5.6228; D Loss Real: 0.0180, ; D Loss Fake: 0.0133, \n",
      "Epoch [51/300], Step [120/234], D Loss: 0.0048, G Loss: -0.0019; D Loss Real: 0.0004, ; D Loss Fake: 0.0044, \n",
      "Epoch [51/300], Step [140/234], D Loss: 0.0019, G Loss: 6.3605; D Loss Real: 0.0005, ; D Loss Fake: 0.0015, \n",
      "Epoch [51/300], Step [160/234], D Loss: 0.0025, G Loss: 6.9733; D Loss Real: 0.0020, ; D Loss Fake: 0.0005, \n",
      "Epoch [51/300], Step [180/234], D Loss: 0.0134, G Loss: 6.7303; D Loss Real: 0.0126, ; D Loss Fake: 0.0009, \n",
      "Epoch [51/300], Step [200/234], D Loss: 0.0158, G Loss: 6.9418; D Loss Real: 0.0152, ; D Loss Fake: 0.0006, \n",
      "Epoch [51/300], Step [220/234], D Loss: 0.0024, G Loss: 7.0978; D Loss Real: 0.0012, ; D Loss Fake: 0.0012, \n",
      "Epoch [52/300], Step [20/234], D Loss: 0.0032, G Loss: -0.0046; D Loss Real: 0.0012, ; D Loss Fake: 0.0020, \n",
      "Epoch [52/300], Step [40/234], D Loss: 0.0494, G Loss: 9.6921; D Loss Real: 0.0494, ; D Loss Fake: 0.0001, \n",
      "Epoch [52/300], Step [60/234], D Loss: 0.0077, G Loss: 5.8543; D Loss Real: 0.0002, ; D Loss Fake: 0.0075, \n",
      "Epoch [52/300], Step [80/234], D Loss: 0.0155, G Loss: 6.3211; D Loss Real: 0.0142, ; D Loss Fake: 0.0013, \n",
      "Epoch [52/300], Step [100/234], D Loss: 0.0004, G Loss: 12.0008; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [52/300], Step [120/234], D Loss: 0.0245, G Loss: 8.1676; D Loss Real: 0.0244, ; D Loss Fake: 0.0001, \n",
      "Epoch [52/300], Step [140/234], D Loss: 0.1349, G Loss: -0.0160; D Loss Real: 0.0110, ; D Loss Fake: 0.1239, \n",
      "Epoch [52/300], Step [160/234], D Loss: 0.0006, G Loss: 8.9209; D Loss Real: 0.0005, ; D Loss Fake: 0.0001, \n",
      "Epoch [52/300], Step [180/234], D Loss: 0.0236, G Loss: 5.4942; D Loss Real: 0.0005, ; D Loss Fake: 0.0231, \n",
      "Epoch [52/300], Step [200/234], D Loss: 0.0272, G Loss: 4.8140; D Loss Real: 0.0064, ; D Loss Fake: 0.0208, \n",
      "Epoch [52/300], Step [220/234], D Loss: 0.0917, G Loss: 12.5204; D Loss Real: 0.0917, ; D Loss Fake: 0.0000, \n",
      "Epoch [53/300], Step [20/234], D Loss: 0.2384, G Loss: 5.8240; D Loss Real: 0.2380, ; D Loss Fake: 0.0004, \n",
      "Epoch [53/300], Step [40/234], D Loss: 0.0134, G Loss: 5.6943; D Loss Real: 0.0087, ; D Loss Fake: 0.0048, \n",
      "Epoch [53/300], Step [60/234], D Loss: 0.0238, G Loss: 6.6517; D Loss Real: 0.0011, ; D Loss Fake: 0.0227, \n",
      "Epoch [53/300], Step [80/234], D Loss: 0.0282, G Loss: 0.0014; D Loss Real: 0.0102, ; D Loss Fake: 0.0179, \n",
      "Epoch [53/300], Step [100/234], D Loss: 0.0064, G Loss: 6.4069; D Loss Real: 0.0040, ; D Loss Fake: 0.0024, \n",
      "Epoch [53/300], Step [120/234], D Loss: 0.0215, G Loss: 12.2238; D Loss Real: 0.0214, ; D Loss Fake: 0.0001, \n",
      "Epoch [53/300], Step [140/234], D Loss: 0.0401, G Loss: 5.5740; D Loss Real: 0.0037, ; D Loss Fake: 0.0364, \n",
      "Epoch [53/300], Step [160/234], D Loss: 0.1878, G Loss: 5.1565; D Loss Real: 0.0314, ; D Loss Fake: 0.1564, \n",
      "Epoch [53/300], Step [180/234], D Loss: 0.2721, G Loss: 12.7170; D Loss Real: 0.2721, ; D Loss Fake: 0.0000, \n",
      "Epoch [53/300], Step [200/234], D Loss: 0.0027, G Loss: 0.0017; D Loss Real: 0.0012, ; D Loss Fake: 0.0015, \n",
      "Epoch [53/300], Step [220/234], D Loss: 0.0390, G Loss: 5.9093; D Loss Real: 0.0029, ; D Loss Fake: 0.0361, \n",
      "Epoch [54/300], Step [20/234], D Loss: 0.0566, G Loss: 4.5071; D Loss Real: 0.0148, ; D Loss Fake: 0.0418, \n",
      "Epoch [54/300], Step [40/234], D Loss: 0.0196, G Loss: 6.5654; D Loss Real: 0.0185, ; D Loss Fake: 0.0010, \n",
      "Epoch [54/300], Step [60/234], D Loss: 0.0044, G Loss: 9.1374; D Loss Real: 0.0043, ; D Loss Fake: 0.0001, \n",
      "Epoch [54/300], Step [80/234], D Loss: 0.0730, G Loss: 12.5659; D Loss Real: 0.0730, ; D Loss Fake: 0.0000, \n",
      "Epoch [54/300], Step [100/234], D Loss: 0.0776, G Loss: 5.3056; D Loss Real: 0.0036, ; D Loss Fake: 0.0740, \n",
      "Epoch [54/300], Step [120/234], D Loss: 0.0011, G Loss: 7.5502; D Loss Real: 0.0002, ; D Loss Fake: 0.0009, \n",
      "Epoch [54/300], Step [140/234], D Loss: 0.0145, G Loss: 0.0136; D Loss Real: 0.0135, ; D Loss Fake: 0.0011, \n",
      "Epoch [54/300], Step [160/234], D Loss: 0.0698, G Loss: 6.3099; D Loss Real: 0.0677, ; D Loss Fake: 0.0021, \n",
      "Epoch [54/300], Step [180/234], D Loss: 0.0182, G Loss: 4.9503; D Loss Real: 0.0011, ; D Loss Fake: 0.0171, \n",
      "Epoch [54/300], Step [200/234], D Loss: 0.1684, G Loss: 11.1934; D Loss Real: 0.1684, ; D Loss Fake: 0.0000, \n",
      "Epoch [54/300], Step [220/234], D Loss: 0.3019, G Loss: 7.4717; D Loss Real: 0.0103, ; D Loss Fake: 0.2916, \n",
      "Epoch [55/300], Step [20/234], D Loss: 0.0352, G Loss: 0.0129; D Loss Real: 0.0060, ; D Loss Fake: 0.0292, \n",
      "Epoch [55/300], Step [40/234], D Loss: 0.0391, G Loss: 13.0315; D Loss Real: 0.0391, ; D Loss Fake: 0.0000, \n",
      "Epoch [55/300], Step [60/234], D Loss: 0.0057, G Loss: 7.8590; D Loss Real: 0.0053, ; D Loss Fake: 0.0004, \n",
      "Epoch [55/300], Step [80/234], D Loss: 0.0117, G Loss: 5.0223; D Loss Real: 0.0031, ; D Loss Fake: 0.0086, \n",
      "Epoch [55/300], Step [100/234], D Loss: 0.0107, G Loss: 11.1147; D Loss Real: 0.0106, ; D Loss Fake: 0.0001, \n",
      "Epoch [55/300], Step [120/234], D Loss: 0.0879, G Loss: 0.0071; D Loss Real: 0.0007, ; D Loss Fake: 0.0872, \n",
      "Epoch [55/300], Step [140/234], D Loss: 0.1150, G Loss: 7.9735; D Loss Real: 0.1149, ; D Loss Fake: 0.0001, \n",
      "Epoch [55/300], Step [160/234], D Loss: 0.1874, G Loss: 4.1805; D Loss Real: 0.1115, ; D Loss Fake: 0.0759, \n",
      "Epoch [55/300], Step [180/234], D Loss: 0.2095, G Loss: 5.5731; D Loss Real: 0.0147, ; D Loss Fake: 0.1947, \n",
      "Epoch [55/300], Step [200/234], D Loss: 0.0480, G Loss: 4.3898; D Loss Real: 0.0048, ; D Loss Fake: 0.0431, \n",
      "Epoch [55/300], Step [220/234], D Loss: 0.0028, G Loss: 10.9261; D Loss Real: 0.0028, ; D Loss Fake: 0.0000, \n",
      "Epoch [56/300], Step [20/234], D Loss: 0.0592, G Loss: 16.8959; D Loss Real: 0.0592, ; D Loss Fake: 0.0000, \n",
      "Epoch [56/300], Step [40/234], D Loss: 0.0360, G Loss: 4.9431; D Loss Real: 0.0006, ; D Loss Fake: 0.0353, \n",
      "Epoch [56/300], Step [60/234], D Loss: 0.3428, G Loss: 8.6270; D Loss Real: 0.0178, ; D Loss Fake: 0.3250, \n",
      "Epoch [56/300], Step [80/234], D Loss: 0.0299, G Loss: 10.2566; D Loss Real: 0.0299, ; D Loss Fake: 0.0000, \n",
      "Epoch [56/300], Step [100/234], D Loss: 0.0081, G Loss: 9.9611; D Loss Real: 0.0080, ; D Loss Fake: 0.0001, \n",
      "Epoch [56/300], Step [120/234], D Loss: 0.0015, G Loss: 6.9924; D Loss Real: 0.0006, ; D Loss Fake: 0.0008, \n",
      "Epoch [56/300], Step [140/234], D Loss: 0.0256, G Loss: 4.8594; D Loss Real: 0.0025, ; D Loss Fake: 0.0231, \n",
      "Epoch [56/300], Step [160/234], D Loss: 0.0050, G Loss: 6.9108; D Loss Real: 0.0042, ; D Loss Fake: 0.0007, \n",
      "Epoch [56/300], Step [180/234], D Loss: 0.0130, G Loss: 8.8248; D Loss Real: 0.0129, ; D Loss Fake: 0.0001, \n",
      "Epoch [56/300], Step [200/234], D Loss: 0.0046, G Loss: 0.0088; D Loss Real: 0.0042, ; D Loss Fake: 0.0004, \n",
      "Epoch [56/300], Step [220/234], D Loss: 0.3405, G Loss: -0.0128; D Loss Real: 0.0007, ; D Loss Fake: 0.3399, \n",
      "Epoch [57/300], Step [20/234], D Loss: 0.0005, G Loss: 11.7325; D Loss Real: 0.0005, ; D Loss Fake: 0.0000, \n",
      "Epoch [57/300], Step [40/234], D Loss: 0.0252, G Loss: 5.5395; D Loss Real: 0.0216, ; D Loss Fake: 0.0036, \n",
      "Epoch [57/300], Step [60/234], D Loss: 0.0331, G Loss: 4.2489; D Loss Real: 0.0192, ; D Loss Fake: 0.0139, \n",
      "Epoch [57/300], Step [80/234], D Loss: 0.0189, G Loss: 4.8000; D Loss Real: 0.0094, ; D Loss Fake: 0.0095, \n",
      "Epoch [57/300], Step [100/234], D Loss: 0.0064, G Loss: 8.0768; D Loss Real: 0.0062, ; D Loss Fake: 0.0002, \n",
      "Epoch [57/300], Step [120/234], D Loss: 0.0113, G Loss: 5.4133; D Loss Real: 0.0093, ; D Loss Fake: 0.0021, \n",
      "Epoch [57/300], Step [140/234], D Loss: 0.0257, G Loss: -0.0004; D Loss Real: 0.0244, ; D Loss Fake: 0.0013, \n",
      "Epoch [57/300], Step [160/234], D Loss: 0.0110, G Loss: 6.5009; D Loss Real: 0.0082, ; D Loss Fake: 0.0029, \n",
      "Epoch [57/300], Step [180/234], D Loss: 0.0027, G Loss: 6.2229; D Loss Real: 0.0005, ; D Loss Fake: 0.0023, \n",
      "Epoch [57/300], Step [200/234], D Loss: 0.0403, G Loss: 4.3297; D Loss Real: 0.0289, ; D Loss Fake: 0.0114, \n",
      "Epoch [57/300], Step [220/234], D Loss: 0.0011, G Loss: 0.0042; D Loss Real: 0.0011, ; D Loss Fake: 0.0000, \n",
      "Epoch [58/300], Step [20/234], D Loss: 0.0252, G Loss: 7.8754; D Loss Real: 0.0243, ; D Loss Fake: 0.0009, \n",
      "Epoch [58/300], Step [40/234], D Loss: 0.1218, G Loss: 5.1701; D Loss Real: 0.0379, ; D Loss Fake: 0.0839, \n",
      "Epoch [58/300], Step [60/234], D Loss: 0.0132, G Loss: 6.1301; D Loss Real: 0.0065, ; D Loss Fake: 0.0068, \n",
      "Epoch [58/300], Step [80/234], D Loss: 0.0041, G Loss: -0.0008; D Loss Real: 0.0013, ; D Loss Fake: 0.0028, \n",
      "Epoch [58/300], Step [100/234], D Loss: 0.0069, G Loss: 6.5935; D Loss Real: 0.0056, ; D Loss Fake: 0.0013, \n",
      "Epoch [58/300], Step [120/234], D Loss: 0.0070, G Loss: 5.1468; D Loss Real: 0.0008, ; D Loss Fake: 0.0062, \n",
      "Epoch [58/300], Step [140/234], D Loss: 0.0429, G Loss: 4.3535; D Loss Real: 0.0063, ; D Loss Fake: 0.0366, \n",
      "Epoch [58/300], Step [160/234], D Loss: 0.0016, G Loss: 7.2829; D Loss Real: 0.0010, ; D Loss Fake: 0.0005, \n",
      "Epoch [58/300], Step [180/234], D Loss: 0.0011, G Loss: 8.6023; D Loss Real: 0.0009, ; D Loss Fake: 0.0002, \n",
      "Epoch [58/300], Step [200/234], D Loss: 0.0020, G Loss: 10.9062; D Loss Real: 0.0018, ; D Loss Fake: 0.0002, \n",
      "Epoch [58/300], Step [220/234], D Loss: 0.0282, G Loss: 4.8811; D Loss Real: 0.0162, ; D Loss Fake: 0.0120, \n",
      "Epoch [59/300], Step [20/234], D Loss: 0.0421, G Loss: 4.5036; D Loss Real: 0.0002, ; D Loss Fake: 0.0419, \n",
      "Epoch [59/300], Step [40/234], D Loss: 0.0167, G Loss: 6.8676; D Loss Real: 0.0153, ; D Loss Fake: 0.0013, \n",
      "Epoch [59/300], Step [60/234], D Loss: 0.0081, G Loss: 6.6887; D Loss Real: 0.0011, ; D Loss Fake: 0.0070, \n",
      "Epoch [59/300], Step [80/234], D Loss: 0.0107, G Loss: 6.1259; D Loss Real: 0.0015, ; D Loss Fake: 0.0092, \n",
      "Epoch [59/300], Step [100/234], D Loss: 0.0002, G Loss: 11.3165; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [59/300], Step [120/234], D Loss: 0.1132, G Loss: 5.5151; D Loss Real: 0.0314, ; D Loss Fake: 0.0818, \n",
      "Epoch [59/300], Step [140/234], D Loss: 0.0430, G Loss: 5.1387; D Loss Real: 0.0014, ; D Loss Fake: 0.0416, \n",
      "Epoch [59/300], Step [160/234], D Loss: 0.0315, G Loss: 4.6332; D Loss Real: 0.0220, ; D Loss Fake: 0.0096, \n",
      "Epoch [59/300], Step [180/234], D Loss: 0.0075, G Loss: 8.3771; D Loss Real: 0.0073, ; D Loss Fake: 0.0002, \n",
      "Epoch [59/300], Step [200/234], D Loss: 0.0023, G Loss: 7.0170; D Loss Real: 0.0015, ; D Loss Fake: 0.0007, \n",
      "Epoch [59/300], Step [220/234], D Loss: 0.0006, G Loss: 10.4020; D Loss Real: 0.0006, ; D Loss Fake: 0.0000, \n",
      "Epoch [60/300], Step [20/234], D Loss: 0.0026, G Loss: 7.6793; D Loss Real: 0.0023, ; D Loss Fake: 0.0004, \n",
      "Epoch [60/300], Step [40/234], D Loss: 0.0877, G Loss: 6.2119; D Loss Real: 0.0005, ; D Loss Fake: 0.0873, \n",
      "Epoch [60/300], Step [60/234], D Loss: 0.0483, G Loss: 10.9661; D Loss Real: 0.0478, ; D Loss Fake: 0.0006, \n",
      "Epoch [60/300], Step [80/234], D Loss: 0.4081, G Loss: 8.4372; D Loss Real: 0.4072, ; D Loss Fake: 0.0008, \n",
      "Epoch [60/300], Step [100/234], D Loss: 0.0675, G Loss: 5.8233; D Loss Real: 0.0655, ; D Loss Fake: 0.0020, \n",
      "Epoch [60/300], Step [120/234], D Loss: 0.0094, G Loss: 6.1105; D Loss Real: 0.0010, ; D Loss Fake: 0.0084, \n",
      "Epoch [60/300], Step [140/234], D Loss: 0.0020, G Loss: 7.5948; D Loss Real: 0.0013, ; D Loss Fake: 0.0007, \n",
      "Epoch [60/300], Step [160/234], D Loss: 0.0489, G Loss: 5.2088; D Loss Real: 0.0015, ; D Loss Fake: 0.0474, \n",
      "Epoch [60/300], Step [180/234], D Loss: 0.0678, G Loss: 9.3649; D Loss Real: 0.0672, ; D Loss Fake: 0.0007, \n",
      "Epoch [60/300], Step [200/234], D Loss: 0.1891, G Loss: 7.4421; D Loss Real: 0.0014, ; D Loss Fake: 0.1877, \n",
      "Epoch [60/300], Step [220/234], D Loss: 0.0105, G Loss: 0.0019; D Loss Real: 0.0011, ; D Loss Fake: 0.0095, \n",
      "Epoch [61/300], Step [20/234], D Loss: 0.0010, G Loss: 7.1631; D Loss Real: 0.0005, ; D Loss Fake: 0.0005, \n",
      "Epoch [61/300], Step [40/234], D Loss: 0.0279, G Loss: 9.5431; D Loss Real: 0.0278, ; D Loss Fake: 0.0000, \n",
      "Epoch [61/300], Step [60/234], D Loss: 0.2041, G Loss: 10.0949; D Loss Real: 0.2041, ; D Loss Fake: 0.0000, \n",
      "Epoch [61/300], Step [80/234], D Loss: 0.0081, G Loss: 13.6950; D Loss Real: 0.0081, ; D Loss Fake: 0.0000, \n",
      "Epoch [61/300], Step [100/234], D Loss: 0.0290, G Loss: 8.8689; D Loss Real: 0.0290, ; D Loss Fake: 0.0001, \n",
      "Epoch [61/300], Step [120/234], D Loss: 0.0051, G Loss: 5.8329; D Loss Real: 0.0015, ; D Loss Fake: 0.0036, \n",
      "Epoch [61/300], Step [140/234], D Loss: 0.0741, G Loss: 5.8020; D Loss Real: 0.0008, ; D Loss Fake: 0.0733, \n",
      "Epoch [61/300], Step [160/234], D Loss: 0.0686, G Loss: 4.7283; D Loss Real: 0.0592, ; D Loss Fake: 0.0095, \n",
      "Epoch [61/300], Step [180/234], D Loss: 0.0519, G Loss: 4.6980; D Loss Real: 0.0002, ; D Loss Fake: 0.0517, \n",
      "Epoch [61/300], Step [200/234], D Loss: 0.0072, G Loss: 6.1208; D Loss Real: 0.0009, ; D Loss Fake: 0.0063, \n",
      "Epoch [61/300], Step [220/234], D Loss: 0.0020, G Loss: 13.2909; D Loss Real: 0.0020, ; D Loss Fake: 0.0000, \n",
      "Epoch [62/300], Step [20/234], D Loss: 0.0048, G Loss: 5.4754; D Loss Real: 0.0010, ; D Loss Fake: 0.0038, \n",
      "Epoch [62/300], Step [40/234], D Loss: 0.0685, G Loss: 4.8240; D Loss Real: 0.0030, ; D Loss Fake: 0.0655, \n",
      "Epoch [62/300], Step [60/234], D Loss: 0.0191, G Loss: 4.7678; D Loss Real: 0.0138, ; D Loss Fake: 0.0054, \n",
      "Epoch [62/300], Step [80/234], D Loss: 0.0195, G Loss: 4.4884; D Loss Real: 0.0012, ; D Loss Fake: 0.0183, \n",
      "Epoch [62/300], Step [100/234], D Loss: 0.2839, G Loss: 20.3851; D Loss Real: 0.2839, ; D Loss Fake: -0.0000, \n",
      "Epoch [62/300], Step [120/234], D Loss: 0.0079, G Loss: 7.2180; D Loss Real: 0.0063, ; D Loss Fake: 0.0016, \n",
      "Epoch [62/300], Step [140/234], D Loss: 0.0270, G Loss: 10.8292; D Loss Real: 0.0270, ; D Loss Fake: 0.0000, \n",
      "Epoch [62/300], Step [160/234], D Loss: 0.0056, G Loss: 11.7784; D Loss Real: 0.0056, ; D Loss Fake: 0.0000, \n",
      "Epoch [62/300], Step [180/234], D Loss: 0.0142, G Loss: 6.7979; D Loss Real: 0.0095, ; D Loss Fake: 0.0046, \n",
      "Epoch [62/300], Step [200/234], D Loss: 0.0054, G Loss: 5.5044; D Loss Real: 0.0043, ; D Loss Fake: 0.0011, \n",
      "Epoch [62/300], Step [220/234], D Loss: 0.0015, G Loss: 7.9498; D Loss Real: 0.0011, ; D Loss Fake: 0.0004, \n",
      "Epoch [63/300], Step [20/234], D Loss: 0.0143, G Loss: 4.8039; D Loss Real: 0.0010, ; D Loss Fake: 0.0133, \n",
      "Epoch [63/300], Step [40/234], D Loss: 0.0011, G Loss: 12.3090; D Loss Real: 0.0010, ; D Loss Fake: 0.0000, \n",
      "Epoch [63/300], Step [60/234], D Loss: 0.0045, G Loss: -0.0075; D Loss Real: 0.0029, ; D Loss Fake: 0.0016, \n",
      "Epoch [63/300], Step [80/234], D Loss: 1.4045, G Loss: 15.3310; D Loss Real: 0.0000, ; D Loss Fake: 1.4045, \n",
      "Epoch [63/300], Step [100/234], D Loss: 0.0064, G Loss: 8.4271; D Loss Real: 0.0051, ; D Loss Fake: 0.0013, \n",
      "Epoch [63/300], Step [120/234], D Loss: 0.0191, G Loss: 8.3989; D Loss Real: 0.0189, ; D Loss Fake: 0.0002, \n",
      "Epoch [63/300], Step [140/234], D Loss: 0.0326, G Loss: 4.7803; D Loss Real: 0.0240, ; D Loss Fake: 0.0087, \n",
      "Epoch [63/300], Step [160/234], D Loss: 0.0026, G Loss: 10.8660; D Loss Real: 0.0026, ; D Loss Fake: 0.0000, \n",
      "Epoch [63/300], Step [180/234], D Loss: 0.0267, G Loss: 10.1414; D Loss Real: 0.0265, ; D Loss Fake: 0.0002, \n",
      "Epoch [63/300], Step [200/234], D Loss: 0.0009, G Loss: 8.2915; D Loss Real: 0.0004, ; D Loss Fake: 0.0005, \n",
      "Epoch [63/300], Step [220/234], D Loss: 0.0005, G Loss: 9.0021; D Loss Real: 0.0004, ; D Loss Fake: 0.0001, \n",
      "Epoch [64/300], Step [20/234], D Loss: 0.0114, G Loss: 7.6342; D Loss Real: 0.0087, ; D Loss Fake: 0.0026, \n",
      "Epoch [64/300], Step [40/234], D Loss: 0.1576, G Loss: 12.5074; D Loss Real: 0.1576, ; D Loss Fake: 0.0000, \n",
      "Epoch [64/300], Step [60/234], D Loss: 0.0639, G Loss: 5.1388; D Loss Real: 0.0587, ; D Loss Fake: 0.0051, \n",
      "Epoch [64/300], Step [80/234], D Loss: 0.0033, G Loss: 7.7448; D Loss Real: 0.0024, ; D Loss Fake: 0.0009, \n",
      "Epoch [64/300], Step [100/234], D Loss: 0.0609, G Loss: 0.0150; D Loss Real: 0.0030, ; D Loss Fake: 0.0579, \n",
      "Epoch [64/300], Step [120/234], D Loss: 0.0054, G Loss: 4.7470; D Loss Real: 0.0003, ; D Loss Fake: 0.0051, \n",
      "Epoch [64/300], Step [140/234], D Loss: 0.0174, G Loss: 4.7327; D Loss Real: 0.0013, ; D Loss Fake: 0.0161, \n",
      "Epoch [64/300], Step [160/234], D Loss: 0.0182, G Loss: 5.6574; D Loss Real: 0.0142, ; D Loss Fake: 0.0040, \n",
      "Epoch [64/300], Step [180/234], D Loss: 0.2170, G Loss: 7.6680; D Loss Real: 0.0008, ; D Loss Fake: 0.2162, \n",
      "Epoch [64/300], Step [200/234], D Loss: 0.0869, G Loss: 5.6841; D Loss Real: 0.0024, ; D Loss Fake: 0.0844, \n",
      "Epoch [64/300], Step [220/234], D Loss: 0.0196, G Loss: 6.5707; D Loss Real: 0.0185, ; D Loss Fake: 0.0011, \n",
      "Epoch [65/300], Step [20/234], D Loss: 0.0408, G Loss: 12.9089; D Loss Real: 0.0408, ; D Loss Fake: 0.0000, \n",
      "Epoch [65/300], Step [40/234], D Loss: 0.0117, G Loss: 8.8452; D Loss Real: 0.0116, ; D Loss Fake: 0.0001, \n",
      "Epoch [65/300], Step [60/234], D Loss: 0.0031, G Loss: 14.3542; D Loss Real: 0.0031, ; D Loss Fake: 0.0000, \n",
      "Epoch [65/300], Step [80/234], D Loss: 0.0028, G Loss: 6.2055; D Loss Real: 0.0009, ; D Loss Fake: 0.0019, \n",
      "Epoch [65/300], Step [100/234], D Loss: 0.0007, G Loss: 8.4255; D Loss Real: 0.0005, ; D Loss Fake: 0.0002, \n",
      "Epoch [65/300], Step [120/234], D Loss: 0.0076, G Loss: 5.2364; D Loss Real: 0.0007, ; D Loss Fake: 0.0069, \n",
      "Epoch [65/300], Step [140/234], D Loss: 0.0051, G Loss: 11.1728; D Loss Real: 0.0051, ; D Loss Fake: 0.0000, \n",
      "Epoch [65/300], Step [160/234], D Loss: 0.0010, G Loss: 7.7263; D Loss Real: 0.0007, ; D Loss Fake: 0.0003, \n",
      "Epoch [65/300], Step [180/234], D Loss: 0.0073, G Loss: 5.6816; D Loss Real: 0.0040, ; D Loss Fake: 0.0033, \n",
      "Epoch [65/300], Step [200/234], D Loss: 0.0073, G Loss: 0.0003; D Loss Real: 0.0073, ; D Loss Fake: 0.0001, \n",
      "Epoch [65/300], Step [220/234], D Loss: 0.0126, G Loss: 6.5211; D Loss Real: 0.0118, ; D Loss Fake: 0.0008, \n",
      "Epoch [66/300], Step [20/234], D Loss: 0.2899, G Loss: 8.5520; D Loss Real: 0.0108, ; D Loss Fake: 0.2790, \n",
      "Epoch [66/300], Step [40/234], D Loss: 0.0145, G Loss: 6.1494; D Loss Real: 0.0100, ; D Loss Fake: 0.0045, \n",
      "Epoch [66/300], Step [60/234], D Loss: 0.0753, G Loss: 5.5206; D Loss Real: 0.0737, ; D Loss Fake: 0.0016, \n",
      "Epoch [66/300], Step [80/234], D Loss: 0.0051, G Loss: 5.5849; D Loss Real: 0.0003, ; D Loss Fake: 0.0049, \n",
      "Epoch [66/300], Step [100/234], D Loss: 0.0034, G Loss: -0.0038; D Loss Real: 0.0028, ; D Loss Fake: 0.0006, \n",
      "Epoch [66/300], Step [120/234], D Loss: 0.0006, G Loss: 10.6749; D Loss Real: 0.0006, ; D Loss Fake: 0.0000, \n",
      "Epoch [66/300], Step [140/234], D Loss: 0.0751, G Loss: 4.4087; D Loss Real: 0.0437, ; D Loss Fake: 0.0314, \n",
      "Epoch [66/300], Step [160/234], D Loss: 0.0049, G Loss: 5.5642; D Loss Real: 0.0023, ; D Loss Fake: 0.0026, \n",
      "Epoch [66/300], Step [180/234], D Loss: 0.0082, G Loss: 8.8594; D Loss Real: 0.0082, ; D Loss Fake: 0.0001, \n",
      "Epoch [66/300], Step [200/234], D Loss: 0.7073, G Loss: 13.6695; D Loss Real: 0.7073, ; D Loss Fake: 0.0000, \n",
      "Epoch [66/300], Step [220/234], D Loss: 0.2382, G Loss: 8.8636; D Loss Real: 0.0027, ; D Loss Fake: 0.2354, \n",
      "Epoch [67/300], Step [20/234], D Loss: 0.0014, G Loss: 12.4709; D Loss Real: 0.0014, ; D Loss Fake: 0.0000, \n",
      "Epoch [67/300], Step [40/234], D Loss: 0.3302, G Loss: 13.8207; D Loss Real: 0.3302, ; D Loss Fake: 0.0000, \n",
      "Epoch [67/300], Step [60/234], D Loss: 0.0332, G Loss: 10.3627; D Loss Real: 0.0332, ; D Loss Fake: 0.0001, \n",
      "Epoch [67/300], Step [80/234], D Loss: 0.0175, G Loss: -0.0083; D Loss Real: 0.0159, ; D Loss Fake: 0.0016, \n",
      "Epoch [67/300], Step [100/234], D Loss: 0.0035, G Loss: 6.4797; D Loss Real: 0.0017, ; D Loss Fake: 0.0019, \n",
      "Epoch [67/300], Step [120/234], D Loss: 0.0624, G Loss: 16.0825; D Loss Real: 0.0624, ; D Loss Fake: 0.0000, \n",
      "Epoch [67/300], Step [140/234], D Loss: 0.0115, G Loss: 6.2820; D Loss Real: 0.0098, ; D Loss Fake: 0.0016, \n",
      "Epoch [67/300], Step [160/234], D Loss: 0.0065, G Loss: 5.7896; D Loss Real: 0.0021, ; D Loss Fake: 0.0045, \n",
      "Epoch [67/300], Step [180/234], D Loss: 0.0021, G Loss: 7.6647; D Loss Real: 0.0009, ; D Loss Fake: 0.0013, \n",
      "Epoch [67/300], Step [200/234], D Loss: 0.0026, G Loss: 6.7970; D Loss Real: 0.0017, ; D Loss Fake: 0.0009, \n",
      "Epoch [67/300], Step [220/234], D Loss: 0.0494, G Loss: 4.7211; D Loss Real: 0.0013, ; D Loss Fake: 0.0481, \n",
      "Epoch [68/300], Step [20/234], D Loss: 0.1570, G Loss: 8.4431; D Loss Real: 0.1564, ; D Loss Fake: 0.0007, \n",
      "Epoch [68/300], Step [40/234], D Loss: 0.0175, G Loss: 0.0181; D Loss Real: 0.0172, ; D Loss Fake: 0.0002, \n",
      "Epoch [68/300], Step [60/234], D Loss: 0.0051, G Loss: 7.9512; D Loss Real: 0.0045, ; D Loss Fake: 0.0006, \n",
      "Epoch [68/300], Step [80/234], D Loss: 1.7785, G Loss: 8.7193; D Loss Real: 1.7785, ; D Loss Fake: 0.0000, \n",
      "Epoch [68/300], Step [100/234], D Loss: 1.3508, G Loss: 11.4689; D Loss Real: 0.0000, ; D Loss Fake: 1.3508, \n",
      "Epoch [68/300], Step [120/234], D Loss: 0.0188, G Loss: 5.3816; D Loss Real: 0.0032, ; D Loss Fake: 0.0156, \n",
      "Epoch [68/300], Step [140/234], D Loss: 0.0745, G Loss: 8.1800; D Loss Real: 0.0005, ; D Loss Fake: 0.0740, \n",
      "Epoch [68/300], Step [160/234], D Loss: 0.0322, G Loss: 6.2872; D Loss Real: 0.0283, ; D Loss Fake: 0.0039, \n",
      "Epoch [68/300], Step [180/234], D Loss: 0.0027, G Loss: 10.6125; D Loss Real: 0.0020, ; D Loss Fake: 0.0007, \n",
      "Epoch [68/300], Step [200/234], D Loss: 0.0445, G Loss: 4.5735; D Loss Real: 0.0160, ; D Loss Fake: 0.0285, \n",
      "Epoch [68/300], Step [220/234], D Loss: 0.0673, G Loss: 5.0364; D Loss Real: 0.0006, ; D Loss Fake: 0.0668, \n",
      "Epoch [69/300], Step [20/234], D Loss: 0.0124, G Loss: 9.0206; D Loss Real: 0.0124, ; D Loss Fake: 0.0001, \n",
      "Epoch [69/300], Step [40/234], D Loss: 0.0428, G Loss: 5.5895; D Loss Real: 0.0073, ; D Loss Fake: 0.0355, \n",
      "Epoch [69/300], Step [60/234], D Loss: 0.0669, G Loss: 5.0837; D Loss Real: 0.0633, ; D Loss Fake: 0.0036, \n",
      "Epoch [69/300], Step [80/234], D Loss: 0.1078, G Loss: 7.0801; D Loss Real: 0.1052, ; D Loss Fake: 0.0027, \n",
      "Epoch [69/300], Step [100/234], D Loss: 0.0117, G Loss: 7.2009; D Loss Real: 0.0109, ; D Loss Fake: 0.0009, \n",
      "Epoch [69/300], Step [120/234], D Loss: 0.0529, G Loss: 10.0948; D Loss Real: 0.0529, ; D Loss Fake: 0.0000, \n",
      "Epoch [69/300], Step [140/234], D Loss: 0.0275, G Loss: 5.7705; D Loss Real: 0.0031, ; D Loss Fake: 0.0243, \n",
      "Epoch [69/300], Step [160/234], D Loss: 0.0038, G Loss: 10.4482; D Loss Real: 0.0038, ; D Loss Fake: 0.0000, \n",
      "Epoch [69/300], Step [180/234], D Loss: 0.0123, G Loss: 8.1781; D Loss Real: 0.0113, ; D Loss Fake: 0.0010, \n",
      "Epoch [69/300], Step [200/234], D Loss: 0.0269, G Loss: 6.1814; D Loss Real: 0.0258, ; D Loss Fake: 0.0011, \n",
      "Epoch [69/300], Step [220/234], D Loss: 0.0045, G Loss: 5.9809; D Loss Real: 0.0028, ; D Loss Fake: 0.0017, \n",
      "Epoch [70/300], Step [20/234], D Loss: 0.0522, G Loss: 6.5336; D Loss Real: 0.0441, ; D Loss Fake: 0.0081, \n",
      "Epoch [70/300], Step [40/234], D Loss: 0.0848, G Loss: 5.8742; D Loss Real: 0.0030, ; D Loss Fake: 0.0818, \n",
      "Epoch [70/300], Step [60/234], D Loss: 0.0053, G Loss: 6.8697; D Loss Real: 0.0047, ; D Loss Fake: 0.0006, \n",
      "Epoch [70/300], Step [80/234], D Loss: 0.0087, G Loss: 6.5457; D Loss Real: 0.0073, ; D Loss Fake: 0.0013, \n",
      "Epoch [70/300], Step [100/234], D Loss: 0.0106, G Loss: 6.3805; D Loss Real: 0.0065, ; D Loss Fake: 0.0041, \n",
      "Epoch [70/300], Step [120/234], D Loss: 0.0116, G Loss: 7.7585; D Loss Real: 0.0112, ; D Loss Fake: 0.0004, \n",
      "Epoch [70/300], Step [140/234], D Loss: 0.0241, G Loss: 20.6364; D Loss Real: 0.0241, ; D Loss Fake: -0.0000, \n",
      "Epoch [70/300], Step [160/234], D Loss: 0.0250, G Loss: 4.4705; D Loss Real: 0.0032, ; D Loss Fake: 0.0218, \n",
      "Epoch [70/300], Step [180/234], D Loss: 0.0043, G Loss: 6.2674; D Loss Real: 0.0024, ; D Loss Fake: 0.0018, \n",
      "Epoch [70/300], Step [200/234], D Loss: 0.0109, G Loss: 7.2286; D Loss Real: 0.0094, ; D Loss Fake: 0.0015, \n",
      "Epoch [70/300], Step [220/234], D Loss: 0.0202, G Loss: 4.6441; D Loss Real: 0.0079, ; D Loss Fake: 0.0123, \n",
      "Epoch [71/300], Step [20/234], D Loss: 0.0321, G Loss: 6.5848; D Loss Real: 0.0314, ; D Loss Fake: 0.0008, \n",
      "Epoch [71/300], Step [40/234], D Loss: 0.0021, G Loss: 16.2780; D Loss Real: 0.0021, ; D Loss Fake: 0.0000, \n",
      "Epoch [71/300], Step [60/234], D Loss: 0.0437, G Loss: 7.9295; D Loss Real: 0.0432, ; D Loss Fake: 0.0005, \n",
      "Epoch [71/300], Step [80/234], D Loss: 0.0070, G Loss: 9.1957; D Loss Real: 0.0065, ; D Loss Fake: 0.0005, \n",
      "Epoch [71/300], Step [100/234], D Loss: 0.1435, G Loss: 9.8538; D Loss Real: 0.1434, ; D Loss Fake: 0.0000, \n",
      "Epoch [71/300], Step [120/234], D Loss: 0.0146, G Loss: 0.0021; D Loss Real: 0.0121, ; D Loss Fake: 0.0025, \n",
      "Epoch [71/300], Step [140/234], D Loss: 0.0244, G Loss: 8.0690; D Loss Real: 0.0240, ; D Loss Fake: 0.0004, \n",
      "Epoch [71/300], Step [160/234], D Loss: 0.0097, G Loss: 5.4272; D Loss Real: 0.0017, ; D Loss Fake: 0.0081, \n",
      "Epoch [71/300], Step [180/234], D Loss: 0.0007, G Loss: 11.2931; D Loss Real: 0.0007, ; D Loss Fake: 0.0000, \n",
      "Epoch [71/300], Step [200/234], D Loss: 0.0163, G Loss: 5.1597; D Loss Real: 0.0082, ; D Loss Fake: 0.0081, \n",
      "Epoch [71/300], Step [220/234], D Loss: 0.0013, G Loss: 7.4902; D Loss Real: 0.0005, ; D Loss Fake: 0.0008, \n",
      "Epoch [72/300], Step [20/234], D Loss: 0.0038, G Loss: 6.5217; D Loss Real: 0.0013, ; D Loss Fake: 0.0025, \n",
      "Epoch [72/300], Step [40/234], D Loss: 0.0090, G Loss: 5.1865; D Loss Real: 0.0005, ; D Loss Fake: 0.0086, \n",
      "Epoch [72/300], Step [60/234], D Loss: 0.0101, G Loss: 5.5213; D Loss Real: 0.0041, ; D Loss Fake: 0.0060, \n",
      "Epoch [72/300], Step [80/234], D Loss: 0.0323, G Loss: 0.0125; D Loss Real: 0.0011, ; D Loss Fake: 0.0312, \n",
      "Epoch [72/300], Step [100/234], D Loss: 0.0013, G Loss: 0.0401; D Loss Real: 0.0013, ; D Loss Fake: 0.0000, \n",
      "Epoch [72/300], Step [120/234], D Loss: 0.0014, G Loss: 7.9610; D Loss Real: 0.0010, ; D Loss Fake: 0.0003, \n",
      "Epoch [72/300], Step [140/234], D Loss: 0.0055, G Loss: 6.3492; D Loss Real: 0.0038, ; D Loss Fake: 0.0018, \n",
      "Epoch [72/300], Step [160/234], D Loss: 0.0011, G Loss: 8.2619; D Loss Real: 0.0008, ; D Loss Fake: 0.0003, \n",
      "Epoch [72/300], Step [180/234], D Loss: 0.0009, G Loss: 8.6518; D Loss Real: 0.0007, ; D Loss Fake: 0.0002, \n",
      "Epoch [72/300], Step [200/234], D Loss: 0.0289, G Loss: 0.0092; D Loss Real: 0.0032, ; D Loss Fake: 0.0257, \n",
      "Epoch [72/300], Step [220/234], D Loss: 0.1036, G Loss: 7.2165; D Loss Real: 0.1033, ; D Loss Fake: 0.0002, \n",
      "Epoch [73/300], Step [20/234], D Loss: 0.7434, G Loss: 9.8017; D Loss Real: 0.0063, ; D Loss Fake: 0.7370, \n",
      "Epoch [73/300], Step [40/234], D Loss: 0.0463, G Loss: -0.0138; D Loss Real: 0.0444, ; D Loss Fake: 0.0020, \n",
      "Epoch [73/300], Step [60/234], D Loss: 0.0849, G Loss: 4.6816; D Loss Real: 0.0007, ; D Loss Fake: 0.0842, \n",
      "Epoch [73/300], Step [80/234], D Loss: 0.0178, G Loss: 9.6678; D Loss Real: 0.0172, ; D Loss Fake: 0.0007, \n",
      "Epoch [73/300], Step [100/234], D Loss: 0.0148, G Loss: 9.0939; D Loss Real: 0.0148, ; D Loss Fake: 0.0000, \n",
      "Epoch [73/300], Step [120/234], D Loss: 0.0025, G Loss: 11.0458; D Loss Real: 0.0025, ; D Loss Fake: 0.0000, \n",
      "Epoch [73/300], Step [140/234], D Loss: 0.0039, G Loss: 5.3874; D Loss Real: 0.0001, ; D Loss Fake: 0.0038, \n",
      "Epoch [73/300], Step [160/234], D Loss: 0.0476, G Loss: 9.4476; D Loss Real: 0.0475, ; D Loss Fake: 0.0001, \n",
      "Epoch [73/300], Step [180/234], D Loss: 0.0080, G Loss: 9.3137; D Loss Real: 0.0079, ; D Loss Fake: 0.0001, \n",
      "Epoch [73/300], Step [200/234], D Loss: 0.0164, G Loss: 6.7493; D Loss Real: 0.0156, ; D Loss Fake: 0.0009, \n",
      "Epoch [73/300], Step [220/234], D Loss: 0.5120, G Loss: 7.8566; D Loss Real: 0.0004, ; D Loss Fake: 0.5116, \n",
      "Epoch [74/300], Step [20/234], D Loss: 0.8728, G Loss: -0.0126; D Loss Real: 0.0013, ; D Loss Fake: 0.8716, \n",
      "Epoch [74/300], Step [40/234], D Loss: 0.0178, G Loss: 5.4587; D Loss Real: 0.0112, ; D Loss Fake: 0.0066, \n",
      "Epoch [74/300], Step [60/234], D Loss: 0.0097, G Loss: 5.6248; D Loss Real: 0.0044, ; D Loss Fake: 0.0053, \n",
      "Epoch [74/300], Step [80/234], D Loss: 0.0202, G Loss: 5.2983; D Loss Real: 0.0087, ; D Loss Fake: 0.0114, \n",
      "Epoch [74/300], Step [100/234], D Loss: 0.0054, G Loss: 8.4933; D Loss Real: 0.0052, ; D Loss Fake: 0.0002, \n",
      "Epoch [74/300], Step [120/234], D Loss: 0.0720, G Loss: 9.0758; D Loss Real: 0.0719, ; D Loss Fake: 0.0001, \n",
      "Epoch [74/300], Step [140/234], D Loss: 0.0025, G Loss: 6.9545; D Loss Real: 0.0008, ; D Loss Fake: 0.0016, \n",
      "Epoch [74/300], Step [160/234], D Loss: 0.0199, G Loss: -0.0023; D Loss Real: 0.0146, ; D Loss Fake: 0.0053, \n",
      "Epoch [74/300], Step [180/234], D Loss: 0.0542, G Loss: 5.1907; D Loss Real: 0.0306, ; D Loss Fake: 0.0235, \n",
      "Epoch [74/300], Step [200/234], D Loss: 0.1547, G Loss: 6.3842; D Loss Real: 0.0002, ; D Loss Fake: 0.1545, \n",
      "Epoch [74/300], Step [220/234], D Loss: 0.0354, G Loss: 4.5901; D Loss Real: 0.0022, ; D Loss Fake: 0.0332, \n",
      "Epoch [75/300], Step [20/234], D Loss: 0.1516, G Loss: 5.4583; D Loss Real: 0.0159, ; D Loss Fake: 0.1358, \n",
      "Epoch [75/300], Step [40/234], D Loss: 0.0136, G Loss: 6.9137; D Loss Real: 0.0108, ; D Loss Fake: 0.0027, \n",
      "Epoch [75/300], Step [60/234], D Loss: 0.0108, G Loss: 5.7029; D Loss Real: 0.0064, ; D Loss Fake: 0.0044, \n",
      "Epoch [75/300], Step [80/234], D Loss: 0.4937, G Loss: 6.8633; D Loss Real: 0.4935, ; D Loss Fake: 0.0002, \n",
      "Epoch [75/300], Step [100/234], D Loss: 0.0025, G Loss: 6.7288; D Loss Real: 0.0007, ; D Loss Fake: 0.0018, \n",
      "Epoch [75/300], Step [120/234], D Loss: 0.0298, G Loss: 7.1459; D Loss Real: 0.0292, ; D Loss Fake: 0.0006, \n",
      "Epoch [75/300], Step [140/234], D Loss: 0.0238, G Loss: 5.4709; D Loss Real: 0.0089, ; D Loss Fake: 0.0148, \n",
      "Epoch [75/300], Step [160/234], D Loss: 0.2873, G Loss: 5.3468; D Loss Real: 0.1713, ; D Loss Fake: 0.1160, \n",
      "Epoch [75/300], Step [180/234], D Loss: 0.0334, G Loss: 4.7409; D Loss Real: 0.0002, ; D Loss Fake: 0.0332, \n",
      "Epoch [75/300], Step [200/234], D Loss: 0.0414, G Loss: 6.3826; D Loss Real: 0.0012, ; D Loss Fake: 0.0402, \n",
      "Epoch [75/300], Step [220/234], D Loss: 0.0083, G Loss: 8.9726; D Loss Real: 0.0083, ; D Loss Fake: 0.0000, \n",
      "Epoch [76/300], Step [20/234], D Loss: 0.0998, G Loss: 5.0457; D Loss Real: 0.0117, ; D Loss Fake: 0.0881, \n",
      "Epoch [76/300], Step [40/234], D Loss: 0.0053, G Loss: 7.7271; D Loss Real: 0.0050, ; D Loss Fake: 0.0003, \n",
      "Epoch [76/300], Step [60/234], D Loss: 0.0254, G Loss: 13.6942; D Loss Real: 0.0254, ; D Loss Fake: 0.0000, \n",
      "Epoch [76/300], Step [80/234], D Loss: 0.0040, G Loss: 8.8709; D Loss Real: 0.0039, ; D Loss Fake: 0.0001, \n",
      "Epoch [76/300], Step [100/234], D Loss: 0.0162, G Loss: 9.2424; D Loss Real: 0.0162, ; D Loss Fake: 0.0001, \n",
      "Epoch [76/300], Step [120/234], D Loss: 0.3581, G Loss: 8.6566; D Loss Real: 0.0054, ; D Loss Fake: 0.3527, \n",
      "Epoch [76/300], Step [140/234], D Loss: 0.0150, G Loss: 0.0034; D Loss Real: 0.0070, ; D Loss Fake: 0.0080, \n",
      "Epoch [76/300], Step [160/234], D Loss: 0.0438, G Loss: 5.8801; D Loss Real: 0.0100, ; D Loss Fake: 0.0337, \n",
      "Epoch [76/300], Step [180/234], D Loss: 0.0018, G Loss: 0.0069; D Loss Real: 0.0018, ; D Loss Fake: 0.0000, \n",
      "Epoch [76/300], Step [200/234], D Loss: 0.0229, G Loss: 6.7260; D Loss Real: 0.0207, ; D Loss Fake: 0.0022, \n",
      "Epoch [76/300], Step [220/234], D Loss: 0.0374, G Loss: 7.4284; D Loss Real: 0.0368, ; D Loss Fake: 0.0006, \n",
      "Epoch [77/300], Step [20/234], D Loss: 0.1923, G Loss: 5.7738; D Loss Real: 0.0009, ; D Loss Fake: 0.1914, \n",
      "Epoch [77/300], Step [40/234], D Loss: 0.0058, G Loss: 5.8011; D Loss Real: 0.0020, ; D Loss Fake: 0.0038, \n",
      "Epoch [77/300], Step [60/234], D Loss: 0.0031, G Loss: 9.6059; D Loss Real: 0.0030, ; D Loss Fake: 0.0001, \n",
      "Epoch [77/300], Step [80/234], D Loss: 0.0044, G Loss: 6.1669; D Loss Real: 0.0018, ; D Loss Fake: 0.0027, \n",
      "Epoch [77/300], Step [100/234], D Loss: 0.0287, G Loss: 6.9449; D Loss Real: 0.0273, ; D Loss Fake: 0.0014, \n",
      "Epoch [77/300], Step [120/234], D Loss: 0.0094, G Loss: 0.0021; D Loss Real: 0.0001, ; D Loss Fake: 0.0093, \n",
      "Epoch [77/300], Step [140/234], D Loss: 0.0024, G Loss: 7.9020; D Loss Real: 0.0020, ; D Loss Fake: 0.0004, \n",
      "Epoch [77/300], Step [160/234], D Loss: 0.0006, G Loss: 0.0102; D Loss Real: 0.0006, ; D Loss Fake: 0.0000, \n",
      "Epoch [77/300], Step [180/234], D Loss: 0.0400, G Loss: 15.5930; D Loss Real: 0.0400, ; D Loss Fake: 0.0000, \n",
      "Epoch [77/300], Step [200/234], D Loss: 0.0232, G Loss: 12.6301; D Loss Real: 0.0232, ; D Loss Fake: 0.0000, \n",
      "Epoch [77/300], Step [220/234], D Loss: 0.0398, G Loss: 5.9023; D Loss Real: 0.0383, ; D Loss Fake: 0.0015, \n",
      "Epoch [78/300], Step [20/234], D Loss: 0.0050, G Loss: 7.7018; D Loss Real: 0.0042, ; D Loss Fake: 0.0007, \n",
      "Epoch [78/300], Step [40/234], D Loss: 0.0107, G Loss: 5.4299; D Loss Real: 0.0049, ; D Loss Fake: 0.0058, \n",
      "Epoch [78/300], Step [60/234], D Loss: 0.1477, G Loss: 4.9082; D Loss Real: 0.0614, ; D Loss Fake: 0.0862, \n",
      "Epoch [78/300], Step [80/234], D Loss: 0.0028, G Loss: 7.6096; D Loss Real: 0.0017, ; D Loss Fake: 0.0011, \n",
      "Epoch [78/300], Step [100/234], D Loss: 0.0302, G Loss: 5.4326; D Loss Real: 0.0265, ; D Loss Fake: 0.0037, \n",
      "Epoch [78/300], Step [120/234], D Loss: 0.0325, G Loss: 4.9219; D Loss Real: 0.0012, ; D Loss Fake: 0.0314, \n",
      "Epoch [78/300], Step [140/234], D Loss: 0.0173, G Loss: 5.1999; D Loss Real: 0.0025, ; D Loss Fake: 0.0149, \n",
      "Epoch [78/300], Step [160/234], D Loss: 0.0013, G Loss: 9.6921; D Loss Real: 0.0013, ; D Loss Fake: 0.0001, \n",
      "Epoch [78/300], Step [180/234], D Loss: 0.0190, G Loss: 7.3833; D Loss Real: 0.0186, ; D Loss Fake: 0.0004, \n",
      "Epoch [78/300], Step [200/234], D Loss: 0.0128, G Loss: 7.0742; D Loss Real: 0.0123, ; D Loss Fake: 0.0005, \n",
      "Epoch [78/300], Step [220/234], D Loss: 0.0217, G Loss: -0.0107; D Loss Real: 0.0214, ; D Loss Fake: 0.0003, \n",
      "Epoch [79/300], Step [20/234], D Loss: 0.1368, G Loss: 6.6745; D Loss Real: 0.1305, ; D Loss Fake: 0.0062, \n",
      "Epoch [79/300], Step [40/234], D Loss: 0.0081, G Loss: 5.8871; D Loss Real: 0.0006, ; D Loss Fake: 0.0075, \n",
      "Epoch [79/300], Step [60/234], D Loss: 0.0017, G Loss: 11.6843; D Loss Real: 0.0017, ; D Loss Fake: 0.0000, \n",
      "Epoch [79/300], Step [80/234], D Loss: 0.0205, G Loss: 0.0108; D Loss Real: 0.0034, ; D Loss Fake: 0.0172, \n",
      "Epoch [79/300], Step [100/234], D Loss: 0.0017, G Loss: 7.7575; D Loss Real: 0.0009, ; D Loss Fake: 0.0007, \n",
      "Epoch [79/300], Step [120/234], D Loss: 0.1212, G Loss: 12.2714; D Loss Real: 0.1212, ; D Loss Fake: 0.0000, \n",
      "Epoch [79/300], Step [140/234], D Loss: 0.1290, G Loss: 11.5377; D Loss Real: 0.1287, ; D Loss Fake: 0.0003, \n",
      "Epoch [79/300], Step [160/234], D Loss: 0.0076, G Loss: 5.4568; D Loss Real: 0.0021, ; D Loss Fake: 0.0055, \n",
      "Epoch [79/300], Step [180/234], D Loss: 0.0568, G Loss: 12.9819; D Loss Real: 0.0568, ; D Loss Fake: 0.0000, \n",
      "Epoch [79/300], Step [200/234], D Loss: 0.0012, G Loss: 6.4309; D Loss Real: 0.0001, ; D Loss Fake: 0.0011, \n",
      "Epoch [79/300], Step [220/234], D Loss: 0.0077, G Loss: 4.8439; D Loss Real: 0.0002, ; D Loss Fake: 0.0075, \n",
      "Epoch [80/300], Step [20/234], D Loss: 0.0813, G Loss: 5.1679; D Loss Real: 0.0025, ; D Loss Fake: 0.0787, \n",
      "Epoch [80/300], Step [40/234], D Loss: 0.0051, G Loss: 6.5384; D Loss Real: 0.0012, ; D Loss Fake: 0.0040, \n",
      "Epoch [80/300], Step [60/234], D Loss: 0.0043, G Loss: 7.3800; D Loss Real: 0.0039, ; D Loss Fake: 0.0003, \n",
      "Epoch [80/300], Step [80/234], D Loss: 0.1504, G Loss: 5.4042; D Loss Real: 0.0626, ; D Loss Fake: 0.0878, \n",
      "Epoch [80/300], Step [100/234], D Loss: 0.0016, G Loss: 9.7289; D Loss Real: 0.0015, ; D Loss Fake: 0.0001, \n",
      "Epoch [80/300], Step [120/234], D Loss: 0.1465, G Loss: 6.3972; D Loss Real: 0.0007, ; D Loss Fake: 0.1458, \n",
      "Epoch [80/300], Step [140/234], D Loss: 0.0106, G Loss: -0.0151; D Loss Real: 0.0097, ; D Loss Fake: 0.0009, \n",
      "Epoch [80/300], Step [160/234], D Loss: 0.1868, G Loss: 7.0127; D Loss Real: 0.0072, ; D Loss Fake: 0.1796, \n",
      "Epoch [80/300], Step [180/234], D Loss: 0.0070, G Loss: 5.3375; D Loss Real: 0.0011, ; D Loss Fake: 0.0059, \n",
      "Epoch [80/300], Step [200/234], D Loss: 0.0045, G Loss: 7.1589; D Loss Real: 0.0032, ; D Loss Fake: 0.0014, \n",
      "Epoch [80/300], Step [220/234], D Loss: 0.0001, G Loss: 14.1971; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [81/300], Step [20/234], D Loss: 0.3073, G Loss: -0.0118; D Loss Real: 0.0002, ; D Loss Fake: 0.3071, \n",
      "Epoch [81/300], Step [40/234], D Loss: 0.0736, G Loss: 4.9043; D Loss Real: 0.0019, ; D Loss Fake: 0.0717, \n",
      "Epoch [81/300], Step [60/234], D Loss: 0.0172, G Loss: 5.5877; D Loss Real: 0.0017, ; D Loss Fake: 0.0155, \n",
      "Epoch [81/300], Step [80/234], D Loss: 0.1798, G Loss: 0.0093; D Loss Real: 0.1797, ; D Loss Fake: 0.0000, \n",
      "Epoch [81/300], Step [100/234], D Loss: 0.9408, G Loss: 0.0067; D Loss Real: 0.0009, ; D Loss Fake: 0.9399, \n",
      "Epoch [81/300], Step [120/234], D Loss: 0.6847, G Loss: 1.6488; D Loss Real: 0.6845, ; D Loss Fake: 0.0002, \n",
      "Epoch [81/300], Step [140/234], D Loss: 0.0481, G Loss: 5.7271; D Loss Real: 0.0008, ; D Loss Fake: 0.0472, \n",
      "Epoch [81/300], Step [160/234], D Loss: 0.0683, G Loss: 5.3443; D Loss Real: 0.0001, ; D Loss Fake: 0.0682, \n",
      "Epoch [81/300], Step [180/234], D Loss: 0.0068, G Loss: 8.7897; D Loss Real: 0.0067, ; D Loss Fake: 0.0001, \n",
      "Epoch [81/300], Step [200/234], D Loss: 0.0024, G Loss: 11.7875; D Loss Real: 0.0024, ; D Loss Fake: 0.0000, \n",
      "Epoch [81/300], Step [220/234], D Loss: 0.0059, G Loss: 6.3682; D Loss Real: 0.0038, ; D Loss Fake: 0.0020, \n",
      "Epoch [82/300], Step [20/234], D Loss: 0.0067, G Loss: 6.1318; D Loss Real: 0.0024, ; D Loss Fake: 0.0043, \n",
      "Epoch [82/300], Step [40/234], D Loss: 0.1136, G Loss: 9.8536; D Loss Real: 0.1136, ; D Loss Fake: 0.0000, \n",
      "Epoch [82/300], Step [60/234], D Loss: 0.0034, G Loss: 5.1506; D Loss Real: 0.0021, ; D Loss Fake: 0.0013, \n",
      "Epoch [82/300], Step [80/234], D Loss: 0.0098, G Loss: 7.4293; D Loss Real: 0.0086, ; D Loss Fake: 0.0012, \n",
      "Epoch [82/300], Step [100/234], D Loss: 0.0077, G Loss: 7.2126; D Loss Real: 0.0070, ; D Loss Fake: 0.0007, \n",
      "Epoch [82/300], Step [120/234], D Loss: 0.0087, G Loss: 5.8156; D Loss Real: 0.0031, ; D Loss Fake: 0.0056, \n",
      "Epoch [82/300], Step [140/234], D Loss: 0.1762, G Loss: 7.1037; D Loss Real: 0.0280, ; D Loss Fake: 0.1482, \n",
      "Epoch [82/300], Step [160/234], D Loss: 0.0151, G Loss: 6.2089; D Loss Real: 0.0133, ; D Loss Fake: 0.0018, \n",
      "Epoch [82/300], Step [180/234], D Loss: 0.0053, G Loss: 5.3318; D Loss Real: 0.0008, ; D Loss Fake: 0.0045, \n",
      "Epoch [82/300], Step [200/234], D Loss: 0.0161, G Loss: 4.4788; D Loss Real: 0.0029, ; D Loss Fake: 0.0132, \n",
      "Epoch [82/300], Step [220/234], D Loss: 0.0171, G Loss: 9.6971; D Loss Real: 0.0171, ; D Loss Fake: 0.0000, \n",
      "Epoch [83/300], Step [20/234], D Loss: 0.0003, G Loss: 13.6460; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [83/300], Step [40/234], D Loss: 0.0291, G Loss: 4.5652; D Loss Real: 0.0021, ; D Loss Fake: 0.0270, \n",
      "Epoch [83/300], Step [60/234], D Loss: 0.0306, G Loss: 0.0124; D Loss Real: 0.0001, ; D Loss Fake: 0.0305, \n",
      "Epoch [83/300], Step [80/234], D Loss: 0.0086, G Loss: 5.8299; D Loss Real: 0.0041, ; D Loss Fake: 0.0046, \n",
      "Epoch [83/300], Step [100/234], D Loss: 0.0215, G Loss: 4.6027; D Loss Real: 0.0111, ; D Loss Fake: 0.0104, \n",
      "Epoch [83/300], Step [120/234], D Loss: 0.0577, G Loss: 4.9171; D Loss Real: 0.0001, ; D Loss Fake: 0.0575, \n",
      "Epoch [83/300], Step [140/234], D Loss: 0.0025, G Loss: 8.7859; D Loss Real: 0.0024, ; D Loss Fake: 0.0001, \n",
      "Epoch [83/300], Step [160/234], D Loss: 0.0032, G Loss: 5.4607; D Loss Real: 0.0005, ; D Loss Fake: 0.0027, \n",
      "Epoch [83/300], Step [180/234], D Loss: 6.2078, G Loss: 12.3042; D Loss Real: 6.2078, ; D Loss Fake: -0.0000, \n",
      "Epoch [83/300], Step [200/234], D Loss: 0.4628, G Loss: 8.0092; D Loss Real: 0.1175, ; D Loss Fake: 0.3454, \n",
      "Epoch [83/300], Step [220/234], D Loss: 0.0307, G Loss: 7.3461; D Loss Real: 0.0302, ; D Loss Fake: 0.0005, \n",
      "Epoch [84/300], Step [20/234], D Loss: 0.1091, G Loss: 6.8603; D Loss Real: 0.1084, ; D Loss Fake: 0.0007, \n",
      "Epoch [84/300], Step [40/234], D Loss: 0.0507, G Loss: 5.7530; D Loss Real: 0.0003, ; D Loss Fake: 0.0503, \n",
      "Epoch [84/300], Step [60/234], D Loss: 0.0018, G Loss: 9.2335; D Loss Real: 0.0018, ; D Loss Fake: 0.0001, \n",
      "Epoch [84/300], Step [80/234], D Loss: 0.0944, G Loss: 3.9291; D Loss Real: 0.0668, ; D Loss Fake: 0.0276, \n",
      "Epoch [84/300], Step [100/234], D Loss: 0.0030, G Loss: 9.7134; D Loss Real: 0.0029, ; D Loss Fake: 0.0001, \n",
      "Epoch [84/300], Step [120/234], D Loss: 0.0045, G Loss: 6.1198; D Loss Real: 0.0015, ; D Loss Fake: 0.0030, \n",
      "Epoch [84/300], Step [140/234], D Loss: 0.0049, G Loss: 6.2066; D Loss Real: 0.0029, ; D Loss Fake: 0.0020, \n",
      "Epoch [84/300], Step [160/234], D Loss: 0.0008, G Loss: 10.2800; D Loss Real: 0.0007, ; D Loss Fake: 0.0000, \n",
      "Epoch [84/300], Step [180/234], D Loss: 0.0042, G Loss: 5.4624; D Loss Real: 0.0006, ; D Loss Fake: 0.0036, \n",
      "Epoch [84/300], Step [200/234], D Loss: 0.0074, G Loss: 5.8167; D Loss Real: 0.0033, ; D Loss Fake: 0.0040, \n",
      "Epoch [84/300], Step [220/234], D Loss: 0.0050, G Loss: 6.9184; D Loss Real: 0.0041, ; D Loss Fake: 0.0008, \n",
      "Epoch [85/300], Step [20/234], D Loss: 0.0037, G Loss: 9.8958; D Loss Real: 0.0037, ; D Loss Fake: 0.0000, \n",
      "Epoch [85/300], Step [40/234], D Loss: 0.0287, G Loss: 5.7165; D Loss Real: 0.0236, ; D Loss Fake: 0.0052, \n",
      "Epoch [85/300], Step [60/234], D Loss: 0.0031, G Loss: 6.8576; D Loss Real: 0.0015, ; D Loss Fake: 0.0016, \n",
      "Epoch [85/300], Step [80/234], D Loss: 0.0106, G Loss: 6.8264; D Loss Real: 0.0097, ; D Loss Fake: 0.0009, \n",
      "Epoch [85/300], Step [100/234], D Loss: 0.0082, G Loss: 5.9064; D Loss Real: 0.0022, ; D Loss Fake: 0.0059, \n",
      "Epoch [85/300], Step [120/234], D Loss: 0.0014, G Loss: 6.9042; D Loss Real: 0.0004, ; D Loss Fake: 0.0010, \n",
      "Epoch [85/300], Step [140/234], D Loss: 0.0019, G Loss: 8.8924; D Loss Real: 0.0017, ; D Loss Fake: 0.0002, \n",
      "Epoch [85/300], Step [160/234], D Loss: 0.0931, G Loss: 5.8825; D Loss Real: 0.0069, ; D Loss Fake: 0.0862, \n",
      "Epoch [85/300], Step [180/234], D Loss: 0.0037, G Loss: 7.8833; D Loss Real: 0.0033, ; D Loss Fake: 0.0004, \n",
      "Epoch [85/300], Step [200/234], D Loss: 0.0016, G Loss: 7.4422; D Loss Real: 0.0008, ; D Loss Fake: 0.0008, \n",
      "Epoch [85/300], Step [220/234], D Loss: 0.3459, G Loss: 8.0848; D Loss Real: 0.0004, ; D Loss Fake: 0.3455, \n",
      "Epoch [86/300], Step [20/234], D Loss: 0.0261, G Loss: 7.3942; D Loss Real: 0.0240, ; D Loss Fake: 0.0021, \n",
      "Epoch [86/300], Step [40/234], D Loss: 0.0399, G Loss: 4.4297; D Loss Real: 0.0324, ; D Loss Fake: 0.0076, \n",
      "Epoch [86/300], Step [60/234], D Loss: 0.0202, G Loss: 11.0156; D Loss Real: 0.0202, ; D Loss Fake: 0.0000, \n",
      "Epoch [86/300], Step [80/234], D Loss: 0.0002, G Loss: 12.0302; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [86/300], Step [100/234], D Loss: 0.0020, G Loss: 12.1583; D Loss Real: 0.0019, ; D Loss Fake: 0.0000, \n",
      "Epoch [86/300], Step [120/234], D Loss: 0.0640, G Loss: 5.9164; D Loss Real: 0.0011, ; D Loss Fake: 0.0629, \n",
      "Epoch [86/300], Step [140/234], D Loss: 0.0141, G Loss: 5.5588; D Loss Real: 0.0047, ; D Loss Fake: 0.0094, \n",
      "Epoch [86/300], Step [160/234], D Loss: 0.0110, G Loss: 5.5041; D Loss Real: 0.0048, ; D Loss Fake: 0.0063, \n",
      "Epoch [86/300], Step [180/234], D Loss: 0.0053, G Loss: 8.5638; D Loss Real: 0.0050, ; D Loss Fake: 0.0003, \n",
      "Epoch [86/300], Step [200/234], D Loss: 0.0063, G Loss: 5.9259; D Loss Real: 0.0033, ; D Loss Fake: 0.0030, \n",
      "Epoch [86/300], Step [220/234], D Loss: 0.0145, G Loss: 5.0256; D Loss Real: 0.0006, ; D Loss Fake: 0.0139, \n",
      "Epoch [87/300], Step [20/234], D Loss: 0.0005, G Loss: 11.9932; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [87/300], Step [40/234], D Loss: 0.0681, G Loss: 12.2278; D Loss Real: 0.0681, ; D Loss Fake: 0.0000, \n",
      "Epoch [87/300], Step [60/234], D Loss: 0.0879, G Loss: 15.2968; D Loss Real: 0.0879, ; D Loss Fake: 0.0000, \n",
      "Epoch [87/300], Step [80/234], D Loss: 0.0645, G Loss: 7.5298; D Loss Real: 0.0007, ; D Loss Fake: 0.0638, \n",
      "Epoch [87/300], Step [100/234], D Loss: 0.0521, G Loss: 4.7222; D Loss Real: 0.0189, ; D Loss Fake: 0.0332, \n",
      "Epoch [87/300], Step [120/234], D Loss: 0.0318, G Loss: 5.5754; D Loss Real: 0.0141, ; D Loss Fake: 0.0177, \n",
      "Epoch [87/300], Step [140/234], D Loss: 0.0177, G Loss: -0.0084; D Loss Real: 0.0163, ; D Loss Fake: 0.0014, \n",
      "Epoch [87/300], Step [160/234], D Loss: 0.0023, G Loss: 13.6802; D Loss Real: 0.0023, ; D Loss Fake: 0.0000, \n",
      "Epoch [87/300], Step [180/234], D Loss: 0.0652, G Loss: 5.4714; D Loss Real: 0.0051, ; D Loss Fake: 0.0601, \n",
      "Epoch [87/300], Step [200/234], D Loss: 0.0202, G Loss: 8.0675; D Loss Real: 0.0200, ; D Loss Fake: 0.0002, \n",
      "Epoch [87/300], Step [220/234], D Loss: 0.0004, G Loss: 8.7272; D Loss Real: 0.0003, ; D Loss Fake: 0.0002, \n",
      "Epoch [88/300], Step [20/234], D Loss: 0.0893, G Loss: 5.4968; D Loss Real: 0.0009, ; D Loss Fake: 0.0884, \n",
      "Epoch [88/300], Step [40/234], D Loss: 0.0028, G Loss: 11.7673; D Loss Real: 0.0028, ; D Loss Fake: 0.0000, \n",
      "Epoch [88/300], Step [60/234], D Loss: 0.1447, G Loss: 6.8095; D Loss Real: 0.0015, ; D Loss Fake: 0.1433, \n",
      "Epoch [88/300], Step [80/234], D Loss: 0.0273, G Loss: 5.3103; D Loss Real: 0.0219, ; D Loss Fake: 0.0054, \n",
      "Epoch [88/300], Step [100/234], D Loss: 0.0068, G Loss: 5.5604; D Loss Real: 0.0015, ; D Loss Fake: 0.0053, \n",
      "Epoch [88/300], Step [120/234], D Loss: 0.1357, G Loss: 13.7346; D Loss Real: 0.1356, ; D Loss Fake: 0.0000, \n",
      "Epoch [88/300], Step [140/234], D Loss: 0.0133, G Loss: 6.2974; D Loss Real: 0.0004, ; D Loss Fake: 0.0129, \n",
      "Epoch [88/300], Step [160/234], D Loss: 0.0037, G Loss: 5.7587; D Loss Real: 0.0003, ; D Loss Fake: 0.0035, \n",
      "Epoch [88/300], Step [180/234], D Loss: 0.0306, G Loss: 12.4063; D Loss Real: 0.0306, ; D Loss Fake: 0.0000, \n",
      "Epoch [88/300], Step [200/234], D Loss: 0.0025, G Loss: 8.3191; D Loss Real: 0.0021, ; D Loss Fake: 0.0004, \n",
      "Epoch [88/300], Step [220/234], D Loss: 0.0013, G Loss: 7.1575; D Loss Real: 0.0006, ; D Loss Fake: 0.0007, \n",
      "Epoch [89/300], Step [20/234], D Loss: 0.0272, G Loss: 6.4393; D Loss Real: 0.0033, ; D Loss Fake: 0.0239, \n",
      "Epoch [89/300], Step [40/234], D Loss: 0.0912, G Loss: 0.0080; D Loss Real: 0.0912, ; D Loss Fake: 0.0000, \n",
      "Epoch [89/300], Step [60/234], D Loss: 0.0134, G Loss: 5.0886; D Loss Real: 0.0048, ; D Loss Fake: 0.0086, \n",
      "Epoch [89/300], Step [80/234], D Loss: 0.0127, G Loss: 0.0041; D Loss Real: 0.0001, ; D Loss Fake: 0.0126, \n",
      "Epoch [89/300], Step [100/234], D Loss: 0.0174, G Loss: 8.2212; D Loss Real: 0.0131, ; D Loss Fake: 0.0043, \n",
      "Epoch [89/300], Step [120/234], D Loss: 0.1029, G Loss: 7.2898; D Loss Real: 0.0113, ; D Loss Fake: 0.0916, \n",
      "Epoch [89/300], Step [140/234], D Loss: 0.0034, G Loss: 15.6966; D Loss Real: 0.0034, ; D Loss Fake: 0.0000, \n",
      "Epoch [89/300], Step [160/234], D Loss: 0.0009, G Loss: 10.6226; D Loss Real: 0.0003, ; D Loss Fake: 0.0006, \n",
      "Epoch [89/300], Step [180/234], D Loss: 0.0284, G Loss: 5.4887; D Loss Real: 0.0128, ; D Loss Fake: 0.0156, \n",
      "Epoch [89/300], Step [200/234], D Loss: 0.0340, G Loss: 6.8538; D Loss Real: 0.0282, ; D Loss Fake: 0.0059, \n",
      "Epoch [89/300], Step [220/234], D Loss: 0.1260, G Loss: 6.4643; D Loss Real: 0.1246, ; D Loss Fake: 0.0014, \n",
      "Epoch [90/300], Step [20/234], D Loss: 0.0050, G Loss: 14.2633; D Loss Real: 0.0050, ; D Loss Fake: 0.0000, \n",
      "Epoch [90/300], Step [40/234], D Loss: 0.0085, G Loss: 8.0476; D Loss Real: 0.0081, ; D Loss Fake: 0.0004, \n",
      "Epoch [90/300], Step [60/234], D Loss: 0.0136, G Loss: 6.8023; D Loss Real: 0.0129, ; D Loss Fake: 0.0007, \n",
      "Epoch [90/300], Step [80/234], D Loss: 0.0141, G Loss: 6.4690; D Loss Real: 0.0068, ; D Loss Fake: 0.0073, \n",
      "Epoch [90/300], Step [100/234], D Loss: 0.0361, G Loss: 5.3936; D Loss Real: 0.0072, ; D Loss Fake: 0.0288, \n",
      "Epoch [90/300], Step [120/234], D Loss: 0.0138, G Loss: 4.9833; D Loss Real: 0.0060, ; D Loss Fake: 0.0077, \n",
      "Epoch [90/300], Step [140/234], D Loss: 0.0002, G Loss: 0.0140; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [90/300], Step [160/234], D Loss: 0.0853, G Loss: 7.7168; D Loss Real: 0.0850, ; D Loss Fake: 0.0003, \n",
      "Epoch [90/300], Step [180/234], D Loss: 0.0059, G Loss: 9.8871; D Loss Real: 0.0058, ; D Loss Fake: 0.0000, \n",
      "Epoch [90/300], Step [200/234], D Loss: 0.0020, G Loss: 11.7563; D Loss Real: 0.0020, ; D Loss Fake: 0.0000, \n",
      "Epoch [90/300], Step [220/234], D Loss: 0.0452, G Loss: 4.6338; D Loss Real: 0.0006, ; D Loss Fake: 0.0446, \n",
      "Epoch [91/300], Step [20/234], D Loss: 0.0082, G Loss: 10.3105; D Loss Real: 0.0066, ; D Loss Fake: 0.0016, \n",
      "Epoch [91/300], Step [40/234], D Loss: 0.1094, G Loss: 14.4793; D Loss Real: 0.1094, ; D Loss Fake: 0.0000, \n",
      "Epoch [91/300], Step [60/234], D Loss: 0.0057, G Loss: 6.4722; D Loss Real: 0.0009, ; D Loss Fake: 0.0048, \n",
      "Epoch [91/300], Step [80/234], D Loss: 0.0043, G Loss: 0.0003; D Loss Real: 0.0021, ; D Loss Fake: 0.0023, \n",
      "Epoch [91/300], Step [100/234], D Loss: 0.0180, G Loss: 4.8163; D Loss Real: 0.0060, ; D Loss Fake: 0.0120, \n",
      "Epoch [91/300], Step [120/234], D Loss: 0.0103, G Loss: 0.0113; D Loss Real: 0.0096, ; D Loss Fake: 0.0007, \n",
      "Epoch [91/300], Step [140/234], D Loss: 0.1952, G Loss: 4.5375; D Loss Real: 0.1801, ; D Loss Fake: 0.0150, \n",
      "Epoch [91/300], Step [160/234], D Loss: 0.0047, G Loss: 7.1387; D Loss Real: 0.0041, ; D Loss Fake: 0.0006, \n",
      "Epoch [91/300], Step [180/234], D Loss: 0.0200, G Loss: 13.0730; D Loss Real: 0.0200, ; D Loss Fake: 0.0000, \n",
      "Epoch [91/300], Step [200/234], D Loss: 0.0025, G Loss: 11.3876; D Loss Real: 0.0025, ; D Loss Fake: 0.0000, \n",
      "Epoch [91/300], Step [220/234], D Loss: 0.0101, G Loss: 5.5012; D Loss Real: 0.0042, ; D Loss Fake: 0.0059, \n",
      "Epoch [92/300], Step [20/234], D Loss: 0.0077, G Loss: 4.9752; D Loss Real: 0.0008, ; D Loss Fake: 0.0069, \n",
      "Epoch [92/300], Step [40/234], D Loss: 0.0213, G Loss: 5.8602; D Loss Real: 0.0014, ; D Loss Fake: 0.0200, \n",
      "Epoch [92/300], Step [60/234], D Loss: 0.0120, G Loss: 5.8194; D Loss Real: 0.0037, ; D Loss Fake: 0.0083, \n",
      "Epoch [92/300], Step [80/234], D Loss: 0.0154, G Loss: 18.9291; D Loss Real: 0.0154, ; D Loss Fake: 0.0000, \n",
      "Epoch [92/300], Step [100/234], D Loss: 0.0036, G Loss: 6.9069; D Loss Real: 0.0017, ; D Loss Fake: 0.0018, \n",
      "Epoch [92/300], Step [120/234], D Loss: 0.0089, G Loss: 8.9857; D Loss Real: 0.0089, ; D Loss Fake: 0.0001, \n",
      "Epoch [92/300], Step [140/234], D Loss: 0.0440, G Loss: 8.0126; D Loss Real: 0.0438, ; D Loss Fake: 0.0002, \n",
      "Epoch [92/300], Step [160/234], D Loss: 0.0173, G Loss: 6.2870; D Loss Real: 0.0151, ; D Loss Fake: 0.0022, \n",
      "Epoch [92/300], Step [180/234], D Loss: 0.0585, G Loss: 11.1326; D Loss Real: 0.0583, ; D Loss Fake: 0.0002, \n",
      "Epoch [92/300], Step [200/234], D Loss: 0.0018, G Loss: 6.9229; D Loss Real: 0.0012, ; D Loss Fake: 0.0006, \n",
      "Epoch [92/300], Step [220/234], D Loss: 0.0001, G Loss: 12.7450; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [93/300], Step [20/234], D Loss: 0.0926, G Loss: -0.0199; D Loss Real: 0.0924, ; D Loss Fake: 0.0002, \n",
      "Epoch [93/300], Step [40/234], D Loss: 0.0071, G Loss: 12.0097; D Loss Real: 0.0071, ; D Loss Fake: 0.0000, \n",
      "Epoch [93/300], Step [60/234], D Loss: 0.0115, G Loss: 7.2876; D Loss Real: 0.0085, ; D Loss Fake: 0.0031, \n",
      "Epoch [93/300], Step [80/234], D Loss: 0.0195, G Loss: 8.3081; D Loss Real: 0.0193, ; D Loss Fake: 0.0002, \n",
      "Epoch [93/300], Step [100/234], D Loss: 0.0031, G Loss: 7.7627; D Loss Real: 0.0026, ; D Loss Fake: 0.0005, \n",
      "Epoch [93/300], Step [120/234], D Loss: 0.0028, G Loss: 8.5174; D Loss Real: 0.0024, ; D Loss Fake: 0.0005, \n",
      "Epoch [93/300], Step [140/234], D Loss: 0.0051, G Loss: 6.0592; D Loss Real: 0.0036, ; D Loss Fake: 0.0015, \n",
      "Epoch [93/300], Step [160/234], D Loss: 0.1344, G Loss: 6.9745; D Loss Real: 0.0021, ; D Loss Fake: 0.1323, \n",
      "Epoch [93/300], Step [180/234], D Loss: 0.0204, G Loss: 5.7483; D Loss Real: 0.0155, ; D Loss Fake: 0.0050, \n",
      "Epoch [93/300], Step [200/234], D Loss: 0.0231, G Loss: 4.6791; D Loss Real: 0.0008, ; D Loss Fake: 0.0223, \n",
      "Epoch [93/300], Step [220/234], D Loss: 0.0085, G Loss: 11.6043; D Loss Real: 0.0085, ; D Loss Fake: 0.0000, \n",
      "Epoch [94/300], Step [20/234], D Loss: 0.0724, G Loss: 7.6226; D Loss Real: 0.0702, ; D Loss Fake: 0.0022, \n",
      "Epoch [94/300], Step [40/234], D Loss: 0.0248, G Loss: -0.0064; D Loss Real: 0.0007, ; D Loss Fake: 0.0241, \n",
      "Epoch [94/300], Step [60/234], D Loss: 0.0191, G Loss: 5.8203; D Loss Real: 0.0126, ; D Loss Fake: 0.0065, \n",
      "Epoch [94/300], Step [80/234], D Loss: 0.0046, G Loss: 8.4590; D Loss Real: 0.0045, ; D Loss Fake: 0.0001, \n",
      "Epoch [94/300], Step [100/234], D Loss: 0.0011, G Loss: 10.5672; D Loss Real: 0.0011, ; D Loss Fake: 0.0000, \n",
      "Epoch [94/300], Step [120/234], D Loss: 0.1853, G Loss: 6.5556; D Loss Real: 0.0005, ; D Loss Fake: 0.1847, \n",
      "Epoch [94/300], Step [140/234], D Loss: 0.0317, G Loss: 9.3545; D Loss Real: 0.0315, ; D Loss Fake: 0.0001, \n",
      "Epoch [94/300], Step [160/234], D Loss: 0.0073, G Loss: -0.0039; D Loss Real: 0.0070, ; D Loss Fake: 0.0003, \n",
      "Epoch [94/300], Step [180/234], D Loss: 0.0007, G Loss: 8.0457; D Loss Real: 0.0006, ; D Loss Fake: 0.0002, \n",
      "Epoch [94/300], Step [200/234], D Loss: 0.0099, G Loss: 11.2166; D Loss Real: 0.0099, ; D Loss Fake: 0.0000, \n",
      "Epoch [94/300], Step [220/234], D Loss: 0.0738, G Loss: 5.7553; D Loss Real: 0.0020, ; D Loss Fake: 0.0717, \n",
      "Epoch [95/300], Step [20/234], D Loss: 0.7722, G Loss: 9.7865; D Loss Real: 0.0428, ; D Loss Fake: 0.7294, \n",
      "Epoch [95/300], Step [40/234], D Loss: 0.0475, G Loss: 8.8949; D Loss Real: 0.0473, ; D Loss Fake: 0.0001, \n",
      "Epoch [95/300], Step [60/234], D Loss: 0.0198, G Loss: 5.1762; D Loss Real: 0.0075, ; D Loss Fake: 0.0122, \n",
      "Epoch [95/300], Step [80/234], D Loss: 0.0428, G Loss: 5.3042; D Loss Real: 0.0386, ; D Loss Fake: 0.0042, \n",
      "Epoch [95/300], Step [100/234], D Loss: 0.0198, G Loss: 8.1659; D Loss Real: 0.0195, ; D Loss Fake: 0.0004, \n",
      "Epoch [95/300], Step [120/234], D Loss: 0.0181, G Loss: 7.7950; D Loss Real: 0.0177, ; D Loss Fake: 0.0004, \n",
      "Epoch [95/300], Step [140/234], D Loss: 0.0462, G Loss: 4.0380; D Loss Real: 0.0012, ; D Loss Fake: 0.0451, \n",
      "Epoch [95/300], Step [160/234], D Loss: 0.0053, G Loss: 6.0237; D Loss Real: 0.0023, ; D Loss Fake: 0.0030, \n",
      "Epoch [95/300], Step [180/234], D Loss: 0.0080, G Loss: 13.8349; D Loss Real: 0.0080, ; D Loss Fake: 0.0000, \n",
      "Epoch [95/300], Step [200/234], D Loss: 0.0176, G Loss: 5.0624; D Loss Real: 0.0117, ; D Loss Fake: 0.0060, \n",
      "Epoch [95/300], Step [220/234], D Loss: 0.0076, G Loss: 7.0720; D Loss Real: 0.0022, ; D Loss Fake: 0.0054, \n",
      "Epoch [96/300], Step [20/234], D Loss: 0.0243, G Loss: -0.0053; D Loss Real: 0.0242, ; D Loss Fake: 0.0001, \n",
      "Epoch [96/300], Step [40/234], D Loss: 0.0060, G Loss: 5.8518; D Loss Real: 0.0034, ; D Loss Fake: 0.0026, \n",
      "Epoch [96/300], Step [60/234], D Loss: 0.0115, G Loss: 4.8441; D Loss Real: 0.0010, ; D Loss Fake: 0.0105, \n",
      "Epoch [96/300], Step [80/234], D Loss: 0.0535, G Loss: 3.9025; D Loss Real: 0.0229, ; D Loss Fake: 0.0306, \n",
      "Epoch [96/300], Step [100/234], D Loss: 0.0214, G Loss: 7.8400; D Loss Real: 0.0209, ; D Loss Fake: 0.0005, \n",
      "Epoch [96/300], Step [120/234], D Loss: 0.0082, G Loss: 5.9755; D Loss Real: 0.0070, ; D Loss Fake: 0.0012, \n",
      "Epoch [96/300], Step [140/234], D Loss: 0.0132, G Loss: 13.0394; D Loss Real: 0.0132, ; D Loss Fake: 0.0000, \n",
      "Epoch [96/300], Step [160/234], D Loss: 0.0188, G Loss: 5.5204; D Loss Real: 0.0044, ; D Loss Fake: 0.0144, \n",
      "Epoch [96/300], Step [180/234], D Loss: 0.0106, G Loss: 5.5335; D Loss Real: 0.0020, ; D Loss Fake: 0.0086, \n",
      "Epoch [96/300], Step [200/234], D Loss: 0.0035, G Loss: 7.1689; D Loss Real: 0.0016, ; D Loss Fake: 0.0019, \n",
      "Epoch [96/300], Step [220/234], D Loss: 0.0117, G Loss: 5.6658; D Loss Real: 0.0042, ; D Loss Fake: 0.0075, \n",
      "Epoch [97/300], Step [20/234], D Loss: 0.4689, G Loss: 9.4841; D Loss Real: 0.0005, ; D Loss Fake: 0.4685, \n",
      "Epoch [97/300], Step [40/234], D Loss: 0.0006, G Loss: 0.0181; D Loss Real: 0.0006, ; D Loss Fake: 0.0000, \n",
      "Epoch [97/300], Step [60/234], D Loss: 0.1101, G Loss: 5.3494; D Loss Real: 0.0070, ; D Loss Fake: 0.1031, \n",
      "Epoch [97/300], Step [80/234], D Loss: 0.0133, G Loss: 9.1205; D Loss Real: 0.0132, ; D Loss Fake: 0.0001, \n",
      "Epoch [97/300], Step [100/234], D Loss: 0.0013, G Loss: 8.8000; D Loss Real: 0.0011, ; D Loss Fake: 0.0002, \n",
      "Epoch [97/300], Step [120/234], D Loss: 0.0940, G Loss: 7.2796; D Loss Real: 0.0890, ; D Loss Fake: 0.0050, \n",
      "Epoch [97/300], Step [140/234], D Loss: 0.0060, G Loss: 9.5469; D Loss Real: 0.0058, ; D Loss Fake: 0.0002, \n",
      "Epoch [97/300], Step [160/234], D Loss: 0.0063, G Loss: 6.6986; D Loss Real: 0.0050, ; D Loss Fake: 0.0013, \n",
      "Epoch [97/300], Step [180/234], D Loss: 0.0009, G Loss: 10.5319; D Loss Real: 0.0008, ; D Loss Fake: 0.0001, \n",
      "Epoch [97/300], Step [200/234], D Loss: 0.0084, G Loss: 8.4309; D Loss Real: 0.0080, ; D Loss Fake: 0.0004, \n",
      "Epoch [97/300], Step [220/234], D Loss: 0.0194, G Loss: 6.6554; D Loss Real: 0.0166, ; D Loss Fake: 0.0028, \n",
      "Epoch [98/300], Step [20/234], D Loss: 0.0083, G Loss: 9.2076; D Loss Real: 0.0082, ; D Loss Fake: 0.0001, \n",
      "Epoch [98/300], Step [40/234], D Loss: 0.0067, G Loss: 5.6418; D Loss Real: 0.0042, ; D Loss Fake: 0.0025, \n",
      "Epoch [98/300], Step [60/234], D Loss: 0.0040, G Loss: 5.9982; D Loss Real: 0.0026, ; D Loss Fake: 0.0014, \n",
      "Epoch [98/300], Step [80/234], D Loss: 0.0005, G Loss: 10.0390; D Loss Real: 0.0005, ; D Loss Fake: 0.0000, \n",
      "Epoch [98/300], Step [100/234], D Loss: 0.0099, G Loss: 8.1098; D Loss Real: 0.0085, ; D Loss Fake: 0.0014, \n",
      "Epoch [98/300], Step [120/234], D Loss: 0.0042, G Loss: 6.9426; D Loss Real: 0.0035, ; D Loss Fake: 0.0007, \n",
      "Epoch [98/300], Step [140/234], D Loss: 0.0010, G Loss: 7.5022; D Loss Real: 0.0002, ; D Loss Fake: 0.0008, \n",
      "Epoch [98/300], Step [160/234], D Loss: 0.0008, G Loss: 7.1484; D Loss Real: 0.0003, ; D Loss Fake: 0.0005, \n",
      "Epoch [98/300], Step [180/234], D Loss: 0.0058, G Loss: 6.7330; D Loss Real: 0.0041, ; D Loss Fake: 0.0016, \n",
      "Epoch [98/300], Step [200/234], D Loss: 0.7296, G Loss: 12.4818; D Loss Real: 0.0004, ; D Loss Fake: 0.7293, \n",
      "Epoch [98/300], Step [220/234], D Loss: 0.0086, G Loss: 8.8297; D Loss Real: 0.0085, ; D Loss Fake: 0.0001, \n",
      "Epoch [99/300], Step [20/234], D Loss: 0.1313, G Loss: 10.4553; D Loss Real: 0.0700, ; D Loss Fake: 0.0613, \n",
      "Epoch [99/300], Step [40/234], D Loss: 0.0718, G Loss: 8.8168; D Loss Real: 0.0233, ; D Loss Fake: 0.0484, \n",
      "Epoch [99/300], Step [60/234], D Loss: 0.0064, G Loss: 7.0715; D Loss Real: 0.0054, ; D Loss Fake: 0.0009, \n",
      "Epoch [99/300], Step [80/234], D Loss: 0.1634, G Loss: 7.4980; D Loss Real: 0.0021, ; D Loss Fake: 0.1612, \n",
      "Epoch [99/300], Step [100/234], D Loss: 0.0500, G Loss: 4.3484; D Loss Real: 0.0299, ; D Loss Fake: 0.0201, \n",
      "Epoch [99/300], Step [120/234], D Loss: 0.0060, G Loss: 0.0044; D Loss Real: 0.0016, ; D Loss Fake: 0.0043, \n",
      "Epoch [99/300], Step [140/234], D Loss: 0.0063, G Loss: 6.0060; D Loss Real: 0.0025, ; D Loss Fake: 0.0038, \n",
      "Epoch [99/300], Step [160/234], D Loss: 0.0081, G Loss: 12.0415; D Loss Real: 0.0081, ; D Loss Fake: 0.0000, \n",
      "Epoch [99/300], Step [180/234], D Loss: 0.0019, G Loss: 8.4696; D Loss Real: 0.0012, ; D Loss Fake: 0.0007, \n",
      "Epoch [99/300], Step [200/234], D Loss: 0.1154, G Loss: 0.0280; D Loss Real: 0.1049, ; D Loss Fake: 0.0106, \n",
      "Epoch [99/300], Step [220/234], D Loss: 0.0175, G Loss: 11.0776; D Loss Real: 0.0175, ; D Loss Fake: 0.0000, \n",
      "Epoch [100/300], Step [20/234], D Loss: 0.0216, G Loss: 6.2632; D Loss Real: 0.0031, ; D Loss Fake: 0.0185, \n",
      "Epoch [100/300], Step [40/234], D Loss: 0.0011, G Loss: 9.1176; D Loss Real: 0.0010, ; D Loss Fake: 0.0001, \n",
      "Epoch [100/300], Step [60/234], D Loss: 0.0117, G Loss: 9.3956; D Loss Real: 0.0116, ; D Loss Fake: 0.0002, \n",
      "Epoch [100/300], Step [80/234], D Loss: 0.0020, G Loss: 15.0734; D Loss Real: 0.0020, ; D Loss Fake: 0.0000, \n",
      "Epoch [100/300], Step [100/234], D Loss: 0.0230, G Loss: 12.2273; D Loss Real: 0.0230, ; D Loss Fake: 0.0000, \n",
      "Epoch [100/300], Step [120/234], D Loss: 0.0012, G Loss: 7.6033; D Loss Real: 0.0006, ; D Loss Fake: 0.0007, \n",
      "Epoch [100/300], Step [140/234], D Loss: 0.0151, G Loss: 5.0887; D Loss Real: 0.0086, ; D Loss Fake: 0.0065, \n",
      "Epoch [100/300], Step [160/234], D Loss: 0.0732, G Loss: 7.8930; D Loss Real: 0.0730, ; D Loss Fake: 0.0002, \n",
      "Epoch [100/300], Step [180/234], D Loss: 0.0224, G Loss: 5.7302; D Loss Real: 0.0148, ; D Loss Fake: 0.0075, \n",
      "Epoch [100/300], Step [200/234], D Loss: 0.0033, G Loss: 6.1301; D Loss Real: 0.0012, ; D Loss Fake: 0.0022, \n",
      "Epoch [100/300], Step [220/234], D Loss: 0.0187, G Loss: -0.0003; D Loss Real: 0.0023, ; D Loss Fake: 0.0164, \n",
      "Epoch [101/300], Step [20/234], D Loss: 0.0328, G Loss: 6.2463; D Loss Real: 0.0149, ; D Loss Fake: 0.0178, \n",
      "Epoch [101/300], Step [40/234], D Loss: 0.0308, G Loss: 5.5013; D Loss Real: 0.0066, ; D Loss Fake: 0.0242, \n",
      "Epoch [101/300], Step [60/234], D Loss: 0.0490, G Loss: 4.8293; D Loss Real: 0.0015, ; D Loss Fake: 0.0475, \n",
      "Epoch [101/300], Step [80/234], D Loss: 0.0076, G Loss: 7.4321; D Loss Real: 0.0067, ; D Loss Fake: 0.0009, \n",
      "Epoch [101/300], Step [100/234], D Loss: 0.0069, G Loss: -0.0016; D Loss Real: 0.0069, ; D Loss Fake: 0.0000, \n",
      "Epoch [101/300], Step [120/234], D Loss: 0.0081, G Loss: 8.9532; D Loss Real: 0.0080, ; D Loss Fake: 0.0001, \n",
      "Epoch [101/300], Step [140/234], D Loss: 0.0290, G Loss: 5.5396; D Loss Real: 0.0008, ; D Loss Fake: 0.0283, \n",
      "Epoch [101/300], Step [160/234], D Loss: 0.0098, G Loss: 5.4780; D Loss Real: 0.0063, ; D Loss Fake: 0.0035, \n",
      "Epoch [101/300], Step [180/234], D Loss: 0.0012, G Loss: 10.1796; D Loss Real: 0.0012, ; D Loss Fake: 0.0000, \n",
      "Epoch [101/300], Step [200/234], D Loss: 0.0230, G Loss: 9.0781; D Loss Real: 0.0229, ; D Loss Fake: 0.0001, \n",
      "Epoch [101/300], Step [220/234], D Loss: 0.0173, G Loss: 7.2099; D Loss Real: 0.0166, ; D Loss Fake: 0.0007, \n",
      "Epoch [102/300], Step [20/234], D Loss: 0.6807, G Loss: 2.0608; D Loss Real: 0.6740, ; D Loss Fake: 0.0067, \n",
      "Epoch [102/300], Step [40/234], D Loss: 0.0200, G Loss: -0.0066; D Loss Real: 0.0197, ; D Loss Fake: 0.0003, \n",
      "Epoch [102/300], Step [60/234], D Loss: 0.0101, G Loss: 9.3233; D Loss Real: 0.0100, ; D Loss Fake: 0.0001, \n",
      "Epoch [102/300], Step [80/234], D Loss: 0.0102, G Loss: 5.6688; D Loss Real: 0.0007, ; D Loss Fake: 0.0094, \n",
      "Epoch [102/300], Step [100/234], D Loss: 0.0808, G Loss: 11.0715; D Loss Real: 0.0808, ; D Loss Fake: 0.0000, \n",
      "Epoch [102/300], Step [120/234], D Loss: 0.0422, G Loss: 5.9851; D Loss Real: 0.0013, ; D Loss Fake: 0.0409, \n",
      "Epoch [102/300], Step [140/234], D Loss: 0.0027, G Loss: 7.5371; D Loss Real: 0.0022, ; D Loss Fake: 0.0005, \n",
      "Epoch [102/300], Step [160/234], D Loss: 0.0074, G Loss: 7.2645; D Loss Real: 0.0070, ; D Loss Fake: 0.0004, \n",
      "Epoch [102/300], Step [180/234], D Loss: 0.0083, G Loss: 7.4663; D Loss Real: 0.0077, ; D Loss Fake: 0.0006, \n",
      "Epoch [102/300], Step [200/234], D Loss: 0.4412, G Loss: 11.2569; D Loss Real: 0.0078, ; D Loss Fake: 0.4334, \n",
      "Epoch [102/300], Step [220/234], D Loss: 0.0042, G Loss: 10.5829; D Loss Real: 0.0042, ; D Loss Fake: 0.0000, \n",
      "Epoch [103/300], Step [20/234], D Loss: 0.3432, G Loss: 0.0203; D Loss Real: 0.0072, ; D Loss Fake: 0.3361, \n",
      "Epoch [103/300], Step [40/234], D Loss: 0.0518, G Loss: 4.9522; D Loss Real: 0.0076, ; D Loss Fake: 0.0442, \n",
      "Epoch [103/300], Step [60/234], D Loss: 0.0159, G Loss: 10.2470; D Loss Real: 0.0157, ; D Loss Fake: 0.0002, \n",
      "Epoch [103/300], Step [80/234], D Loss: 0.0482, G Loss: 8.6956; D Loss Real: 0.0481, ; D Loss Fake: 0.0001, \n",
      "Epoch [103/300], Step [100/234], D Loss: 0.0042, G Loss: 5.6155; D Loss Real: 0.0005, ; D Loss Fake: 0.0037, \n",
      "Epoch [103/300], Step [120/234], D Loss: 0.1626, G Loss: 14.8134; D Loss Real: 0.1626, ; D Loss Fake: 0.0000, \n",
      "Epoch [103/300], Step [140/234], D Loss: 0.0035, G Loss: 7.5697; D Loss Real: 0.0032, ; D Loss Fake: 0.0003, \n",
      "Epoch [103/300], Step [160/234], D Loss: 0.2896, G Loss: 14.4752; D Loss Real: 0.2896, ; D Loss Fake: 0.0000, \n",
      "Epoch [103/300], Step [180/234], D Loss: 0.0140, G Loss: 8.2383; D Loss Real: 0.0135, ; D Loss Fake: 0.0005, \n",
      "Epoch [103/300], Step [200/234], D Loss: 0.0021, G Loss: 6.9230; D Loss Real: 0.0013, ; D Loss Fake: 0.0008, \n",
      "Epoch [103/300], Step [220/234], D Loss: 0.0068, G Loss: 7.8699; D Loss Real: 0.0066, ; D Loss Fake: 0.0002, \n",
      "Epoch [104/300], Step [20/234], D Loss: 0.0024, G Loss: 7.3936; D Loss Real: 0.0006, ; D Loss Fake: 0.0017, \n",
      "Epoch [104/300], Step [40/234], D Loss: 0.0172, G Loss: 8.9381; D Loss Real: 0.0171, ; D Loss Fake: 0.0001, \n",
      "Epoch [104/300], Step [60/234], D Loss: 0.0390, G Loss: 6.2975; D Loss Real: 0.0031, ; D Loss Fake: 0.0359, \n",
      "Epoch [104/300], Step [80/234], D Loss: 0.0200, G Loss: 7.4665; D Loss Real: 0.0179, ; D Loss Fake: 0.0021, \n",
      "Epoch [104/300], Step [100/234], D Loss: 0.0104, G Loss: 8.4795; D Loss Real: 0.0084, ; D Loss Fake: 0.0020, \n",
      "Epoch [104/300], Step [120/234], D Loss: 0.0092, G Loss: 5.6091; D Loss Real: 0.0042, ; D Loss Fake: 0.0050, \n",
      "Epoch [104/300], Step [140/234], D Loss: 0.1156, G Loss: 6.6629; D Loss Real: 0.0004, ; D Loss Fake: 0.1152, \n",
      "Epoch [104/300], Step [160/234], D Loss: 0.0121, G Loss: 13.9471; D Loss Real: 0.0121, ; D Loss Fake: 0.0000, \n",
      "Epoch [104/300], Step [180/234], D Loss: 0.0589, G Loss: 5.0273; D Loss Real: 0.0062, ; D Loss Fake: 0.0527, \n",
      "Epoch [104/300], Step [200/234], D Loss: 0.0021, G Loss: 16.3887; D Loss Real: 0.0021, ; D Loss Fake: 0.0000, \n",
      "Epoch [104/300], Step [220/234], D Loss: 0.1168, G Loss: 12.7763; D Loss Real: 0.1168, ; D Loss Fake: 0.0000, \n",
      "Epoch [105/300], Step [20/234], D Loss: 0.0006, G Loss: 13.1669; D Loss Real: 0.0006, ; D Loss Fake: 0.0000, \n",
      "Epoch [105/300], Step [40/234], D Loss: 0.0051, G Loss: 6.0440; D Loss Real: 0.0028, ; D Loss Fake: 0.0023, \n",
      "Epoch [105/300], Step [60/234], D Loss: 0.0028, G Loss: 6.9909; D Loss Real: 0.0007, ; D Loss Fake: 0.0021, \n",
      "Epoch [105/300], Step [80/234], D Loss: 0.0173, G Loss: 5.6634; D Loss Real: 0.0137, ; D Loss Fake: 0.0036, \n",
      "Epoch [105/300], Step [100/234], D Loss: 0.1418, G Loss: 6.3225; D Loss Real: 0.1411, ; D Loss Fake: 0.0007, \n",
      "Epoch [105/300], Step [120/234], D Loss: 0.1237, G Loss: 6.9339; D Loss Real: 0.0002, ; D Loss Fake: 0.1235, \n",
      "Epoch [105/300], Step [140/234], D Loss: 0.4593, G Loss: 13.6458; D Loss Real: 0.0003, ; D Loss Fake: 0.4590, \n",
      "Epoch [105/300], Step [160/234], D Loss: 0.0234, G Loss: 11.1767; D Loss Real: 0.0234, ; D Loss Fake: 0.0000, \n",
      "Epoch [105/300], Step [180/234], D Loss: 0.0029, G Loss: 7.6373; D Loss Real: 0.0026, ; D Loss Fake: 0.0002, \n",
      "Epoch [105/300], Step [200/234], D Loss: 0.0390, G Loss: 5.3825; D Loss Real: 0.0355, ; D Loss Fake: 0.0035, \n",
      "Epoch [105/300], Step [220/234], D Loss: 0.0031, G Loss: 12.7330; D Loss Real: 0.0030, ; D Loss Fake: 0.0000, \n",
      "Epoch [106/300], Step [20/234], D Loss: 0.0499, G Loss: 6.1308; D Loss Real: 0.0010, ; D Loss Fake: 0.0489, \n",
      "Epoch [106/300], Step [40/234], D Loss: 0.0379, G Loss: 5.8662; D Loss Real: 0.0004, ; D Loss Fake: 0.0374, \n",
      "Epoch [106/300], Step [60/234], D Loss: 0.0309, G Loss: 0.0157; D Loss Real: 0.0084, ; D Loss Fake: 0.0225, \n",
      "Epoch [106/300], Step [80/234], D Loss: 0.0084, G Loss: 4.8835; D Loss Real: 0.0011, ; D Loss Fake: 0.0074, \n",
      "Epoch [106/300], Step [100/234], D Loss: 0.0535, G Loss: 4.3270; D Loss Real: 0.0135, ; D Loss Fake: 0.0400, \n",
      "Epoch [106/300], Step [120/234], D Loss: 0.0164, G Loss: 7.1518; D Loss Real: 0.0004, ; D Loss Fake: 0.0160, \n",
      "Epoch [106/300], Step [140/234], D Loss: 0.0214, G Loss: 5.9488; D Loss Real: 0.0104, ; D Loss Fake: 0.0111, \n",
      "Epoch [106/300], Step [160/234], D Loss: 0.0140, G Loss: -0.0009; D Loss Real: 0.0022, ; D Loss Fake: 0.0117, \n",
      "Epoch [106/300], Step [180/234], D Loss: 0.0087, G Loss: 7.5195; D Loss Real: 0.0084, ; D Loss Fake: 0.0003, \n",
      "Epoch [106/300], Step [200/234], D Loss: 0.0134, G Loss: 11.6938; D Loss Real: 0.0134, ; D Loss Fake: 0.0000, \n",
      "Epoch [106/300], Step [220/234], D Loss: 0.0026, G Loss: 7.7357; D Loss Real: 0.0023, ; D Loss Fake: 0.0003, \n",
      "Epoch [107/300], Step [20/234], D Loss: 0.0149, G Loss: 5.1772; D Loss Real: 0.0114, ; D Loss Fake: 0.0035, \n",
      "Epoch [107/300], Step [40/234], D Loss: 0.0997, G Loss: 10.9336; D Loss Real: 0.0997, ; D Loss Fake: 0.0000, \n",
      "Epoch [107/300], Step [60/234], D Loss: 0.0423, G Loss: 5.7270; D Loss Real: 0.0058, ; D Loss Fake: 0.0365, \n",
      "Epoch [107/300], Step [80/234], D Loss: 0.0062, G Loss: 6.0980; D Loss Real: 0.0013, ; D Loss Fake: 0.0049, \n",
      "Epoch [107/300], Step [100/234], D Loss: 0.0111, G Loss: 9.5044; D Loss Real: 0.0110, ; D Loss Fake: 0.0000, \n",
      "Epoch [107/300], Step [120/234], D Loss: 0.0009, G Loss: 8.7321; D Loss Real: 0.0002, ; D Loss Fake: 0.0008, \n",
      "Epoch [107/300], Step [140/234], D Loss: 0.0120, G Loss: 6.2133; D Loss Real: 0.0111, ; D Loss Fake: 0.0010, \n",
      "Epoch [107/300], Step [160/234], D Loss: 0.0114, G Loss: 9.3137; D Loss Real: 0.0113, ; D Loss Fake: 0.0000, \n",
      "Epoch [107/300], Step [180/234], D Loss: 0.0072, G Loss: 11.3366; D Loss Real: 0.0071, ; D Loss Fake: 0.0000, \n",
      "Epoch [107/300], Step [200/234], D Loss: 0.0020, G Loss: 7.8047; D Loss Real: 0.0017, ; D Loss Fake: 0.0003, \n",
      "Epoch [107/300], Step [220/234], D Loss: 0.0056, G Loss: 6.6040; D Loss Real: 0.0019, ; D Loss Fake: 0.0037, \n",
      "Epoch [108/300], Step [20/234], D Loss: 0.1220, G Loss: -0.0027; D Loss Real: 0.0015, ; D Loss Fake: 0.1205, \n",
      "Epoch [108/300], Step [40/234], D Loss: 0.0194, G Loss: 5.8784; D Loss Real: 0.0128, ; D Loss Fake: 0.0066, \n",
      "Epoch [108/300], Step [60/234], D Loss: 0.0374, G Loss: 4.5878; D Loss Real: 0.0262, ; D Loss Fake: 0.0112, \n",
      "Epoch [108/300], Step [80/234], D Loss: 0.0538, G Loss: 7.7033; D Loss Real: 0.0535, ; D Loss Fake: 0.0003, \n",
      "Epoch [108/300], Step [100/234], D Loss: 0.1624, G Loss: 5.4111; D Loss Real: 0.0000, ; D Loss Fake: 0.1624, \n",
      "Epoch [108/300], Step [120/234], D Loss: 0.0387, G Loss: -0.0077; D Loss Real: 0.0109, ; D Loss Fake: 0.0277, \n",
      "Epoch [108/300], Step [140/234], D Loss: 0.0020, G Loss: 9.9020; D Loss Real: 0.0018, ; D Loss Fake: 0.0001, \n",
      "Epoch [108/300], Step [160/234], D Loss: 0.0135, G Loss: 5.0722; D Loss Real: 0.0057, ; D Loss Fake: 0.0079, \n",
      "Epoch [108/300], Step [180/234], D Loss: 0.0052, G Loss: 11.5233; D Loss Real: 0.0052, ; D Loss Fake: 0.0000, \n",
      "Epoch [108/300], Step [200/234], D Loss: 0.2168, G Loss: 13.3004; D Loss Real: 0.2168, ; D Loss Fake: 0.0000, \n",
      "Epoch [108/300], Step [220/234], D Loss: 0.0292, G Loss: 8.9653; D Loss Real: 0.0291, ; D Loss Fake: 0.0001, \n",
      "Epoch [109/300], Step [20/234], D Loss: 0.1701, G Loss: 10.0969; D Loss Real: 0.1700, ; D Loss Fake: 0.0000, \n",
      "Epoch [109/300], Step [40/234], D Loss: 0.0059, G Loss: 10.2843; D Loss Real: 0.0059, ; D Loss Fake: 0.0000, \n",
      "Epoch [109/300], Step [60/234], D Loss: 0.0149, G Loss: 5.8806; D Loss Real: 0.0052, ; D Loss Fake: 0.0097, \n",
      "Epoch [109/300], Step [80/234], D Loss: 0.0951, G Loss: 7.8351; D Loss Real: 0.0003, ; D Loss Fake: 0.0948, \n",
      "Epoch [109/300], Step [100/234], D Loss: 0.0220, G Loss: 9.5366; D Loss Real: 0.0219, ; D Loss Fake: 0.0001, \n",
      "Epoch [109/300], Step [120/234], D Loss: 0.0028, G Loss: 8.3993; D Loss Real: 0.0025, ; D Loss Fake: 0.0003, \n",
      "Epoch [109/300], Step [140/234], D Loss: 0.0040, G Loss: 5.6815; D Loss Real: 0.0007, ; D Loss Fake: 0.0033, \n",
      "Epoch [109/300], Step [160/234], D Loss: 0.4230, G Loss: 10.7063; D Loss Real: 0.0001, ; D Loss Fake: 0.4229, \n",
      "Epoch [109/300], Step [180/234], D Loss: 0.0085, G Loss: 6.7121; D Loss Real: 0.0038, ; D Loss Fake: 0.0047, \n",
      "Epoch [109/300], Step [200/234], D Loss: 0.0216, G Loss: 9.8012; D Loss Real: 0.0215, ; D Loss Fake: 0.0001, \n",
      "Epoch [109/300], Step [220/234], D Loss: 0.0055, G Loss: 8.7502; D Loss Real: 0.0052, ; D Loss Fake: 0.0003, \n",
      "Epoch [110/300], Step [20/234], D Loss: 0.0008, G Loss: 7.8351; D Loss Real: 0.0008, ; D Loss Fake: 0.0000, \n",
      "Epoch [110/300], Step [40/234], D Loss: 0.0098, G Loss: 4.7113; D Loss Real: 0.0027, ; D Loss Fake: 0.0071, \n",
      "Epoch [110/300], Step [60/234], D Loss: 0.0251, G Loss: 4.7049; D Loss Real: 0.0013, ; D Loss Fake: 0.0238, \n",
      "Epoch [110/300], Step [80/234], D Loss: 0.0219, G Loss: 11.4972; D Loss Real: 0.0219, ; D Loss Fake: 0.0000, \n",
      "Epoch [110/300], Step [100/234], D Loss: 0.0147, G Loss: 10.8913; D Loss Real: 0.0146, ; D Loss Fake: 0.0000, \n",
      "Epoch [110/300], Step [120/234], D Loss: 0.8690, G Loss: 10.7644; D Loss Real: 0.0006, ; D Loss Fake: 0.8683, \n",
      "Epoch [110/300], Step [140/234], D Loss: 0.0002, G Loss: 9.1292; D Loss Real: 0.0001, ; D Loss Fake: 0.0001, \n",
      "Epoch [110/300], Step [160/234], D Loss: 0.0013, G Loss: 7.7437; D Loss Real: 0.0007, ; D Loss Fake: 0.0005, \n",
      "Epoch [110/300], Step [180/234], D Loss: 0.0033, G Loss: 12.1828; D Loss Real: 0.0033, ; D Loss Fake: 0.0000, \n",
      "Epoch [110/300], Step [200/234], D Loss: 0.0060, G Loss: 5.7451; D Loss Real: 0.0014, ; D Loss Fake: 0.0046, \n",
      "Epoch [110/300], Step [220/234], D Loss: 0.0243, G Loss: 4.5321; D Loss Real: 0.0084, ; D Loss Fake: 0.0159, \n",
      "Epoch [111/300], Step [20/234], D Loss: 0.0130, G Loss: 10.5034; D Loss Real: 0.0130, ; D Loss Fake: 0.0000, \n",
      "Epoch [111/300], Step [40/234], D Loss: 0.4484, G Loss: 12.3215; D Loss Real: 0.4484, ; D Loss Fake: 0.0000, \n",
      "Epoch [111/300], Step [60/234], D Loss: 0.0144, G Loss: 10.7433; D Loss Real: 0.0144, ; D Loss Fake: 0.0000, \n",
      "Epoch [111/300], Step [80/234], D Loss: 0.0044, G Loss: 5.9192; D Loss Real: 0.0003, ; D Loss Fake: 0.0040, \n",
      "Epoch [111/300], Step [100/234], D Loss: 0.0218, G Loss: 7.4724; D Loss Real: 0.0196, ; D Loss Fake: 0.0022, \n",
      "Epoch [111/300], Step [120/234], D Loss: 0.0029, G Loss: 6.9273; D Loss Real: 0.0010, ; D Loss Fake: 0.0019, \n",
      "Epoch [111/300], Step [140/234], D Loss: 0.0047, G Loss: 14.3279; D Loss Real: 0.0047, ; D Loss Fake: 0.0000, \n",
      "Epoch [111/300], Step [160/234], D Loss: 0.0080, G Loss: 7.8076; D Loss Real: 0.0075, ; D Loss Fake: 0.0004, \n",
      "Epoch [111/300], Step [180/234], D Loss: 0.0183, G Loss: 9.0580; D Loss Real: 0.0138, ; D Loss Fake: 0.0045, \n",
      "Epoch [111/300], Step [200/234], D Loss: 0.0050, G Loss: 5.5420; D Loss Real: 0.0010, ; D Loss Fake: 0.0041, \n",
      "Epoch [111/300], Step [220/234], D Loss: 0.0075, G Loss: 7.5961; D Loss Real: 0.0070, ; D Loss Fake: 0.0005, \n",
      "Epoch [112/300], Step [20/234], D Loss: 0.0253, G Loss: 7.3239; D Loss Real: 0.0001, ; D Loss Fake: 0.0251, \n",
      "Epoch [112/300], Step [40/234], D Loss: 0.0312, G Loss: 6.4177; D Loss Real: 0.0259, ; D Loss Fake: 0.0052, \n",
      "Epoch [112/300], Step [60/234], D Loss: 0.0442, G Loss: 7.1962; D Loss Real: 0.0020, ; D Loss Fake: 0.0421, \n",
      "Epoch [112/300], Step [80/234], D Loss: 0.0096, G Loss: 0.0113; D Loss Real: 0.0094, ; D Loss Fake: 0.0002, \n",
      "Epoch [112/300], Step [100/234], D Loss: 0.0006, G Loss: 7.7848; D Loss Real: 0.0003, ; D Loss Fake: 0.0003, \n",
      "Epoch [112/300], Step [120/234], D Loss: 0.0071, G Loss: 15.9478; D Loss Real: 0.0071, ; D Loss Fake: 0.0000, \n",
      "Epoch [112/300], Step [140/234], D Loss: 0.0133, G Loss: 5.3665; D Loss Real: 0.0022, ; D Loss Fake: 0.0110, \n",
      "Epoch [112/300], Step [160/234], D Loss: 0.0018, G Loss: 7.1053; D Loss Real: 0.0005, ; D Loss Fake: 0.0012, \n",
      "Epoch [112/300], Step [180/234], D Loss: 0.0046, G Loss: 5.6098; D Loss Real: 0.0010, ; D Loss Fake: 0.0036, \n",
      "Epoch [112/300], Step [200/234], D Loss: 0.0012, G Loss: 10.7426; D Loss Real: 0.0012, ; D Loss Fake: 0.0000, \n",
      "Epoch [112/300], Step [220/234], D Loss: 0.0012, G Loss: 8.0359; D Loss Real: 0.0007, ; D Loss Fake: 0.0005, \n",
      "Epoch [113/300], Step [20/234], D Loss: 0.0257, G Loss: 8.4004; D Loss Real: 0.0254, ; D Loss Fake: 0.0003, \n",
      "Epoch [113/300], Step [40/234], D Loss: 0.0303, G Loss: 5.3012; D Loss Real: 0.0142, ; D Loss Fake: 0.0161, \n",
      "Epoch [113/300], Step [60/234], D Loss: 0.0022, G Loss: 8.8245; D Loss Real: 0.0021, ; D Loss Fake: 0.0001, \n",
      "Epoch [113/300], Step [80/234], D Loss: 0.1182, G Loss: 7.0068; D Loss Real: 0.1175, ; D Loss Fake: 0.0007, \n",
      "Epoch [113/300], Step [100/234], D Loss: 0.0016, G Loss: 16.5919; D Loss Real: 0.0016, ; D Loss Fake: 0.0000, \n",
      "Epoch [113/300], Step [120/234], D Loss: 0.0055, G Loss: 7.2750; D Loss Real: 0.0047, ; D Loss Fake: 0.0008, \n",
      "Epoch [113/300], Step [140/234], D Loss: 0.0655, G Loss: 6.3351; D Loss Real: 0.0643, ; D Loss Fake: 0.0013, \n",
      "Epoch [113/300], Step [160/234], D Loss: 0.0032, G Loss: 6.9362; D Loss Real: 0.0021, ; D Loss Fake: 0.0010, \n",
      "Epoch [113/300], Step [180/234], D Loss: 0.0043, G Loss: 6.0414; D Loss Real: 0.0013, ; D Loss Fake: 0.0031, \n",
      "Epoch [113/300], Step [200/234], D Loss: 1.1218, G Loss: -0.0059; D Loss Real: 1.1218, ; D Loss Fake: 0.0000, \n",
      "Epoch [113/300], Step [220/234], D Loss: 0.0949, G Loss: 6.7672; D Loss Real: 0.0921, ; D Loss Fake: 0.0028, \n",
      "Epoch [114/300], Step [20/234], D Loss: 0.0692, G Loss: 13.4268; D Loss Real: 0.0692, ; D Loss Fake: 0.0000, \n",
      "Epoch [114/300], Step [40/234], D Loss: 0.3735, G Loss: 5.7683; D Loss Real: 0.3733, ; D Loss Fake: 0.0002, \n",
      "Epoch [114/300], Step [60/234], D Loss: 0.0322, G Loss: 6.9028; D Loss Real: 0.0286, ; D Loss Fake: 0.0036, \n",
      "Epoch [114/300], Step [80/234], D Loss: 0.0687, G Loss: -0.0054; D Loss Real: 0.0001, ; D Loss Fake: 0.0686, \n",
      "Epoch [114/300], Step [100/234], D Loss: 0.0067, G Loss: 9.0822; D Loss Real: 0.0053, ; D Loss Fake: 0.0014, \n",
      "Epoch [114/300], Step [120/234], D Loss: 0.0988, G Loss: 0.0127; D Loss Real: 0.0008, ; D Loss Fake: 0.0980, \n",
      "Epoch [114/300], Step [140/234], D Loss: 0.0004, G Loss: 10.6035; D Loss Real: 0.0003, ; D Loss Fake: 0.0001, \n",
      "Epoch [114/300], Step [160/234], D Loss: 0.0649, G Loss: 4.5492; D Loss Real: 0.0524, ; D Loss Fake: 0.0125, \n",
      "Epoch [114/300], Step [180/234], D Loss: 0.0066, G Loss: 5.0411; D Loss Real: 0.0025, ; D Loss Fake: 0.0042, \n",
      "Epoch [114/300], Step [200/234], D Loss: 0.4150, G Loss: 0.0076; D Loss Real: 0.0146, ; D Loss Fake: 0.4004, \n",
      "Epoch [114/300], Step [220/234], D Loss: 0.0056, G Loss: 6.9457; D Loss Real: 0.0041, ; D Loss Fake: 0.0014, \n",
      "Epoch [115/300], Step [20/234], D Loss: 0.0014, G Loss: 8.1617; D Loss Real: 0.0013, ; D Loss Fake: 0.0001, \n",
      "Epoch [115/300], Step [40/234], D Loss: 0.0042, G Loss: 9.3369; D Loss Real: 0.0041, ; D Loss Fake: 0.0001, \n",
      "Epoch [115/300], Step [60/234], D Loss: 0.3157, G Loss: 9.5514; D Loss Real: 0.0099, ; D Loss Fake: 0.3058, \n",
      "Epoch [115/300], Step [80/234], D Loss: 0.0114, G Loss: 5.2564; D Loss Real: 0.0016, ; D Loss Fake: 0.0098, \n",
      "Epoch [115/300], Step [100/234], D Loss: 0.0063, G Loss: 9.5475; D Loss Real: 0.0059, ; D Loss Fake: 0.0004, \n",
      "Epoch [115/300], Step [120/234], D Loss: 0.0015, G Loss: 7.0902; D Loss Real: 0.0003, ; D Loss Fake: 0.0012, \n",
      "Epoch [115/300], Step [140/234], D Loss: 0.0166, G Loss: 5.0081; D Loss Real: 0.0030, ; D Loss Fake: 0.0136, \n",
      "Epoch [115/300], Step [160/234], D Loss: 0.0162, G Loss: 7.1605; D Loss Real: 0.0156, ; D Loss Fake: 0.0005, \n",
      "Epoch [115/300], Step [180/234], D Loss: 0.0020, G Loss: 6.8675; D Loss Real: 0.0003, ; D Loss Fake: 0.0017, \n",
      "Epoch [115/300], Step [200/234], D Loss: 0.0028, G Loss: 8.5553; D Loss Real: 0.0024, ; D Loss Fake: 0.0004, \n",
      "Epoch [115/300], Step [220/234], D Loss: 0.0127, G Loss: 8.3818; D Loss Real: 0.0121, ; D Loss Fake: 0.0005, \n",
      "Epoch [116/300], Step [20/234], D Loss: 0.0165, G Loss: 6.9758; D Loss Real: 0.0154, ; D Loss Fake: 0.0012, \n",
      "Epoch [116/300], Step [40/234], D Loss: 0.0056, G Loss: 6.6019; D Loss Real: 0.0028, ; D Loss Fake: 0.0028, \n",
      "Epoch [116/300], Step [60/234], D Loss: 0.0037, G Loss: 7.3713; D Loss Real: 0.0034, ; D Loss Fake: 0.0003, \n",
      "Epoch [116/300], Step [80/234], D Loss: 0.0026, G Loss: 6.5964; D Loss Real: 0.0006, ; D Loss Fake: 0.0019, \n",
      "Epoch [116/300], Step [100/234], D Loss: 0.0004, G Loss: 0.0042; D Loss Real: 0.0003, ; D Loss Fake: 0.0001, \n",
      "Epoch [116/300], Step [120/234], D Loss: 0.0001, G Loss: 29.1760; D Loss Real: 0.0001, ; D Loss Fake: -0.0000, \n",
      "Epoch [116/300], Step [140/234], D Loss: 0.0011, G Loss: 7.5227; D Loss Real: 0.0006, ; D Loss Fake: 0.0004, \n",
      "Epoch [116/300], Step [160/234], D Loss: 0.0010, G Loss: 9.2442; D Loss Real: 0.0007, ; D Loss Fake: 0.0003, \n",
      "Epoch [116/300], Step [180/234], D Loss: 0.0044, G Loss: 6.5213; D Loss Real: 0.0017, ; D Loss Fake: 0.0027, \n",
      "Epoch [116/300], Step [200/234], D Loss: 0.0007, G Loss: 12.5817; D Loss Real: 0.0007, ; D Loss Fake: 0.0000, \n",
      "Epoch [116/300], Step [220/234], D Loss: 0.0400, G Loss: 6.2461; D Loss Real: 0.0004, ; D Loss Fake: 0.0397, \n",
      "Epoch [117/300], Step [20/234], D Loss: 0.0334, G Loss: 5.1856; D Loss Real: 0.0001, ; D Loss Fake: 0.0333, \n",
      "Epoch [117/300], Step [40/234], D Loss: 0.0052, G Loss: 9.5990; D Loss Real: 0.0050, ; D Loss Fake: 0.0002, \n",
      "Epoch [117/300], Step [60/234], D Loss: 0.0471, G Loss: 5.8591; D Loss Real: 0.0204, ; D Loss Fake: 0.0268, \n",
      "Epoch [117/300], Step [80/234], D Loss: 0.0152, G Loss: 7.0993; D Loss Real: 0.0075, ; D Loss Fake: 0.0077, \n",
      "Epoch [117/300], Step [100/234], D Loss: 0.0038, G Loss: 9.7000; D Loss Real: 0.0037, ; D Loss Fake: 0.0001, \n",
      "Epoch [117/300], Step [120/234], D Loss: 0.0068, G Loss: 5.7832; D Loss Real: 0.0019, ; D Loss Fake: 0.0049, \n",
      "Epoch [117/300], Step [140/234], D Loss: 0.0140, G Loss: 5.3768; D Loss Real: 0.0051, ; D Loss Fake: 0.0089, \n",
      "Epoch [117/300], Step [160/234], D Loss: 0.1717, G Loss: 6.0582; D Loss Real: 0.1710, ; D Loss Fake: 0.0007, \n",
      "Epoch [117/300], Step [180/234], D Loss: 0.0285, G Loss: 6.7626; D Loss Real: 0.0180, ; D Loss Fake: 0.0105, \n",
      "Epoch [117/300], Step [200/234], D Loss: 0.6807, G Loss: 5.1833; D Loss Real: 0.6806, ; D Loss Fake: 0.0001, \n",
      "Epoch [117/300], Step [220/234], D Loss: 0.0117, G Loss: 6.9308; D Loss Real: 0.0039, ; D Loss Fake: 0.0079, \n",
      "Epoch [118/300], Step [20/234], D Loss: 0.5633, G Loss: -0.0049; D Loss Real: 0.5633, ; D Loss Fake: 0.0000, \n",
      "Epoch [118/300], Step [40/234], D Loss: 0.1672, G Loss: 7.1841; D Loss Real: 0.0017, ; D Loss Fake: 0.1656, \n",
      "Epoch [118/300], Step [60/234], D Loss: 0.5824, G Loss: 11.1311; D Loss Real: 0.5824, ; D Loss Fake: 0.0000, \n",
      "Epoch [118/300], Step [80/234], D Loss: 0.2215, G Loss: 7.8885; D Loss Real: 0.2213, ; D Loss Fake: 0.0002, \n",
      "Epoch [118/300], Step [100/234], D Loss: 0.0099, G Loss: 5.7631; D Loss Real: 0.0040, ; D Loss Fake: 0.0059, \n",
      "Epoch [118/300], Step [120/234], D Loss: 0.0202, G Loss: 6.7555; D Loss Real: 0.0175, ; D Loss Fake: 0.0026, \n",
      "Epoch [118/300], Step [140/234], D Loss: 0.0021, G Loss: 9.4557; D Loss Real: 0.0020, ; D Loss Fake: 0.0000, \n",
      "Epoch [118/300], Step [160/234], D Loss: 0.1117, G Loss: 5.5657; D Loss Real: 0.0023, ; D Loss Fake: 0.1094, \n",
      "Epoch [118/300], Step [180/234], D Loss: 0.0327, G Loss: 11.7715; D Loss Real: 0.0327, ; D Loss Fake: 0.0000, \n",
      "Epoch [118/300], Step [200/234], D Loss: 0.0048, G Loss: 8.7425; D Loss Real: 0.0047, ; D Loss Fake: 0.0001, \n",
      "Epoch [118/300], Step [220/234], D Loss: 0.0326, G Loss: 13.8577; D Loss Real: 0.0326, ; D Loss Fake: 0.0000, \n",
      "Epoch [119/300], Step [20/234], D Loss: 0.4299, G Loss: 11.4052; D Loss Real: 0.4298, ; D Loss Fake: 0.0001, \n",
      "Epoch [119/300], Step [40/234], D Loss: 0.0199, G Loss: 0.0019; D Loss Real: 0.0048, ; D Loss Fake: 0.0151, \n",
      "Epoch [119/300], Step [60/234], D Loss: 0.1697, G Loss: 9.8380; D Loss Real: 0.1694, ; D Loss Fake: 0.0003, \n",
      "Epoch [119/300], Step [80/234], D Loss: 0.0082, G Loss: 15.9544; D Loss Real: 0.0082, ; D Loss Fake: 0.0000, \n",
      "Epoch [119/300], Step [100/234], D Loss: 0.1364, G Loss: 5.9642; D Loss Real: 0.0024, ; D Loss Fake: 0.1340, \n",
      "Epoch [119/300], Step [120/234], D Loss: 0.7819, G Loss: 8.7551; D Loss Real: 0.7793, ; D Loss Fake: 0.0026, \n",
      "Epoch [119/300], Step [140/234], D Loss: 0.0016, G Loss: 8.8319; D Loss Real: 0.0015, ; D Loss Fake: 0.0001, \n",
      "Epoch [119/300], Step [160/234], D Loss: 0.2595, G Loss: 7.4826; D Loss Real: 0.2595, ; D Loss Fake: 0.0000, \n",
      "Epoch [119/300], Step [180/234], D Loss: 0.0090, G Loss: 7.2331; D Loss Real: 0.0055, ; D Loss Fake: 0.0035, \n",
      "Epoch [119/300], Step [200/234], D Loss: 0.0011, G Loss: 11.8574; D Loss Real: 0.0011, ; D Loss Fake: 0.0000, \n",
      "Epoch [119/300], Step [220/234], D Loss: 0.0044, G Loss: 7.3606; D Loss Real: 0.0035, ; D Loss Fake: 0.0009, \n",
      "Epoch [120/300], Step [20/234], D Loss: 0.0094, G Loss: -0.0006; D Loss Real: 0.0084, ; D Loss Fake: 0.0010, \n",
      "Epoch [120/300], Step [40/234], D Loss: 0.0679, G Loss: 9.9493; D Loss Real: 0.0679, ; D Loss Fake: 0.0000, \n",
      "Epoch [120/300], Step [60/234], D Loss: 0.0032, G Loss: 8.3095; D Loss Real: 0.0030, ; D Loss Fake: 0.0002, \n",
      "Epoch [120/300], Step [80/234], D Loss: 0.0648, G Loss: 12.1084; D Loss Real: 0.0648, ; D Loss Fake: 0.0000, \n",
      "Epoch [120/300], Step [100/234], D Loss: 0.0197, G Loss: 5.2568; D Loss Real: 0.0007, ; D Loss Fake: 0.0190, \n",
      "Epoch [120/300], Step [120/234], D Loss: 0.0034, G Loss: 6.4700; D Loss Real: 0.0001, ; D Loss Fake: 0.0033, \n",
      "Epoch [120/300], Step [140/234], D Loss: 0.0118, G Loss: 6.5069; D Loss Real: 0.0093, ; D Loss Fake: 0.0025, \n",
      "Epoch [120/300], Step [160/234], D Loss: 0.0120, G Loss: 5.0163; D Loss Real: 0.0006, ; D Loss Fake: 0.0113, \n",
      "Epoch [120/300], Step [180/234], D Loss: 0.0032, G Loss: 12.6708; D Loss Real: 0.0032, ; D Loss Fake: 0.0000, \n",
      "Epoch [120/300], Step [200/234], D Loss: 0.0043, G Loss: 7.5065; D Loss Real: 0.0039, ; D Loss Fake: 0.0004, \n",
      "Epoch [120/300], Step [220/234], D Loss: 0.0460, G Loss: 0.0270; D Loss Real: 0.0027, ; D Loss Fake: 0.0433, \n",
      "Epoch [121/300], Step [20/234], D Loss: 0.0038, G Loss: 6.6089; D Loss Real: 0.0013, ; D Loss Fake: 0.0025, \n",
      "Epoch [121/300], Step [40/234], D Loss: 0.0100, G Loss: 6.1504; D Loss Real: 0.0074, ; D Loss Fake: 0.0026, \n",
      "Epoch [121/300], Step [60/234], D Loss: 0.0356, G Loss: 5.8603; D Loss Real: 0.0324, ; D Loss Fake: 0.0032, \n",
      "Epoch [121/300], Step [80/234], D Loss: 0.0188, G Loss: 5.9193; D Loss Real: 0.0059, ; D Loss Fake: 0.0129, \n",
      "Epoch [121/300], Step [100/234], D Loss: 0.0021, G Loss: 0.0024; D Loss Real: 0.0011, ; D Loss Fake: 0.0010, \n",
      "Epoch [121/300], Step [120/234], D Loss: 0.0125, G Loss: 5.0263; D Loss Real: 0.0035, ; D Loss Fake: 0.0090, \n",
      "Epoch [121/300], Step [140/234], D Loss: 0.0515, G Loss: 0.0052; D Loss Real: 0.0469, ; D Loss Fake: 0.0046, \n",
      "Epoch [121/300], Step [160/234], D Loss: 0.0204, G Loss: 7.6828; D Loss Real: 0.0201, ; D Loss Fake: 0.0003, \n",
      "Epoch [121/300], Step [180/234], D Loss: 0.0129, G Loss: -0.0014; D Loss Real: 0.0126, ; D Loss Fake: 0.0003, \n",
      "Epoch [121/300], Step [200/234], D Loss: 0.0403, G Loss: 5.7943; D Loss Real: 0.0018, ; D Loss Fake: 0.0384, \n",
      "Epoch [121/300], Step [220/234], D Loss: 0.0148, G Loss: 5.9373; D Loss Real: 0.0043, ; D Loss Fake: 0.0105, \n",
      "Epoch [122/300], Step [20/234], D Loss: 0.3038, G Loss: 6.4307; D Loss Real: 0.0696, ; D Loss Fake: 0.2342, \n",
      "Epoch [122/300], Step [40/234], D Loss: 0.0413, G Loss: 4.9493; D Loss Real: 0.0166, ; D Loss Fake: 0.0247, \n",
      "Epoch [122/300], Step [60/234], D Loss: 0.2924, G Loss: 5.7567; D Loss Real: 0.2900, ; D Loss Fake: 0.0024, \n",
      "Epoch [122/300], Step [80/234], D Loss: 0.2400, G Loss: 5.9856; D Loss Real: 0.2374, ; D Loss Fake: 0.0026, \n",
      "Epoch [122/300], Step [100/234], D Loss: 0.0271, G Loss: 5.4580; D Loss Real: 0.0167, ; D Loss Fake: 0.0104, \n",
      "Epoch [122/300], Step [120/234], D Loss: 0.0201, G Loss: 4.7875; D Loss Real: 0.0001, ; D Loss Fake: 0.0200, \n",
      "Epoch [122/300], Step [140/234], D Loss: 0.0156, G Loss: 5.4251; D Loss Real: 0.0046, ; D Loss Fake: 0.0110, \n",
      "Epoch [122/300], Step [160/234], D Loss: 0.0090, G Loss: 8.4091; D Loss Real: 0.0087, ; D Loss Fake: 0.0002, \n",
      "Epoch [122/300], Step [180/234], D Loss: 0.4584, G Loss: 9.6019; D Loss Real: 0.4584, ; D Loss Fake: 0.0000, \n",
      "Epoch [122/300], Step [200/234], D Loss: 0.0135, G Loss: 5.2426; D Loss Real: 0.0072, ; D Loss Fake: 0.0062, \n",
      "Epoch [122/300], Step [220/234], D Loss: 0.0962, G Loss: 5.6803; D Loss Real: 0.0006, ; D Loss Fake: 0.0956, \n",
      "Epoch [123/300], Step [20/234], D Loss: 0.0458, G Loss: 0.0033; D Loss Real: 0.0124, ; D Loss Fake: 0.0334, \n",
      "Epoch [123/300], Step [40/234], D Loss: 0.0223, G Loss: 6.2066; D Loss Real: 0.0196, ; D Loss Fake: 0.0027, \n",
      "Epoch [123/300], Step [60/234], D Loss: 0.0468, G Loss: 6.2157; D Loss Real: 0.0459, ; D Loss Fake: 0.0009, \n",
      "Epoch [123/300], Step [80/234], D Loss: 0.0308, G Loss: 0.0107; D Loss Real: 0.0008, ; D Loss Fake: 0.0300, \n",
      "Epoch [123/300], Step [100/234], D Loss: 0.0069, G Loss: 5.6523; D Loss Real: 0.0043, ; D Loss Fake: 0.0025, \n",
      "Epoch [123/300], Step [120/234], D Loss: 0.0168, G Loss: 6.0195; D Loss Real: 0.0108, ; D Loss Fake: 0.0060, \n",
      "Epoch [123/300], Step [140/234], D Loss: 0.0145, G Loss: 7.7163; D Loss Real: 0.0139, ; D Loss Fake: 0.0006, \n",
      "Epoch [123/300], Step [160/234], D Loss: 0.0135, G Loss: 5.1731; D Loss Real: 0.0039, ; D Loss Fake: 0.0096, \n",
      "Epoch [123/300], Step [180/234], D Loss: 0.0865, G Loss: 12.6490; D Loss Real: 0.0864, ; D Loss Fake: 0.0000, \n",
      "Epoch [123/300], Step [200/234], D Loss: 0.0325, G Loss: 6.5200; D Loss Real: 0.0318, ; D Loss Fake: 0.0007, \n",
      "Epoch [123/300], Step [220/234], D Loss: 0.0232, G Loss: 7.0240; D Loss Real: 0.0154, ; D Loss Fake: 0.0078, \n",
      "Epoch [124/300], Step [20/234], D Loss: 0.3766, G Loss: 9.6758; D Loss Real: 0.0210, ; D Loss Fake: 0.3556, \n",
      "Epoch [124/300], Step [40/234], D Loss: 0.0825, G Loss: 12.4042; D Loss Real: 0.0824, ; D Loss Fake: 0.0001, \n",
      "Epoch [124/300], Step [60/234], D Loss: 0.0059, G Loss: 7.5960; D Loss Real: 0.0038, ; D Loss Fake: 0.0022, \n",
      "Epoch [124/300], Step [80/234], D Loss: 0.0129, G Loss: 5.0895; D Loss Real: 0.0022, ; D Loss Fake: 0.0107, \n",
      "Epoch [124/300], Step [100/234], D Loss: 0.0019, G Loss: 8.6754; D Loss Real: 0.0015, ; D Loss Fake: 0.0004, \n",
      "Epoch [124/300], Step [120/234], D Loss: 0.0558, G Loss: 5.3504; D Loss Real: 0.0278, ; D Loss Fake: 0.0280, \n",
      "Epoch [124/300], Step [140/234], D Loss: 0.1161, G Loss: -0.0092; D Loss Real: 0.1159, ; D Loss Fake: 0.0002, \n",
      "Epoch [124/300], Step [160/234], D Loss: 0.0207, G Loss: 8.3961; D Loss Real: 0.0204, ; D Loss Fake: 0.0003, \n",
      "Epoch [124/300], Step [180/234], D Loss: 0.0673, G Loss: 7.3363; D Loss Real: 0.0669, ; D Loss Fake: 0.0003, \n",
      "Epoch [124/300], Step [200/234], D Loss: 0.0137, G Loss: 11.6223; D Loss Real: 0.0137, ; D Loss Fake: 0.0000, \n",
      "Epoch [124/300], Step [220/234], D Loss: 0.0066, G Loss: 5.5635; D Loss Real: 0.0011, ; D Loss Fake: 0.0056, \n",
      "Epoch [125/300], Step [20/234], D Loss: 0.0042, G Loss: 7.0781; D Loss Real: 0.0027, ; D Loss Fake: 0.0014, \n",
      "Epoch [125/300], Step [40/234], D Loss: 0.0042, G Loss: 6.7232; D Loss Real: 0.0031, ; D Loss Fake: 0.0011, \n",
      "Epoch [125/300], Step [60/234], D Loss: 0.0552, G Loss: 4.1929; D Loss Real: 0.0287, ; D Loss Fake: 0.0265, \n",
      "Epoch [125/300], Step [80/234], D Loss: 0.1372, G Loss: 4.1116; D Loss Real: 0.1200, ; D Loss Fake: 0.0173, \n",
      "Epoch [125/300], Step [100/234], D Loss: 0.0223, G Loss: 5.1178; D Loss Real: 0.0158, ; D Loss Fake: 0.0065, \n",
      "Epoch [125/300], Step [120/234], D Loss: 0.0069, G Loss: 6.8027; D Loss Real: 0.0041, ; D Loss Fake: 0.0028, \n",
      "Epoch [125/300], Step [140/234], D Loss: 0.0244, G Loss: 4.5485; D Loss Real: 0.0062, ; D Loss Fake: 0.0183, \n",
      "Epoch [125/300], Step [160/234], D Loss: 0.0024, G Loss: 7.6494; D Loss Real: 0.0022, ; D Loss Fake: 0.0003, \n",
      "Epoch [125/300], Step [180/234], D Loss: 0.0664, G Loss: 5.6196; D Loss Real: 0.0638, ; D Loss Fake: 0.0026, \n",
      "Epoch [125/300], Step [200/234], D Loss: 0.0248, G Loss: -0.0081; D Loss Real: 0.0238, ; D Loss Fake: 0.0010, \n",
      "Epoch [125/300], Step [220/234], D Loss: 0.0084, G Loss: 5.5037; D Loss Real: 0.0047, ; D Loss Fake: 0.0038, \n",
      "Epoch [126/300], Step [20/234], D Loss: 0.0012, G Loss: 7.8679; D Loss Real: 0.0007, ; D Loss Fake: 0.0005, \n",
      "Epoch [126/300], Step [40/234], D Loss: 0.0171, G Loss: 4.6665; D Loss Real: 0.0006, ; D Loss Fake: 0.0165, \n",
      "Epoch [126/300], Step [60/234], D Loss: 0.0033, G Loss: 18.6829; D Loss Real: 0.0033, ; D Loss Fake: -0.0000, \n",
      "Epoch [126/300], Step [80/234], D Loss: 0.3664, G Loss: 9.2754; D Loss Real: 0.0009, ; D Loss Fake: 0.3655, \n",
      "Epoch [126/300], Step [100/234], D Loss: 0.0028, G Loss: 12.0310; D Loss Real: 0.0028, ; D Loss Fake: 0.0000, \n",
      "Epoch [126/300], Step [120/234], D Loss: 0.0026, G Loss: 7.4497; D Loss Real: 0.0017, ; D Loss Fake: 0.0010, \n",
      "Epoch [126/300], Step [140/234], D Loss: 0.0017, G Loss: 0.0013; D Loss Real: 0.0011, ; D Loss Fake: 0.0006, \n",
      "Epoch [126/300], Step [160/234], D Loss: 0.0137, G Loss: -0.0102; D Loss Real: 0.0137, ; D Loss Fake: 0.0000, \n",
      "Epoch [126/300], Step [180/234], D Loss: 0.0046, G Loss: 9.4030; D Loss Real: 0.0043, ; D Loss Fake: 0.0003, \n",
      "Epoch [126/300], Step [200/234], D Loss: 0.0006, G Loss: 8.7502; D Loss Real: 0.0003, ; D Loss Fake: 0.0003, \n",
      "Epoch [126/300], Step [220/234], D Loss: 0.0649, G Loss: 8.8391; D Loss Real: 0.0647, ; D Loss Fake: 0.0001, \n",
      "Epoch [127/300], Step [20/234], D Loss: 0.0043, G Loss: 0.0037; D Loss Real: 0.0024, ; D Loss Fake: 0.0020, \n",
      "Epoch [127/300], Step [40/234], D Loss: 0.0055, G Loss: 6.3835; D Loss Real: 0.0039, ; D Loss Fake: 0.0016, \n",
      "Epoch [127/300], Step [60/234], D Loss: 0.1906, G Loss: 10.6472; D Loss Real: 0.1906, ; D Loss Fake: 0.0000, \n",
      "Epoch [127/300], Step [80/234], D Loss: 0.0072, G Loss: 15.3746; D Loss Real: 0.0072, ; D Loss Fake: 0.0000, \n",
      "Epoch [127/300], Step [100/234], D Loss: 0.0199, G Loss: 8.4682; D Loss Real: 0.0197, ; D Loss Fake: 0.0002, \n",
      "Epoch [127/300], Step [120/234], D Loss: 0.1801, G Loss: 6.0160; D Loss Real: 0.0002, ; D Loss Fake: 0.1799, \n",
      "Epoch [127/300], Step [140/234], D Loss: 0.0262, G Loss: 5.5665; D Loss Real: 0.0233, ; D Loss Fake: 0.0029, \n",
      "Epoch [127/300], Step [160/234], D Loss: 0.0473, G Loss: 4.7314; D Loss Real: 0.0236, ; D Loss Fake: 0.0237, \n",
      "Epoch [127/300], Step [180/234], D Loss: 0.0020, G Loss: 0.0106; D Loss Real: 0.0008, ; D Loss Fake: 0.0012, \n",
      "Epoch [127/300], Step [200/234], D Loss: 0.0156, G Loss: 8.2494; D Loss Real: 0.0155, ; D Loss Fake: 0.0001, \n",
      "Epoch [127/300], Step [220/234], D Loss: 0.0177, G Loss: 6.0356; D Loss Real: 0.0162, ; D Loss Fake: 0.0015, \n",
      "Epoch [128/300], Step [20/234], D Loss: 0.0132, G Loss: 9.1111; D Loss Real: 0.0118, ; D Loss Fake: 0.0015, \n",
      "Epoch [128/300], Step [40/234], D Loss: 0.0034, G Loss: 15.7657; D Loss Real: 0.0034, ; D Loss Fake: 0.0000, \n",
      "Epoch [128/300], Step [60/234], D Loss: 0.0358, G Loss: 9.5654; D Loss Real: 0.0351, ; D Loss Fake: 0.0007, \n",
      "Epoch [128/300], Step [80/234], D Loss: 0.0022, G Loss: 9.7957; D Loss Real: 0.0022, ; D Loss Fake: 0.0001, \n",
      "Epoch [128/300], Step [100/234], D Loss: 0.0200, G Loss: 6.8392; D Loss Real: 0.0002, ; D Loss Fake: 0.0198, \n",
      "Epoch [128/300], Step [120/234], D Loss: 0.0178, G Loss: 13.2899; D Loss Real: 0.0178, ; D Loss Fake: 0.0000, \n",
      "Epoch [128/300], Step [140/234], D Loss: 0.0288, G Loss: 4.4434; D Loss Real: 0.0224, ; D Loss Fake: 0.0064, \n",
      "Epoch [128/300], Step [160/234], D Loss: 0.1861, G Loss: 6.5697; D Loss Real: 0.0114, ; D Loss Fake: 0.1746, \n",
      "Epoch [128/300], Step [180/234], D Loss: 0.1597, G Loss: 6.7153; D Loss Real: 0.0002, ; D Loss Fake: 0.1595, \n",
      "Epoch [128/300], Step [200/234], D Loss: 0.0441, G Loss: 5.8278; D Loss Real: 0.0016, ; D Loss Fake: 0.0426, \n",
      "Epoch [128/300], Step [220/234], D Loss: 0.0063, G Loss: 8.6533; D Loss Real: 0.0062, ; D Loss Fake: 0.0001, \n",
      "Epoch [129/300], Step [20/234], D Loss: 0.0009, G Loss: 10.5240; D Loss Real: 0.0008, ; D Loss Fake: 0.0001, \n",
      "Epoch [129/300], Step [40/234], D Loss: 0.0059, G Loss: 10.7698; D Loss Real: 0.0059, ; D Loss Fake: 0.0000, \n",
      "Epoch [129/300], Step [60/234], D Loss: 0.0151, G Loss: 8.1215; D Loss Real: 0.0078, ; D Loss Fake: 0.0073, \n",
      "Epoch [129/300], Step [80/234], D Loss: 0.0656, G Loss: 10.1200; D Loss Real: 0.0645, ; D Loss Fake: 0.0011, \n",
      "Epoch [129/300], Step [100/234], D Loss: 0.0058, G Loss: 8.8702; D Loss Real: 0.0056, ; D Loss Fake: 0.0002, \n",
      "Epoch [129/300], Step [120/234], D Loss: 0.0032, G Loss: 8.0646; D Loss Real: 0.0005, ; D Loss Fake: 0.0026, \n",
      "Epoch [129/300], Step [140/234], D Loss: 0.0030, G Loss: 6.2071; D Loss Real: 0.0004, ; D Loss Fake: 0.0026, \n",
      "Epoch [129/300], Step [160/234], D Loss: 0.0517, G Loss: 6.1469; D Loss Real: 0.0035, ; D Loss Fake: 0.0482, \n",
      "Epoch [129/300], Step [180/234], D Loss: 0.0015, G Loss: 8.7352; D Loss Real: 0.0014, ; D Loss Fake: 0.0001, \n",
      "Epoch [129/300], Step [200/234], D Loss: 0.0055, G Loss: 8.4406; D Loss Real: 0.0048, ; D Loss Fake: 0.0008, \n",
      "Epoch [129/300], Step [220/234], D Loss: 0.0411, G Loss: 12.1807; D Loss Real: 0.0411, ; D Loss Fake: 0.0000, \n",
      "Epoch [130/300], Step [20/234], D Loss: 0.0796, G Loss: 12.4144; D Loss Real: 0.0771, ; D Loss Fake: 0.0025, \n",
      "Epoch [130/300], Step [40/234], D Loss: 0.0016, G Loss: -0.0178; D Loss Real: 0.0008, ; D Loss Fake: 0.0008, \n",
      "Epoch [130/300], Step [60/234], D Loss: 0.0188, G Loss: 6.1053; D Loss Real: 0.0004, ; D Loss Fake: 0.0184, \n",
      "Epoch [130/300], Step [80/234], D Loss: 0.0314, G Loss: 0.0020; D Loss Real: 0.0014, ; D Loss Fake: 0.0301, \n",
      "Epoch [130/300], Step [100/234], D Loss: 0.0785, G Loss: 5.3320; D Loss Real: 0.0015, ; D Loss Fake: 0.0770, \n",
      "Epoch [130/300], Step [120/234], D Loss: 0.0058, G Loss: 8.1735; D Loss Real: 0.0054, ; D Loss Fake: 0.0004, \n",
      "Epoch [130/300], Step [140/234], D Loss: 0.1348, G Loss: 5.7559; D Loss Real: 0.0010, ; D Loss Fake: 0.1339, \n",
      "Epoch [130/300], Step [160/234], D Loss: 0.0718, G Loss: 7.2351; D Loss Real: 0.0708, ; D Loss Fake: 0.0010, \n",
      "Epoch [130/300], Step [180/234], D Loss: 0.0244, G Loss: 8.2976; D Loss Real: 0.0230, ; D Loss Fake: 0.0014, \n",
      "Epoch [130/300], Step [200/234], D Loss: 0.0020, G Loss: 9.4760; D Loss Real: 0.0019, ; D Loss Fake: 0.0001, \n",
      "Epoch [130/300], Step [220/234], D Loss: 0.0268, G Loss: 5.2158; D Loss Real: 0.0097, ; D Loss Fake: 0.0171, \n",
      "Epoch [131/300], Step [20/234], D Loss: 0.0329, G Loss: 11.8833; D Loss Real: 0.0329, ; D Loss Fake: 0.0000, \n",
      "Epoch [131/300], Step [40/234], D Loss: 0.0099, G Loss: 5.8176; D Loss Real: 0.0068, ; D Loss Fake: 0.0031, \n",
      "Epoch [131/300], Step [60/234], D Loss: 0.0240, G Loss: 5.8438; D Loss Real: 0.0083, ; D Loss Fake: 0.0158, \n",
      "Epoch [131/300], Step [80/234], D Loss: 0.0025, G Loss: 11.6704; D Loss Real: 0.0025, ; D Loss Fake: 0.0000, \n",
      "Epoch [131/300], Step [100/234], D Loss: 0.0494, G Loss: 8.3768; D Loss Real: 0.0493, ; D Loss Fake: 0.0001, \n",
      "Epoch [131/300], Step [120/234], D Loss: 0.0101, G Loss: 5.0357; D Loss Real: 0.0024, ; D Loss Fake: 0.0077, \n",
      "Epoch [131/300], Step [140/234], D Loss: 0.0010, G Loss: 10.6964; D Loss Real: 0.0009, ; D Loss Fake: 0.0000, \n",
      "Epoch [131/300], Step [160/234], D Loss: 0.0024, G Loss: 5.8606; D Loss Real: 0.0005, ; D Loss Fake: 0.0019, \n",
      "Epoch [131/300], Step [180/234], D Loss: 0.0116, G Loss: 0.0061; D Loss Real: 0.0108, ; D Loss Fake: 0.0007, \n",
      "Epoch [131/300], Step [200/234], D Loss: 0.0101, G Loss: 4.9314; D Loss Real: 0.0025, ; D Loss Fake: 0.0076, \n",
      "Epoch [131/300], Step [220/234], D Loss: 0.0073, G Loss: 12.2943; D Loss Real: 0.0072, ; D Loss Fake: 0.0000, \n",
      "Epoch [132/300], Step [20/234], D Loss: 0.0083, G Loss: 0.0002; D Loss Real: 0.0026, ; D Loss Fake: 0.0057, \n",
      "Epoch [132/300], Step [40/234], D Loss: 0.0064, G Loss: 8.8709; D Loss Real: 0.0062, ; D Loss Fake: 0.0002, \n",
      "Epoch [132/300], Step [60/234], D Loss: 0.0111, G Loss: 10.5114; D Loss Real: 0.0111, ; D Loss Fake: 0.0000, \n",
      "Epoch [132/300], Step [80/234], D Loss: 0.0005, G Loss: 0.0049; D Loss Real: 0.0003, ; D Loss Fake: 0.0002, \n",
      "Epoch [132/300], Step [100/234], D Loss: 0.0143, G Loss: 6.6374; D Loss Real: 0.0059, ; D Loss Fake: 0.0084, \n",
      "Epoch [132/300], Step [120/234], D Loss: 0.0059, G Loss: 5.8568; D Loss Real: 0.0027, ; D Loss Fake: 0.0032, \n",
      "Epoch [132/300], Step [140/234], D Loss: 0.0009, G Loss: 8.4697; D Loss Real: 0.0005, ; D Loss Fake: 0.0004, \n",
      "Epoch [132/300], Step [160/234], D Loss: 0.0032, G Loss: 7.0653; D Loss Real: 0.0021, ; D Loss Fake: 0.0011, \n",
      "Epoch [132/300], Step [180/234], D Loss: 0.0941, G Loss: 0.0039; D Loss Real: 0.0005, ; D Loss Fake: 0.0936, \n",
      "Epoch [132/300], Step [200/234], D Loss: 0.0469, G Loss: 5.0722; D Loss Real: 0.0109, ; D Loss Fake: 0.0360, \n",
      "Epoch [132/300], Step [220/234], D Loss: 0.3419, G Loss: 17.2450; D Loss Real: 0.3419, ; D Loss Fake: -0.0000, \n",
      "Epoch [133/300], Step [20/234], D Loss: 0.0812, G Loss: 5.2903; D Loss Real: 0.0399, ; D Loss Fake: 0.0414, \n",
      "Epoch [133/300], Step [40/234], D Loss: 0.0025, G Loss: 10.9800; D Loss Real: 0.0024, ; D Loss Fake: 0.0000, \n",
      "Epoch [133/300], Step [60/234], D Loss: 0.1095, G Loss: 11.0529; D Loss Real: 0.1095, ; D Loss Fake: 0.0000, \n",
      "Epoch [133/300], Step [80/234], D Loss: 0.0223, G Loss: 6.6890; D Loss Real: 0.0037, ; D Loss Fake: 0.0186, \n",
      "Epoch [133/300], Step [100/234], D Loss: 0.0298, G Loss: -0.0016; D Loss Real: 0.0262, ; D Loss Fake: 0.0036, \n",
      "Epoch [133/300], Step [120/234], D Loss: 0.0122, G Loss: 9.7634; D Loss Real: 0.0121, ; D Loss Fake: 0.0001, \n",
      "Epoch [133/300], Step [140/234], D Loss: 0.0032, G Loss: 7.0470; D Loss Real: 0.0024, ; D Loss Fake: 0.0008, \n",
      "Epoch [133/300], Step [160/234], D Loss: 0.0023, G Loss: 9.4742; D Loss Real: 0.0022, ; D Loss Fake: 0.0001, \n",
      "Epoch [133/300], Step [180/234], D Loss: 0.0253, G Loss: 5.5101; D Loss Real: 0.0047, ; D Loss Fake: 0.0206, \n",
      "Epoch [133/300], Step [200/234], D Loss: 0.0236, G Loss: 5.5019; D Loss Real: 0.0008, ; D Loss Fake: 0.0228, \n",
      "Epoch [133/300], Step [220/234], D Loss: 0.0109, G Loss: 8.9997; D Loss Real: 0.0107, ; D Loss Fake: 0.0001, \n",
      "Epoch [134/300], Step [20/234], D Loss: 0.0143, G Loss: 11.9897; D Loss Real: 0.0142, ; D Loss Fake: 0.0001, \n",
      "Epoch [134/300], Step [40/234], D Loss: 0.0065, G Loss: 7.0320; D Loss Real: 0.0040, ; D Loss Fake: 0.0026, \n",
      "Epoch [134/300], Step [60/234], D Loss: 0.0015, G Loss: 16.1293; D Loss Real: 0.0015, ; D Loss Fake: 0.0000, \n",
      "Epoch [134/300], Step [80/234], D Loss: 0.1146, G Loss: 7.6403; D Loss Real: 0.1129, ; D Loss Fake: 0.0017, \n",
      "Epoch [134/300], Step [100/234], D Loss: 0.0012, G Loss: 11.7438; D Loss Real: 0.0011, ; D Loss Fake: 0.0001, \n",
      "Epoch [134/300], Step [120/234], D Loss: 0.0093, G Loss: 21.8637; D Loss Real: 0.0093, ; D Loss Fake: -0.0000, \n",
      "Epoch [134/300], Step [140/234], D Loss: 0.0178, G Loss: 0.0186; D Loss Real: 0.0178, ; D Loss Fake: 0.0000, \n",
      "Epoch [134/300], Step [160/234], D Loss: 0.1173, G Loss: 5.7564; D Loss Real: 0.0017, ; D Loss Fake: 0.1156, \n",
      "Epoch [134/300], Step [180/234], D Loss: 0.0013, G Loss: 7.5988; D Loss Real: 0.0009, ; D Loss Fake: 0.0004, \n",
      "Epoch [134/300], Step [200/234], D Loss: 0.0064, G Loss: 11.1419; D Loss Real: 0.0064, ; D Loss Fake: 0.0000, \n",
      "Epoch [134/300], Step [220/234], D Loss: 0.0055, G Loss: 7.4667; D Loss Real: 0.0036, ; D Loss Fake: 0.0018, \n",
      "Epoch [135/300], Step [20/234], D Loss: 0.0061, G Loss: 11.5310; D Loss Real: 0.0061, ; D Loss Fake: 0.0000, \n",
      "Epoch [135/300], Step [40/234], D Loss: 0.0225, G Loss: 6.4658; D Loss Real: 0.0209, ; D Loss Fake: 0.0017, \n",
      "Epoch [135/300], Step [60/234], D Loss: 0.0146, G Loss: 6.9545; D Loss Real: 0.0008, ; D Loss Fake: 0.0137, \n",
      "Epoch [135/300], Step [80/234], D Loss: 0.1168, G Loss: 11.7855; D Loss Real: 0.1168, ; D Loss Fake: 0.0000, \n",
      "Epoch [135/300], Step [100/234], D Loss: 0.0182, G Loss: 4.9826; D Loss Real: 0.0043, ; D Loss Fake: 0.0139, \n",
      "Epoch [135/300], Step [120/234], D Loss: 0.0088, G Loss: 9.9607; D Loss Real: 0.0087, ; D Loss Fake: 0.0001, \n",
      "Epoch [135/300], Step [140/234], D Loss: 0.0221, G Loss: 5.8347; D Loss Real: 0.0051, ; D Loss Fake: 0.0169, \n",
      "Epoch [135/300], Step [160/234], D Loss: 0.0240, G Loss: 5.3921; D Loss Real: 0.0067, ; D Loss Fake: 0.0173, \n",
      "Epoch [135/300], Step [180/234], D Loss: 0.0417, G Loss: 5.2411; D Loss Real: 0.0065, ; D Loss Fake: 0.0352, \n",
      "Epoch [135/300], Step [200/234], D Loss: 0.0028, G Loss: 6.0413; D Loss Real: 0.0006, ; D Loss Fake: 0.0022, \n",
      "Epoch [135/300], Step [220/234], D Loss: 0.0124, G Loss: 10.6931; D Loss Real: 0.0123, ; D Loss Fake: 0.0001, \n",
      "Epoch [136/300], Step [20/234], D Loss: 0.0075, G Loss: 7.0719; D Loss Real: 0.0003, ; D Loss Fake: 0.0072, \n",
      "Epoch [136/300], Step [40/234], D Loss: 0.0013, G Loss: 9.7994; D Loss Real: 0.0011, ; D Loss Fake: 0.0002, \n",
      "Epoch [136/300], Step [60/234], D Loss: 0.0074, G Loss: 0.0087; D Loss Real: 0.0074, ; D Loss Fake: 0.0000, \n",
      "Epoch [136/300], Step [80/234], D Loss: 0.0041, G Loss: 8.3569; D Loss Real: 0.0036, ; D Loss Fake: 0.0005, \n",
      "Epoch [136/300], Step [100/234], D Loss: 0.0264, G Loss: 14.5904; D Loss Real: 0.0264, ; D Loss Fake: 0.0000, \n",
      "Epoch [136/300], Step [120/234], D Loss: 0.0556, G Loss: 6.7292; D Loss Real: 0.0549, ; D Loss Fake: 0.0007, \n",
      "Epoch [136/300], Step [140/234], D Loss: 0.0098, G Loss: 6.0571; D Loss Real: 0.0034, ; D Loss Fake: 0.0065, \n",
      "Epoch [136/300], Step [160/234], D Loss: 0.0016, G Loss: 10.8492; D Loss Real: 0.0015, ; D Loss Fake: 0.0001, \n",
      "Epoch [136/300], Step [180/234], D Loss: 0.0218, G Loss: 6.3068; D Loss Real: 0.0163, ; D Loss Fake: 0.0055, \n",
      "Epoch [136/300], Step [200/234], D Loss: 0.0131, G Loss: 6.8289; D Loss Real: 0.0099, ; D Loss Fake: 0.0032, \n",
      "Epoch [136/300], Step [220/234], D Loss: 0.0119, G Loss: 7.9689; D Loss Real: 0.0109, ; D Loss Fake: 0.0010, \n",
      "Epoch [137/300], Step [20/234], D Loss: 0.0421, G Loss: 7.7149; D Loss Real: 0.0000, ; D Loss Fake: 0.0421, \n",
      "Epoch [137/300], Step [40/234], D Loss: 0.0967, G Loss: 8.2582; D Loss Real: 0.0957, ; D Loss Fake: 0.0010, \n",
      "Epoch [137/300], Step [60/234], D Loss: 0.3106, G Loss: 8.5759; D Loss Real: 0.0147, ; D Loss Fake: 0.2959, \n",
      "Epoch [137/300], Step [80/234], D Loss: 0.0078, G Loss: 8.0081; D Loss Real: 0.0074, ; D Loss Fake: 0.0005, \n",
      "Epoch [137/300], Step [100/234], D Loss: 0.0060, G Loss: 7.4594; D Loss Real: 0.0054, ; D Loss Fake: 0.0006, \n",
      "Epoch [137/300], Step [120/234], D Loss: 0.0281, G Loss: 4.6164; D Loss Real: 0.0006, ; D Loss Fake: 0.0275, \n",
      "Epoch [137/300], Step [140/234], D Loss: 0.0010, G Loss: 11.7344; D Loss Real: 0.0010, ; D Loss Fake: 0.0000, \n",
      "Epoch [137/300], Step [160/234], D Loss: 0.1071, G Loss: 5.4358; D Loss Real: 0.0221, ; D Loss Fake: 0.0851, \n",
      "Epoch [137/300], Step [180/234], D Loss: 0.0027, G Loss: -0.0297; D Loss Real: 0.0027, ; D Loss Fake: 0.0000, \n",
      "Epoch [137/300], Step [200/234], D Loss: 0.0004, G Loss: 10.2186; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [137/300], Step [220/234], D Loss: 0.0677, G Loss: 4.1374; D Loss Real: 0.0006, ; D Loss Fake: 0.0671, \n",
      "Epoch [138/300], Step [20/234], D Loss: 0.0453, G Loss: 4.2144; D Loss Real: 0.0051, ; D Loss Fake: 0.0401, \n",
      "Epoch [138/300], Step [40/234], D Loss: 0.0004, G Loss: 11.1080; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [138/300], Step [60/234], D Loss: 0.0315, G Loss: 5.4996; D Loss Real: 0.0026, ; D Loss Fake: 0.0289, \n",
      "Epoch [138/300], Step [80/234], D Loss: 0.0212, G Loss: 0.0002; D Loss Real: 0.0211, ; D Loss Fake: 0.0000, \n",
      "Epoch [138/300], Step [100/234], D Loss: 0.0040, G Loss: 10.6528; D Loss Real: 0.0040, ; D Loss Fake: 0.0000, \n",
      "Epoch [138/300], Step [120/234], D Loss: 0.0163, G Loss: 7.2162; D Loss Real: 0.0151, ; D Loss Fake: 0.0012, \n",
      "Epoch [138/300], Step [140/234], D Loss: 0.0062, G Loss: 6.7865; D Loss Real: 0.0020, ; D Loss Fake: 0.0043, \n",
      "Epoch [138/300], Step [160/234], D Loss: 0.0093, G Loss: 6.3765; D Loss Real: 0.0075, ; D Loss Fake: 0.0018, \n",
      "Epoch [138/300], Step [180/234], D Loss: 0.0164, G Loss: 5.3121; D Loss Real: 0.0066, ; D Loss Fake: 0.0098, \n",
      "Epoch [138/300], Step [200/234], D Loss: 0.0072, G Loss: 6.7613; D Loss Real: 0.0034, ; D Loss Fake: 0.0038, \n",
      "Epoch [138/300], Step [220/234], D Loss: 0.0510, G Loss: -0.0003; D Loss Real: 0.0004, ; D Loss Fake: 0.0506, \n",
      "Epoch [139/300], Step [20/234], D Loss: 0.0322, G Loss: 12.4620; D Loss Real: 0.0321, ; D Loss Fake: 0.0000, \n",
      "Epoch [139/300], Step [40/234], D Loss: 0.0101, G Loss: 5.5999; D Loss Real: 0.0035, ; D Loss Fake: 0.0066, \n",
      "Epoch [139/300], Step [60/234], D Loss: 0.0118, G Loss: 11.6469; D Loss Real: 0.0117, ; D Loss Fake: 0.0000, \n",
      "Epoch [139/300], Step [80/234], D Loss: 0.0494, G Loss: 4.9729; D Loss Real: 0.0029, ; D Loss Fake: 0.0465, \n",
      "Epoch [139/300], Step [100/234], D Loss: 0.0151, G Loss: 5.8771; D Loss Real: 0.0108, ; D Loss Fake: 0.0043, \n",
      "Epoch [139/300], Step [120/234], D Loss: 0.0097, G Loss: 7.7781; D Loss Real: 0.0088, ; D Loss Fake: 0.0009, \n",
      "Epoch [139/300], Step [140/234], D Loss: 0.0003, G Loss: 13.3407; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [139/300], Step [160/234], D Loss: 0.0022, G Loss: 11.1291; D Loss Real: 0.0022, ; D Loss Fake: 0.0000, \n",
      "Epoch [139/300], Step [180/234], D Loss: 0.0126, G Loss: 5.4693; D Loss Real: 0.0002, ; D Loss Fake: 0.0124, \n",
      "Epoch [139/300], Step [200/234], D Loss: 0.0187, G Loss: 6.6815; D Loss Real: 0.0001, ; D Loss Fake: 0.0186, \n",
      "Epoch [139/300], Step [220/234], D Loss: 0.0105, G Loss: 7.8000; D Loss Real: 0.0100, ; D Loss Fake: 0.0005, \n",
      "Epoch [140/300], Step [20/234], D Loss: 0.3660, G Loss: 10.1321; D Loss Real: 0.0041, ; D Loss Fake: 0.3619, \n",
      "Epoch [140/300], Step [40/234], D Loss: 0.0560, G Loss: 6.9745; D Loss Real: 0.0407, ; D Loss Fake: 0.0152, \n",
      "Epoch [140/300], Step [60/234], D Loss: 0.0052, G Loss: 10.0787; D Loss Real: 0.0051, ; D Loss Fake: 0.0002, \n",
      "Epoch [140/300], Step [80/234], D Loss: 0.0020, G Loss: 11.6331; D Loss Real: 0.0015, ; D Loss Fake: 0.0005, \n",
      "Epoch [140/300], Step [100/234], D Loss: 0.0099, G Loss: 5.5884; D Loss Real: 0.0010, ; D Loss Fake: 0.0089, \n",
      "Epoch [140/300], Step [120/234], D Loss: 0.2215, G Loss: 0.0018; D Loss Real: 0.0256, ; D Loss Fake: 0.1958, \n",
      "Epoch [140/300], Step [140/234], D Loss: 0.0068, G Loss: 6.4487; D Loss Real: 0.0044, ; D Loss Fake: 0.0024, \n",
      "Epoch [140/300], Step [160/234], D Loss: 0.0256, G Loss: 4.9849; D Loss Real: 0.0003, ; D Loss Fake: 0.0253, \n",
      "Epoch [140/300], Step [180/234], D Loss: 0.0364, G Loss: 0.0017; D Loss Real: 0.0364, ; D Loss Fake: 0.0000, \n",
      "Epoch [140/300], Step [200/234], D Loss: 0.0015, G Loss: 8.3740; D Loss Real: 0.0013, ; D Loss Fake: 0.0001, \n",
      "Epoch [140/300], Step [220/234], D Loss: 0.0024, G Loss: 7.1679; D Loss Real: 0.0011, ; D Loss Fake: 0.0013, \n",
      "Epoch [141/300], Step [20/234], D Loss: 0.0283, G Loss: 8.2059; D Loss Real: 0.0175, ; D Loss Fake: 0.0109, \n",
      "Epoch [141/300], Step [40/234], D Loss: 0.0033, G Loss: 6.7818; D Loss Real: 0.0012, ; D Loss Fake: 0.0021, \n",
      "Epoch [141/300], Step [60/234], D Loss: 0.0032, G Loss: 8.9553; D Loss Real: 0.0030, ; D Loss Fake: 0.0002, \n",
      "Epoch [141/300], Step [80/234], D Loss: 0.1374, G Loss: 6.0686; D Loss Real: 0.0434, ; D Loss Fake: 0.0940, \n",
      "Epoch [141/300], Step [100/234], D Loss: 0.0071, G Loss: 7.9673; D Loss Real: 0.0066, ; D Loss Fake: 0.0005, \n",
      "Epoch [141/300], Step [120/234], D Loss: 0.0445, G Loss: 9.9303; D Loss Real: 0.0156, ; D Loss Fake: 0.0289, \n",
      "Epoch [141/300], Step [140/234], D Loss: 0.4451, G Loss: 11.4046; D Loss Real: 0.0037, ; D Loss Fake: 0.4414, \n",
      "Epoch [141/300], Step [160/234], D Loss: 0.0183, G Loss: 5.7946; D Loss Real: 0.0066, ; D Loss Fake: 0.0118, \n",
      "Epoch [141/300], Step [180/234], D Loss: 0.1190, G Loss: 7.5193; D Loss Real: 0.1179, ; D Loss Fake: 0.0011, \n",
      "Epoch [141/300], Step [200/234], D Loss: 0.0515, G Loss: 4.9370; D Loss Real: 0.0001, ; D Loss Fake: 0.0514, \n",
      "Epoch [141/300], Step [220/234], D Loss: 0.0011, G Loss: 12.1431; D Loss Real: 0.0011, ; D Loss Fake: 0.0000, \n",
      "Epoch [142/300], Step [20/234], D Loss: 0.0073, G Loss: 13.5524; D Loss Real: 0.0073, ; D Loss Fake: 0.0000, \n",
      "Epoch [142/300], Step [40/234], D Loss: 0.0034, G Loss: 10.0814; D Loss Real: 0.0029, ; D Loss Fake: 0.0004, \n",
      "Epoch [142/300], Step [60/234], D Loss: 0.0153, G Loss: 0.0033; D Loss Real: 0.0056, ; D Loss Fake: 0.0097, \n",
      "Epoch [142/300], Step [80/234], D Loss: 0.0331, G Loss: 0.0110; D Loss Real: 0.0179, ; D Loss Fake: 0.0152, \n",
      "Epoch [142/300], Step [100/234], D Loss: 0.0092, G Loss: 5.8659; D Loss Real: 0.0033, ; D Loss Fake: 0.0060, \n",
      "Epoch [142/300], Step [120/234], D Loss: 0.0131, G Loss: 4.7505; D Loss Real: 0.0015, ; D Loss Fake: 0.0116, \n",
      "Epoch [142/300], Step [140/234], D Loss: 0.0074, G Loss: 8.9972; D Loss Real: 0.0073, ; D Loss Fake: 0.0001, \n",
      "Epoch [142/300], Step [160/234], D Loss: 0.1259, G Loss: 6.4994; D Loss Real: 0.0151, ; D Loss Fake: 0.1108, \n",
      "Epoch [142/300], Step [180/234], D Loss: 0.0020, G Loss: 6.7777; D Loss Real: 0.0001, ; D Loss Fake: 0.0020, \n",
      "Epoch [142/300], Step [200/234], D Loss: 0.0082, G Loss: 7.3451; D Loss Real: 0.0065, ; D Loss Fake: 0.0017, \n",
      "Epoch [142/300], Step [220/234], D Loss: 0.0069, G Loss: 5.5115; D Loss Real: 0.0023, ; D Loss Fake: 0.0046, \n",
      "Epoch [143/300], Step [20/234], D Loss: 0.0191, G Loss: 15.2225; D Loss Real: 0.0191, ; D Loss Fake: 0.0000, \n",
      "Epoch [143/300], Step [40/234], D Loss: 0.0172, G Loss: 10.3716; D Loss Real: 0.0171, ; D Loss Fake: 0.0001, \n",
      "Epoch [143/300], Step [60/234], D Loss: 0.0662, G Loss: 6.4329; D Loss Real: 0.0152, ; D Loss Fake: 0.0510, \n",
      "Epoch [143/300], Step [80/234], D Loss: 0.0004, G Loss: 8.8053; D Loss Real: 0.0001, ; D Loss Fake: 0.0003, \n",
      "Epoch [143/300], Step [100/234], D Loss: 0.0909, G Loss: 0.0087; D Loss Real: 0.0909, ; D Loss Fake: 0.0000, \n",
      "Epoch [143/300], Step [120/234], D Loss: 0.0238, G Loss: 8.2294; D Loss Real: 0.0230, ; D Loss Fake: 0.0008, \n",
      "Epoch [143/300], Step [140/234], D Loss: 0.0027, G Loss: 0.0006; D Loss Real: 0.0015, ; D Loss Fake: 0.0012, \n",
      "Epoch [143/300], Step [160/234], D Loss: 0.0141, G Loss: 5.8238; D Loss Real: 0.0091, ; D Loss Fake: 0.0051, \n",
      "Epoch [143/300], Step [180/234], D Loss: 0.0319, G Loss: 4.9575; D Loss Real: 0.0151, ; D Loss Fake: 0.0168, \n",
      "Epoch [143/300], Step [200/234], D Loss: 0.1154, G Loss: 8.5917; D Loss Real: 0.1154, ; D Loss Fake: 0.0000, \n",
      "Epoch [143/300], Step [220/234], D Loss: 0.0191, G Loss: 4.9755; D Loss Real: 0.0008, ; D Loss Fake: 0.0183, \n",
      "Epoch [144/300], Step [20/234], D Loss: 0.0119, G Loss: 9.4974; D Loss Real: 0.0113, ; D Loss Fake: 0.0006, \n",
      "Epoch [144/300], Step [40/234], D Loss: 0.1881, G Loss: 7.8364; D Loss Real: 0.0210, ; D Loss Fake: 0.1671, \n",
      "Epoch [144/300], Step [60/234], D Loss: 0.0208, G Loss: -0.0076; D Loss Real: 0.0208, ; D Loss Fake: 0.0001, \n",
      "Epoch [144/300], Step [80/234], D Loss: 0.0027, G Loss: 8.7753; D Loss Real: 0.0023, ; D Loss Fake: 0.0004, \n",
      "Epoch [144/300], Step [100/234], D Loss: 0.0087, G Loss: 12.4909; D Loss Real: 0.0087, ; D Loss Fake: 0.0000, \n",
      "Epoch [144/300], Step [120/234], D Loss: 0.0127, G Loss: 7.3414; D Loss Real: 0.0109, ; D Loss Fake: 0.0018, \n",
      "Epoch [144/300], Step [140/234], D Loss: 0.0221, G Loss: 6.8865; D Loss Real: 0.0206, ; D Loss Fake: 0.0015, \n",
      "Epoch [144/300], Step [160/234], D Loss: 0.0096, G Loss: 6.1787; D Loss Real: 0.0045, ; D Loss Fake: 0.0052, \n",
      "Epoch [144/300], Step [180/234], D Loss: 0.0255, G Loss: 5.3952; D Loss Real: 0.0180, ; D Loss Fake: 0.0076, \n",
      "Epoch [144/300], Step [200/234], D Loss: 0.0089, G Loss: 6.4873; D Loss Real: 0.0076, ; D Loss Fake: 0.0013, \n",
      "Epoch [144/300], Step [220/234], D Loss: 0.0723, G Loss: 10.0880; D Loss Real: 0.0723, ; D Loss Fake: 0.0000, \n",
      "Epoch [145/300], Step [20/234], D Loss: 0.0386, G Loss: 5.6080; D Loss Real: 0.0006, ; D Loss Fake: 0.0379, \n",
      "Epoch [145/300], Step [40/234], D Loss: 0.0108, G Loss: 6.8577; D Loss Real: 0.0097, ; D Loss Fake: 0.0011, \n",
      "Epoch [145/300], Step [60/234], D Loss: 0.0090, G Loss: 9.6959; D Loss Real: 0.0089, ; D Loss Fake: 0.0001, \n",
      "Epoch [145/300], Step [80/234], D Loss: 0.0430, G Loss: 0.0104; D Loss Real: 0.0002, ; D Loss Fake: 0.0427, \n",
      "Epoch [145/300], Step [100/234], D Loss: 0.0012, G Loss: 7.4060; D Loss Real: 0.0006, ; D Loss Fake: 0.0007, \n",
      "Epoch [145/300], Step [120/234], D Loss: 0.0259, G Loss: 6.9978; D Loss Real: 0.0254, ; D Loss Fake: 0.0005, \n",
      "Epoch [145/300], Step [140/234], D Loss: 0.0008, G Loss: 8.2727; D Loss Real: 0.0008, ; D Loss Fake: 0.0000, \n",
      "Epoch [145/300], Step [160/234], D Loss: 0.0163, G Loss: 10.7399; D Loss Real: 0.0163, ; D Loss Fake: 0.0001, \n",
      "Epoch [145/300], Step [180/234], D Loss: 0.0090, G Loss: 17.9481; D Loss Real: 0.0090, ; D Loss Fake: -0.0000, \n",
      "Epoch [145/300], Step [200/234], D Loss: 0.0168, G Loss: -0.0058; D Loss Real: 0.0167, ; D Loss Fake: 0.0001, \n",
      "Epoch [145/300], Step [220/234], D Loss: 0.0854, G Loss: 6.7111; D Loss Real: 0.0848, ; D Loss Fake: 0.0005, \n",
      "Epoch [146/300], Step [20/234], D Loss: 0.0020, G Loss: 9.2522; D Loss Real: 0.0018, ; D Loss Fake: 0.0002, \n",
      "Epoch [146/300], Step [40/234], D Loss: 0.0162, G Loss: 5.3852; D Loss Real: 0.0108, ; D Loss Fake: 0.0054, \n",
      "Epoch [146/300], Step [60/234], D Loss: 0.0114, G Loss: 6.3363; D Loss Real: 0.0053, ; D Loss Fake: 0.0061, \n",
      "Epoch [146/300], Step [80/234], D Loss: 0.0034, G Loss: 6.9232; D Loss Real: 0.0015, ; D Loss Fake: 0.0019, \n",
      "Epoch [146/300], Step [100/234], D Loss: 0.0212, G Loss: 4.6804; D Loss Real: 0.0008, ; D Loss Fake: 0.0205, \n",
      "Epoch [146/300], Step [120/234], D Loss: 0.0154, G Loss: 11.6795; D Loss Real: 0.0154, ; D Loss Fake: 0.0000, \n",
      "Epoch [146/300], Step [140/234], D Loss: 0.0051, G Loss: 7.6059; D Loss Real: 0.0046, ; D Loss Fake: 0.0005, \n",
      "Epoch [146/300], Step [160/234], D Loss: 0.0026, G Loss: 10.4940; D Loss Real: 0.0025, ; D Loss Fake: 0.0001, \n",
      "Epoch [146/300], Step [180/234], D Loss: 0.0022, G Loss: 14.1694; D Loss Real: 0.0022, ; D Loss Fake: 0.0000, \n",
      "Epoch [146/300], Step [200/234], D Loss: 0.0282, G Loss: 5.1923; D Loss Real: 0.0035, ; D Loss Fake: 0.0248, \n",
      "Epoch [146/300], Step [220/234], D Loss: 0.0058, G Loss: 16.9810; D Loss Real: 0.0058, ; D Loss Fake: 0.0000, \n",
      "Epoch [147/300], Step [20/234], D Loss: 0.0184, G Loss: 7.3501; D Loss Real: 0.0083, ; D Loss Fake: 0.0101, \n",
      "Epoch [147/300], Step [40/234], D Loss: 0.0210, G Loss: 10.6527; D Loss Real: 0.0210, ; D Loss Fake: 0.0000, \n",
      "Epoch [147/300], Step [60/234], D Loss: 0.0050, G Loss: 0.0046; D Loss Real: 0.0001, ; D Loss Fake: 0.0048, \n",
      "Epoch [147/300], Step [80/234], D Loss: 0.0715, G Loss: 0.0064; D Loss Real: 0.0070, ; D Loss Fake: 0.0645, \n",
      "Epoch [147/300], Step [100/234], D Loss: 0.0225, G Loss: 10.6884; D Loss Real: 0.0225, ; D Loss Fake: 0.0000, \n",
      "Epoch [147/300], Step [120/234], D Loss: 0.0149, G Loss: 6.2521; D Loss Real: 0.0126, ; D Loss Fake: 0.0023, \n",
      "Epoch [147/300], Step [140/234], D Loss: 0.0076, G Loss: 6.3356; D Loss Real: 0.0012, ; D Loss Fake: 0.0064, \n",
      "Epoch [147/300], Step [160/234], D Loss: 0.0680, G Loss: 8.6162; D Loss Real: 0.0610, ; D Loss Fake: 0.0070, \n",
      "Epoch [147/300], Step [180/234], D Loss: 0.0137, G Loss: 13.3663; D Loss Real: 0.0137, ; D Loss Fake: 0.0000, \n",
      "Epoch [147/300], Step [200/234], D Loss: 0.0077, G Loss: 7.6140; D Loss Real: 0.0076, ; D Loss Fake: 0.0002, \n",
      "Epoch [147/300], Step [220/234], D Loss: 0.0017, G Loss: 9.0526; D Loss Real: 0.0013, ; D Loss Fake: 0.0004, \n",
      "Epoch [148/300], Step [20/234], D Loss: 0.3311, G Loss: 17.8395; D Loss Real: 0.3311, ; D Loss Fake: 0.0000, \n",
      "Epoch [148/300], Step [40/234], D Loss: 0.2098, G Loss: 5.3582; D Loss Real: 0.2042, ; D Loss Fake: 0.0057, \n",
      "Epoch [148/300], Step [60/234], D Loss: 0.0370, G Loss: 4.5571; D Loss Real: 0.0176, ; D Loss Fake: 0.0194, \n",
      "Epoch [148/300], Step [80/234], D Loss: 0.0016, G Loss: 7.3063; D Loss Real: 0.0004, ; D Loss Fake: 0.0012, \n",
      "Epoch [148/300], Step [100/234], D Loss: 0.1226, G Loss: 6.0234; D Loss Real: 0.0010, ; D Loss Fake: 0.1216, \n",
      "Epoch [148/300], Step [120/234], D Loss: 0.0086, G Loss: 7.2427; D Loss Real: 0.0077, ; D Loss Fake: 0.0010, \n",
      "Epoch [148/300], Step [140/234], D Loss: 0.0054, G Loss: 10.9011; D Loss Real: 0.0054, ; D Loss Fake: 0.0000, \n",
      "Epoch [148/300], Step [160/234], D Loss: 0.0059, G Loss: 12.9352; D Loss Real: 0.0059, ; D Loss Fake: 0.0000, \n",
      "Epoch [148/300], Step [180/234], D Loss: 0.0086, G Loss: -0.0145; D Loss Real: 0.0085, ; D Loss Fake: 0.0001, \n",
      "Epoch [148/300], Step [200/234], D Loss: 0.5331, G Loss: 12.5940; D Loss Real: 0.0295, ; D Loss Fake: 0.5036, \n",
      "Epoch [148/300], Step [220/234], D Loss: 0.0345, G Loss: 4.7327; D Loss Real: 0.0036, ; D Loss Fake: 0.0309, \n",
      "Epoch [149/300], Step [20/234], D Loss: 0.0022, G Loss: 6.8077; D Loss Real: 0.0005, ; D Loss Fake: 0.0017, \n",
      "Epoch [149/300], Step [40/234], D Loss: 0.0568, G Loss: 4.7698; D Loss Real: 0.0021, ; D Loss Fake: 0.0547, \n",
      "Epoch [149/300], Step [60/234], D Loss: 0.0193, G Loss: 10.0799; D Loss Real: 0.0193, ; D Loss Fake: 0.0000, \n",
      "Epoch [149/300], Step [80/234], D Loss: 0.0027, G Loss: -0.0052; D Loss Real: 0.0027, ; D Loss Fake: 0.0000, \n",
      "Epoch [149/300], Step [100/234], D Loss: 0.0778, G Loss: 5.2484; D Loss Real: 0.0067, ; D Loss Fake: 0.0712, \n",
      "Epoch [149/300], Step [120/234], D Loss: 0.0032, G Loss: 7.2516; D Loss Real: 0.0027, ; D Loss Fake: 0.0005, \n",
      "Epoch [149/300], Step [140/234], D Loss: 0.0469, G Loss: 5.1318; D Loss Real: 0.0162, ; D Loss Fake: 0.0306, \n",
      "Epoch [149/300], Step [160/234], D Loss: 0.0048, G Loss: 6.9916; D Loss Real: 0.0035, ; D Loss Fake: 0.0013, \n",
      "Epoch [149/300], Step [180/234], D Loss: 0.0023, G Loss: -0.0067; D Loss Real: 0.0023, ; D Loss Fake: 0.0000, \n",
      "Epoch [149/300], Step [200/234], D Loss: 0.0067, G Loss: 6.0948; D Loss Real: 0.0033, ; D Loss Fake: 0.0034, \n",
      "Epoch [149/300], Step [220/234], D Loss: 0.0223, G Loss: 12.5021; D Loss Real: 0.0223, ; D Loss Fake: 0.0000, \n",
      "Epoch [150/300], Step [20/234], D Loss: 0.0069, G Loss: 7.8392; D Loss Real: 0.0010, ; D Loss Fake: 0.0060, \n",
      "Epoch [150/300], Step [40/234], D Loss: 0.0560, G Loss: 5.5184; D Loss Real: 0.0013, ; D Loss Fake: 0.0548, \n",
      "Epoch [150/300], Step [60/234], D Loss: 0.0145, G Loss: 6.0728; D Loss Real: 0.0028, ; D Loss Fake: 0.0117, \n",
      "Epoch [150/300], Step [80/234], D Loss: 0.0100, G Loss: 7.6199; D Loss Real: 0.0084, ; D Loss Fake: 0.0016, \n",
      "Epoch [150/300], Step [100/234], D Loss: 0.0241, G Loss: 7.1463; D Loss Real: 0.0227, ; D Loss Fake: 0.0014, \n",
      "Epoch [150/300], Step [120/234], D Loss: 0.3122, G Loss: 8.8056; D Loss Real: 0.0025, ; D Loss Fake: 0.3097, \n",
      "Epoch [150/300], Step [140/234], D Loss: 0.0299, G Loss: 4.9012; D Loss Real: 0.0018, ; D Loss Fake: 0.0281, \n",
      "Epoch [150/300], Step [160/234], D Loss: 0.0022, G Loss: 6.6685; D Loss Real: 0.0006, ; D Loss Fake: 0.0016, \n",
      "Epoch [150/300], Step [180/234], D Loss: 0.0041, G Loss: 8.0524; D Loss Real: 0.0027, ; D Loss Fake: 0.0013, \n",
      "Epoch [150/300], Step [200/234], D Loss: 0.0361, G Loss: 0.0099; D Loss Real: 0.0010, ; D Loss Fake: 0.0351, \n",
      "Epoch [150/300], Step [220/234], D Loss: 0.0241, G Loss: 13.3925; D Loss Real: 0.0241, ; D Loss Fake: 0.0000, \n",
      "Epoch [151/300], Step [20/234], D Loss: 0.0050, G Loss: 8.5009; D Loss Real: 0.0047, ; D Loss Fake: 0.0004, \n",
      "Epoch [151/300], Step [40/234], D Loss: 0.0262, G Loss: 4.6655; D Loss Real: 0.0000, ; D Loss Fake: 0.0262, \n",
      "Epoch [151/300], Step [60/234], D Loss: 0.0018, G Loss: 8.0974; D Loss Real: 0.0005, ; D Loss Fake: 0.0013, \n",
      "Epoch [151/300], Step [80/234], D Loss: 0.0635, G Loss: 14.5541; D Loss Real: 0.0635, ; D Loss Fake: 0.0000, \n",
      "Epoch [151/300], Step [100/234], D Loss: 0.0105, G Loss: 8.6092; D Loss Real: 0.0097, ; D Loss Fake: 0.0007, \n",
      "Epoch [151/300], Step [120/234], D Loss: 0.0052, G Loss: 5.9782; D Loss Real: 0.0012, ; D Loss Fake: 0.0039, \n",
      "Epoch [151/300], Step [140/234], D Loss: 0.0244, G Loss: 13.9483; D Loss Real: 0.0244, ; D Loss Fake: 0.0000, \n",
      "Epoch [151/300], Step [160/234], D Loss: 0.0013, G Loss: 10.5328; D Loss Real: 0.0013, ; D Loss Fake: 0.0001, \n",
      "Epoch [151/300], Step [180/234], D Loss: 0.0483, G Loss: 4.8944; D Loss Real: 0.0076, ; D Loss Fake: 0.0407, \n",
      "Epoch [151/300], Step [200/234], D Loss: 0.8035, G Loss: 14.2059; D Loss Real: 0.0000, ; D Loss Fake: 0.8035, \n",
      "Epoch [151/300], Step [220/234], D Loss: 0.0105, G Loss: 8.9497; D Loss Real: 0.0103, ; D Loss Fake: 0.0001, \n",
      "Epoch [152/300], Step [20/234], D Loss: 0.0003, G Loss: 13.6450; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [152/300], Step [40/234], D Loss: 0.0146, G Loss: 5.6466; D Loss Real: 0.0094, ; D Loss Fake: 0.0053, \n",
      "Epoch [152/300], Step [60/234], D Loss: 0.4029, G Loss: 16.2833; D Loss Real: 0.4029, ; D Loss Fake: 0.0000, \n",
      "Epoch [152/300], Step [80/234], D Loss: 0.0941, G Loss: 5.8564; D Loss Real: 0.0006, ; D Loss Fake: 0.0935, \n",
      "Epoch [152/300], Step [100/234], D Loss: 0.0048, G Loss: 5.8794; D Loss Real: 0.0001, ; D Loss Fake: 0.0047, \n",
      "Epoch [152/300], Step [120/234], D Loss: 0.0014, G Loss: 8.0991; D Loss Real: 0.0010, ; D Loss Fake: 0.0004, \n",
      "Epoch [152/300], Step [140/234], D Loss: 0.0134, G Loss: 5.7151; D Loss Real: 0.0029, ; D Loss Fake: 0.0105, \n",
      "Epoch [152/300], Step [160/234], D Loss: 0.0034, G Loss: 14.2046; D Loss Real: 0.0034, ; D Loss Fake: 0.0000, \n",
      "Epoch [152/300], Step [180/234], D Loss: 0.0161, G Loss: 0.0030; D Loss Real: 0.0102, ; D Loss Fake: 0.0059, \n",
      "Epoch [152/300], Step [200/234], D Loss: 0.0010, G Loss: 12.3163; D Loss Real: 0.0010, ; D Loss Fake: 0.0000, \n",
      "Epoch [152/300], Step [220/234], D Loss: 0.2750, G Loss: 0.0119; D Loss Real: 0.2744, ; D Loss Fake: 0.0006, \n",
      "Epoch [153/300], Step [20/234], D Loss: 0.2911, G Loss: 7.7957; D Loss Real: 0.2801, ; D Loss Fake: 0.0110, \n",
      "Epoch [153/300], Step [40/234], D Loss: 0.0018, G Loss: 0.0125; D Loss Real: 0.0017, ; D Loss Fake: 0.0000, \n",
      "Epoch [153/300], Step [60/234], D Loss: 0.0857, G Loss: 4.3559; D Loss Real: 0.0245, ; D Loss Fake: 0.0612, \n",
      "Epoch [153/300], Step [80/234], D Loss: 0.3102, G Loss: 11.8965; D Loss Real: 0.3102, ; D Loss Fake: 0.0000, \n",
      "Epoch [153/300], Step [100/234], D Loss: 0.0050, G Loss: 8.7176; D Loss Real: 0.0048, ; D Loss Fake: 0.0002, \n",
      "Epoch [153/300], Step [120/234], D Loss: 0.0252, G Loss: 6.8768; D Loss Real: 0.0175, ; D Loss Fake: 0.0077, \n",
      "Epoch [153/300], Step [140/234], D Loss: 0.0687, G Loss: 5.3772; D Loss Real: 0.0244, ; D Loss Fake: 0.0442, \n",
      "Epoch [153/300], Step [160/234], D Loss: 0.0075, G Loss: 5.7452; D Loss Real: 0.0011, ; D Loss Fake: 0.0065, \n",
      "Epoch [153/300], Step [180/234], D Loss: 0.0293, G Loss: 6.9505; D Loss Real: 0.0272, ; D Loss Fake: 0.0021, \n",
      "Epoch [153/300], Step [200/234], D Loss: 0.0064, G Loss: 11.6281; D Loss Real: 0.0064, ; D Loss Fake: 0.0000, \n",
      "Epoch [153/300], Step [220/234], D Loss: 0.0404, G Loss: 4.4713; D Loss Real: 0.0067, ; D Loss Fake: 0.0337, \n",
      "Epoch [154/300], Step [20/234], D Loss: 0.0022, G Loss: 7.5519; D Loss Real: 0.0016, ; D Loss Fake: 0.0006, \n",
      "Epoch [154/300], Step [40/234], D Loss: 0.0656, G Loss: 5.8423; D Loss Real: 0.0602, ; D Loss Fake: 0.0054, \n",
      "Epoch [154/300], Step [60/234], D Loss: 0.0041, G Loss: 8.8785; D Loss Real: 0.0030, ; D Loss Fake: 0.0011, \n",
      "Epoch [154/300], Step [80/234], D Loss: 0.0654, G Loss: 9.1156; D Loss Real: 0.0652, ; D Loss Fake: 0.0002, \n",
      "Epoch [154/300], Step [100/234], D Loss: 0.0043, G Loss: 11.1866; D Loss Real: 0.0043, ; D Loss Fake: 0.0000, \n",
      "Epoch [154/300], Step [120/234], D Loss: 0.0058, G Loss: 13.9086; D Loss Real: 0.0058, ; D Loss Fake: 0.0000, \n",
      "Epoch [154/300], Step [140/234], D Loss: 0.0174, G Loss: 4.9100; D Loss Real: 0.0007, ; D Loss Fake: 0.0168, \n",
      "Epoch [154/300], Step [160/234], D Loss: 0.4890, G Loss: 10.8059; D Loss Real: 0.0029, ; D Loss Fake: 0.4861, \n",
      "Epoch [154/300], Step [180/234], D Loss: 0.0043, G Loss: 7.7179; D Loss Real: 0.0040, ; D Loss Fake: 0.0003, \n",
      "Epoch [154/300], Step [200/234], D Loss: 0.0077, G Loss: 9.2400; D Loss Real: 0.0075, ; D Loss Fake: 0.0002, \n",
      "Epoch [154/300], Step [220/234], D Loss: 0.0043, G Loss: 11.1684; D Loss Real: 0.0043, ; D Loss Fake: 0.0000, \n",
      "Epoch [155/300], Step [20/234], D Loss: 0.0779, G Loss: 5.2872; D Loss Real: 0.0755, ; D Loss Fake: 0.0024, \n",
      "Epoch [155/300], Step [40/234], D Loss: 0.0617, G Loss: 6.7181; D Loss Real: 0.0603, ; D Loss Fake: 0.0014, \n",
      "Epoch [155/300], Step [60/234], D Loss: 0.0051, G Loss: 6.4505; D Loss Real: 0.0037, ; D Loss Fake: 0.0014, \n",
      "Epoch [155/300], Step [80/234], D Loss: 0.0019, G Loss: 7.4914; D Loss Real: 0.0010, ; D Loss Fake: 0.0009, \n",
      "Epoch [155/300], Step [100/234], D Loss: 0.0198, G Loss: 7.7503; D Loss Real: 0.0191, ; D Loss Fake: 0.0007, \n",
      "Epoch [155/300], Step [120/234], D Loss: 0.0247, G Loss: 5.2010; D Loss Real: 0.0033, ; D Loss Fake: 0.0214, \n",
      "Epoch [155/300], Step [140/234], D Loss: 0.0145, G Loss: 5.4107; D Loss Real: 0.0093, ; D Loss Fake: 0.0051, \n",
      "Epoch [155/300], Step [160/234], D Loss: 0.0064, G Loss: 5.3369; D Loss Real: 0.0003, ; D Loss Fake: 0.0061, \n",
      "Epoch [155/300], Step [180/234], D Loss: 0.0056, G Loss: 5.9605; D Loss Real: 0.0002, ; D Loss Fake: 0.0055, \n",
      "Epoch [155/300], Step [200/234], D Loss: 0.0021, G Loss: 6.9625; D Loss Real: 0.0009, ; D Loss Fake: 0.0012, \n",
      "Epoch [155/300], Step [220/234], D Loss: 0.0467, G Loss: 7.1063; D Loss Real: 0.0453, ; D Loss Fake: 0.0015, \n",
      "Epoch [156/300], Step [20/234], D Loss: 0.0066, G Loss: 13.7051; D Loss Real: 0.0066, ; D Loss Fake: 0.0000, \n",
      "Epoch [156/300], Step [40/234], D Loss: 0.9943, G Loss: -0.0157; D Loss Real: 0.0000, ; D Loss Fake: 0.9943, \n",
      "Epoch [156/300], Step [60/234], D Loss: 0.0084, G Loss: 6.7076; D Loss Real: 0.0070, ; D Loss Fake: 0.0014, \n",
      "Epoch [156/300], Step [80/234], D Loss: 0.1788, G Loss: 6.2667; D Loss Real: 0.0375, ; D Loss Fake: 0.1413, \n",
      "Epoch [156/300], Step [100/234], D Loss: 0.0790, G Loss: 5.1680; D Loss Real: 0.0039, ; D Loss Fake: 0.0751, \n",
      "Epoch [156/300], Step [120/234], D Loss: 0.0399, G Loss: 6.1357; D Loss Real: 0.0084, ; D Loss Fake: 0.0315, \n",
      "Epoch [156/300], Step [140/234], D Loss: 0.0350, G Loss: 5.3704; D Loss Real: 0.0030, ; D Loss Fake: 0.0321, \n",
      "Epoch [156/300], Step [160/234], D Loss: 0.0190, G Loss: 5.0127; D Loss Real: 0.0063, ; D Loss Fake: 0.0127, \n",
      "Epoch [156/300], Step [180/234], D Loss: 0.0236, G Loss: 5.3223; D Loss Real: 0.0007, ; D Loss Fake: 0.0229, \n",
      "Epoch [156/300], Step [200/234], D Loss: 0.0063, G Loss: 8.3280; D Loss Real: 0.0059, ; D Loss Fake: 0.0004, \n",
      "Epoch [156/300], Step [220/234], D Loss: 0.0836, G Loss: 7.0146; D Loss Real: 0.0829, ; D Loss Fake: 0.0007, \n",
      "Epoch [157/300], Step [20/234], D Loss: 0.7750, G Loss: -0.0185; D Loss Real: 0.0054, ; D Loss Fake: 0.7696, \n",
      "Epoch [157/300], Step [40/234], D Loss: 0.0615, G Loss: 0.0040; D Loss Real: 0.0029, ; D Loss Fake: 0.0586, \n",
      "Epoch [157/300], Step [60/234], D Loss: 0.0176, G Loss: 9.2603; D Loss Real: 0.0175, ; D Loss Fake: 0.0001, \n",
      "Epoch [157/300], Step [80/234], D Loss: 0.0017, G Loss: 11.7969; D Loss Real: 0.0017, ; D Loss Fake: 0.0000, \n",
      "Epoch [157/300], Step [100/234], D Loss: 0.0020, G Loss: 7.8545; D Loss Real: 0.0015, ; D Loss Fake: 0.0005, \n",
      "Epoch [157/300], Step [120/234], D Loss: 0.0110, G Loss: 5.7466; D Loss Real: 0.0049, ; D Loss Fake: 0.0061, \n",
      "Epoch [157/300], Step [140/234], D Loss: 0.0116, G Loss: 8.2907; D Loss Real: 0.0108, ; D Loss Fake: 0.0008, \n",
      "Epoch [157/300], Step [160/234], D Loss: 0.0086, G Loss: 5.6364; D Loss Real: 0.0023, ; D Loss Fake: 0.0063, \n",
      "Epoch [157/300], Step [180/234], D Loss: 0.0079, G Loss: 6.9279; D Loss Real: 0.0066, ; D Loss Fake: 0.0014, \n",
      "Epoch [157/300], Step [200/234], D Loss: 0.0293, G Loss: 4.3442; D Loss Real: 0.0012, ; D Loss Fake: 0.0281, \n",
      "Epoch [157/300], Step [220/234], D Loss: 0.1004, G Loss: 5.1514; D Loss Real: 0.0036, ; D Loss Fake: 0.0968, \n",
      "Epoch [158/300], Step [20/234], D Loss: 0.0020, G Loss: 7.5192; D Loss Real: 0.0009, ; D Loss Fake: 0.0010, \n",
      "Epoch [158/300], Step [40/234], D Loss: 0.0112, G Loss: 5.5292; D Loss Real: 0.0050, ; D Loss Fake: 0.0062, \n",
      "Epoch [158/300], Step [60/234], D Loss: 0.0120, G Loss: 5.4872; D Loss Real: 0.0011, ; D Loss Fake: 0.0109, \n",
      "Epoch [158/300], Step [80/234], D Loss: 0.0110, G Loss: 7.0576; D Loss Real: 0.0099, ; D Loss Fake: 0.0010, \n",
      "Epoch [158/300], Step [100/234], D Loss: 0.0688, G Loss: 4.3227; D Loss Real: 0.0071, ; D Loss Fake: 0.0617, \n",
      "Epoch [158/300], Step [120/234], D Loss: 0.0047, G Loss: 6.2663; D Loss Real: 0.0028, ; D Loss Fake: 0.0019, \n",
      "Epoch [158/300], Step [140/234], D Loss: 0.0655, G Loss: 5.2104; D Loss Real: 0.0001, ; D Loss Fake: 0.0654, \n",
      "Epoch [158/300], Step [160/234], D Loss: 0.0016, G Loss: 12.7892; D Loss Real: 0.0016, ; D Loss Fake: 0.0000, \n",
      "Epoch [158/300], Step [180/234], D Loss: 0.0750, G Loss: 9.9962; D Loss Real: 0.0750, ; D Loss Fake: 0.0000, \n",
      "Epoch [158/300], Step [200/234], D Loss: 0.0234, G Loss: 4.4303; D Loss Real: 0.0170, ; D Loss Fake: 0.0063, \n",
      "Epoch [158/300], Step [220/234], D Loss: 0.0367, G Loss: 4.5997; D Loss Real: 0.0021, ; D Loss Fake: 0.0346, \n",
      "Epoch [159/300], Step [20/234], D Loss: 0.0093, G Loss: 9.4239; D Loss Real: 0.0084, ; D Loss Fake: 0.0008, \n",
      "Epoch [159/300], Step [40/234], D Loss: 0.0061, G Loss: 7.4786; D Loss Real: 0.0046, ; D Loss Fake: 0.0015, \n",
      "Epoch [159/300], Step [60/234], D Loss: 0.0630, G Loss: 5.2355; D Loss Real: 0.0451, ; D Loss Fake: 0.0179, \n",
      "Epoch [159/300], Step [80/234], D Loss: 0.0020, G Loss: 10.0367; D Loss Real: 0.0014, ; D Loss Fake: 0.0005, \n",
      "Epoch [159/300], Step [100/234], D Loss: 0.0071, G Loss: 6.0984; D Loss Real: 0.0045, ; D Loss Fake: 0.0026, \n",
      "Epoch [159/300], Step [120/234], D Loss: 0.6102, G Loss: 11.5713; D Loss Real: 0.0028, ; D Loss Fake: 0.6074, \n",
      "Epoch [159/300], Step [140/234], D Loss: 0.0158, G Loss: 4.7933; D Loss Real: 0.0016, ; D Loss Fake: 0.0142, \n",
      "Epoch [159/300], Step [160/234], D Loss: 0.3509, G Loss: -0.0066; D Loss Real: 0.3509, ; D Loss Fake: 0.0000, \n",
      "Epoch [159/300], Step [180/234], D Loss: 0.0041, G Loss: 5.8054; D Loss Real: 0.0005, ; D Loss Fake: 0.0036, \n",
      "Epoch [159/300], Step [200/234], D Loss: 0.0133, G Loss: 16.7934; D Loss Real: 0.0133, ; D Loss Fake: 0.0000, \n",
      "Epoch [159/300], Step [220/234], D Loss: 0.0038, G Loss: 5.6494; D Loss Real: 0.0008, ; D Loss Fake: 0.0031, \n",
      "Epoch [160/300], Step [20/234], D Loss: 0.0109, G Loss: 12.2912; D Loss Real: 0.0109, ; D Loss Fake: 0.0000, \n",
      "Epoch [160/300], Step [40/234], D Loss: 0.0137, G Loss: 9.0094; D Loss Real: 0.0135, ; D Loss Fake: 0.0002, \n",
      "Epoch [160/300], Step [60/234], D Loss: 0.0222, G Loss: 10.4254; D Loss Real: 0.0222, ; D Loss Fake: 0.0000, \n",
      "Epoch [160/300], Step [80/234], D Loss: 0.1118, G Loss: 5.2670; D Loss Real: 0.0357, ; D Loss Fake: 0.0762, \n",
      "Epoch [160/300], Step [100/234], D Loss: 0.0788, G Loss: 5.8684; D Loss Real: 0.0182, ; D Loss Fake: 0.0606, \n",
      "Epoch [160/300], Step [120/234], D Loss: 0.0206, G Loss: 7.8685; D Loss Real: 0.0203, ; D Loss Fake: 0.0003, \n",
      "Epoch [160/300], Step [140/234], D Loss: 0.0109, G Loss: 7.1943; D Loss Real: 0.0094, ; D Loss Fake: 0.0015, \n",
      "Epoch [160/300], Step [160/234], D Loss: 0.0530, G Loss: 5.9758; D Loss Real: 0.0521, ; D Loss Fake: 0.0009, \n",
      "Epoch [160/300], Step [180/234], D Loss: 0.0038, G Loss: 0.0071; D Loss Real: 0.0007, ; D Loss Fake: 0.0031, \n",
      "Epoch [160/300], Step [200/234], D Loss: 0.0118, G Loss: 0.0090; D Loss Real: 0.0007, ; D Loss Fake: 0.0111, \n",
      "Epoch [160/300], Step [220/234], D Loss: 0.0039, G Loss: 5.7679; D Loss Real: 0.0006, ; D Loss Fake: 0.0034, \n",
      "Epoch [161/300], Step [20/234], D Loss: 0.0266, G Loss: 15.6970; D Loss Real: 0.0266, ; D Loss Fake: 0.0000, \n",
      "Epoch [161/300], Step [40/234], D Loss: 0.0858, G Loss: 15.6964; D Loss Real: 0.0858, ; D Loss Fake: 0.0000, \n",
      "Epoch [161/300], Step [60/234], D Loss: 0.0144, G Loss: 7.5248; D Loss Real: 0.0139, ; D Loss Fake: 0.0005, \n",
      "Epoch [161/300], Step [80/234], D Loss: 0.0171, G Loss: 10.5157; D Loss Real: 0.0170, ; D Loss Fake: 0.0001, \n",
      "Epoch [161/300], Step [100/234], D Loss: 0.0792, G Loss: 10.8190; D Loss Real: 0.0792, ; D Loss Fake: 0.0000, \n",
      "Epoch [161/300], Step [120/234], D Loss: 0.0390, G Loss: 4.6911; D Loss Real: 0.0237, ; D Loss Fake: 0.0154, \n",
      "Epoch [161/300], Step [140/234], D Loss: 0.0104, G Loss: 5.8402; D Loss Real: 0.0009, ; D Loss Fake: 0.0094, \n",
      "Epoch [161/300], Step [160/234], D Loss: 0.0040, G Loss: 6.2208; D Loss Real: 0.0009, ; D Loss Fake: 0.0031, \n",
      "Epoch [161/300], Step [180/234], D Loss: 0.1379, G Loss: 7.5662; D Loss Real: 0.0003, ; D Loss Fake: 0.1376, \n",
      "Epoch [161/300], Step [200/234], D Loss: 0.0019, G Loss: 7.4998; D Loss Real: 0.0007, ; D Loss Fake: 0.0013, \n",
      "Epoch [161/300], Step [220/234], D Loss: 0.0086, G Loss: 7.3885; D Loss Real: 0.0082, ; D Loss Fake: 0.0004, \n",
      "Epoch [162/300], Step [20/234], D Loss: 0.0014, G Loss: 8.4071; D Loss Real: 0.0010, ; D Loss Fake: 0.0003, \n",
      "Epoch [162/300], Step [40/234], D Loss: 0.0176, G Loss: 6.0210; D Loss Real: 0.0135, ; D Loss Fake: 0.0041, \n",
      "Epoch [162/300], Step [60/234], D Loss: 0.1216, G Loss: 5.0033; D Loss Real: 0.0668, ; D Loss Fake: 0.0547, \n",
      "Epoch [162/300], Step [80/234], D Loss: 0.0416, G Loss: 7.1630; D Loss Real: 0.0410, ; D Loss Fake: 0.0006, \n",
      "Epoch [162/300], Step [100/234], D Loss: 0.0433, G Loss: 5.0333; D Loss Real: 0.0145, ; D Loss Fake: 0.0287, \n",
      "Epoch [162/300], Step [120/234], D Loss: 0.0075, G Loss: 8.3447; D Loss Real: 0.0058, ; D Loss Fake: 0.0017, \n",
      "Epoch [162/300], Step [140/234], D Loss: 0.0037, G Loss: 11.6564; D Loss Real: 0.0036, ; D Loss Fake: 0.0000, \n",
      "Epoch [162/300], Step [160/234], D Loss: 0.0555, G Loss: -0.0041; D Loss Real: 0.0554, ; D Loss Fake: 0.0001, \n",
      "Epoch [162/300], Step [180/234], D Loss: 0.0280, G Loss: -0.0071; D Loss Real: 0.0280, ; D Loss Fake: 0.0000, \n",
      "Epoch [162/300], Step [200/234], D Loss: 0.0130, G Loss: 7.9363; D Loss Real: 0.0129, ; D Loss Fake: 0.0001, \n",
      "Epoch [162/300], Step [220/234], D Loss: 0.0021, G Loss: 15.0438; D Loss Real: 0.0021, ; D Loss Fake: 0.0000, \n",
      "Epoch [163/300], Step [20/234], D Loss: 0.0368, G Loss: 7.4233; D Loss Real: 0.0004, ; D Loss Fake: 0.0364, \n",
      "Epoch [163/300], Step [40/234], D Loss: 0.0132, G Loss: 4.8689; D Loss Real: 0.0044, ; D Loss Fake: 0.0088, \n",
      "Epoch [163/300], Step [60/234], D Loss: 0.1131, G Loss: 6.8765; D Loss Real: 0.0006, ; D Loss Fake: 0.1125, \n",
      "Epoch [163/300], Step [80/234], D Loss: 0.0066, G Loss: 6.6245; D Loss Real: 0.0015, ; D Loss Fake: 0.0051, \n",
      "Epoch [163/300], Step [100/234], D Loss: 0.1721, G Loss: 5.3026; D Loss Real: 0.1708, ; D Loss Fake: 0.0013, \n",
      "Epoch [163/300], Step [120/234], D Loss: 0.0311, G Loss: 5.6199; D Loss Real: 0.0009, ; D Loss Fake: 0.0302, \n",
      "Epoch [163/300], Step [140/234], D Loss: 0.0021, G Loss: 6.3816; D Loss Real: 0.0007, ; D Loss Fake: 0.0014, \n",
      "Epoch [163/300], Step [160/234], D Loss: 0.0149, G Loss: 12.9964; D Loss Real: 0.0149, ; D Loss Fake: 0.0000, \n",
      "Epoch [163/300], Step [180/234], D Loss: 0.0016, G Loss: 0.0139; D Loss Real: 0.0012, ; D Loss Fake: 0.0004, \n",
      "Epoch [163/300], Step [200/234], D Loss: 0.0436, G Loss: 9.6442; D Loss Real: 0.0434, ; D Loss Fake: 0.0001, \n",
      "Epoch [163/300], Step [220/234], D Loss: 0.0224, G Loss: 5.8616; D Loss Real: 0.0004, ; D Loss Fake: 0.0219, \n",
      "Epoch [164/300], Step [20/234], D Loss: 0.0291, G Loss: 6.1324; D Loss Real: 0.0006, ; D Loss Fake: 0.0285, \n",
      "Epoch [164/300], Step [40/234], D Loss: 0.0089, G Loss: 19.3269; D Loss Real: 0.0089, ; D Loss Fake: -0.0000, \n",
      "Epoch [164/300], Step [60/234], D Loss: 0.0020, G Loss: 6.8901; D Loss Real: 0.0002, ; D Loss Fake: 0.0019, \n",
      "Epoch [164/300], Step [80/234], D Loss: 0.0009, G Loss: 0.0030; D Loss Real: 0.0008, ; D Loss Fake: 0.0001, \n",
      "Epoch [164/300], Step [100/234], D Loss: 0.0093, G Loss: 8.8995; D Loss Real: 0.0086, ; D Loss Fake: 0.0007, \n",
      "Epoch [164/300], Step [120/234], D Loss: 0.0395, G Loss: 7.2377; D Loss Real: 0.0376, ; D Loss Fake: 0.0019, \n",
      "Epoch [164/300], Step [140/234], D Loss: 0.1676, G Loss: -0.0001; D Loss Real: 0.0002, ; D Loss Fake: 0.1674, \n",
      "Epoch [164/300], Step [160/234], D Loss: 0.0487, G Loss: 9.4510; D Loss Real: 0.0486, ; D Loss Fake: 0.0001, \n",
      "Epoch [164/300], Step [180/234], D Loss: 0.0687, G Loss: 5.1259; D Loss Real: 0.0054, ; D Loss Fake: 0.0633, \n",
      "Epoch [164/300], Step [200/234], D Loss: 0.0085, G Loss: 5.4795; D Loss Real: 0.0022, ; D Loss Fake: 0.0063, \n",
      "Epoch [164/300], Step [220/234], D Loss: 0.0201, G Loss: 7.1504; D Loss Real: 0.0196, ; D Loss Fake: 0.0005, \n",
      "Epoch [165/300], Step [20/234], D Loss: 0.6128, G Loss: 10.1683; D Loss Real: 0.0003, ; D Loss Fake: 0.6125, \n",
      "Epoch [165/300], Step [40/234], D Loss: 0.0026, G Loss: 8.9985; D Loss Real: 0.0017, ; D Loss Fake: 0.0009, \n",
      "Epoch [165/300], Step [60/234], D Loss: 0.0339, G Loss: 14.6573; D Loss Real: 0.0339, ; D Loss Fake: 0.0000, \n",
      "Epoch [165/300], Step [80/234], D Loss: 0.8227, G Loss: 11.0351; D Loss Real: 0.8227, ; D Loss Fake: 0.0000, \n",
      "Epoch [165/300], Step [100/234], D Loss: 0.0817, G Loss: 6.1148; D Loss Real: 0.0007, ; D Loss Fake: 0.0811, \n",
      "Epoch [165/300], Step [120/234], D Loss: 0.0029, G Loss: 9.4882; D Loss Real: 0.0023, ; D Loss Fake: 0.0006, \n",
      "Epoch [165/300], Step [140/234], D Loss: 0.0101, G Loss: 6.1793; D Loss Real: 0.0000, ; D Loss Fake: 0.0101, \n",
      "Epoch [165/300], Step [160/234], D Loss: 0.0049, G Loss: 6.5774; D Loss Real: 0.0002, ; D Loss Fake: 0.0047, \n",
      "Epoch [165/300], Step [180/234], D Loss: 0.0697, G Loss: 5.5830; D Loss Real: 0.0042, ; D Loss Fake: 0.0654, \n",
      "Epoch [165/300], Step [200/234], D Loss: 0.0145, G Loss: 5.3425; D Loss Real: 0.0005, ; D Loss Fake: 0.0139, \n",
      "Epoch [165/300], Step [220/234], D Loss: 0.0132, G Loss: 5.3502; D Loss Real: 0.0023, ; D Loss Fake: 0.0109, \n",
      "Epoch [166/300], Step [20/234], D Loss: 0.0105, G Loss: 0.0121; D Loss Real: 0.0028, ; D Loss Fake: 0.0077, \n",
      "Epoch [166/300], Step [40/234], D Loss: 0.0711, G Loss: 6.9900; D Loss Real: 0.0249, ; D Loss Fake: 0.0462, \n",
      "Epoch [166/300], Step [60/234], D Loss: 0.0858, G Loss: 5.9532; D Loss Real: 0.0006, ; D Loss Fake: 0.0852, \n",
      "Epoch [166/300], Step [80/234], D Loss: 0.0617, G Loss: 5.4877; D Loss Real: 0.0018, ; D Loss Fake: 0.0599, \n",
      "Epoch [166/300], Step [100/234], D Loss: 0.0032, G Loss: 7.8710; D Loss Real: 0.0026, ; D Loss Fake: 0.0005, \n",
      "Epoch [166/300], Step [120/234], D Loss: 0.0163, G Loss: 7.9928; D Loss Real: 0.0157, ; D Loss Fake: 0.0006, \n",
      "Epoch [166/300], Step [140/234], D Loss: 0.0048, G Loss: -0.0053; D Loss Real: 0.0012, ; D Loss Fake: 0.0036, \n",
      "Epoch [166/300], Step [160/234], D Loss: 0.0460, G Loss: 4.8819; D Loss Real: 0.0008, ; D Loss Fake: 0.0451, \n",
      "Epoch [166/300], Step [180/234], D Loss: 0.0148, G Loss: 6.9438; D Loss Real: 0.0128, ; D Loss Fake: 0.0021, \n",
      "Epoch [166/300], Step [200/234], D Loss: 0.0037, G Loss: 7.9742; D Loss Real: 0.0034, ; D Loss Fake: 0.0003, \n",
      "Epoch [166/300], Step [220/234], D Loss: 0.0255, G Loss: 4.7854; D Loss Real: 0.0005, ; D Loss Fake: 0.0251, \n",
      "Epoch [167/300], Step [20/234], D Loss: 0.0009, G Loss: 10.4231; D Loss Real: 0.0008, ; D Loss Fake: 0.0001, \n",
      "Epoch [167/300], Step [40/234], D Loss: 0.0045, G Loss: 5.6825; D Loss Real: 0.0024, ; D Loss Fake: 0.0021, \n",
      "Epoch [167/300], Step [60/234], D Loss: 0.0015, G Loss: 9.3575; D Loss Real: 0.0014, ; D Loss Fake: 0.0001, \n",
      "Epoch [167/300], Step [80/234], D Loss: 0.0032, G Loss: 10.6028; D Loss Real: 0.0032, ; D Loss Fake: 0.0000, \n",
      "Epoch [167/300], Step [100/234], D Loss: 0.0036, G Loss: 6.3157; D Loss Real: 0.0005, ; D Loss Fake: 0.0031, \n",
      "Epoch [167/300], Step [120/234], D Loss: 0.0015, G Loss: 8.5542; D Loss Real: 0.0011, ; D Loss Fake: 0.0004, \n",
      "Epoch [167/300], Step [140/234], D Loss: 0.0152, G Loss: 6.8687; D Loss Real: 0.0005, ; D Loss Fake: 0.0146, \n",
      "Epoch [167/300], Step [160/234], D Loss: 0.0004, G Loss: 12.2980; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [167/300], Step [180/234], D Loss: 0.0010, G Loss: 8.7332; D Loss Real: 0.0008, ; D Loss Fake: 0.0002, \n",
      "Epoch [167/300], Step [200/234], D Loss: 0.0075, G Loss: 8.2543; D Loss Real: 0.0072, ; D Loss Fake: 0.0003, \n",
      "Epoch [167/300], Step [220/234], D Loss: 0.0005, G Loss: -0.0056; D Loss Real: 0.0004, ; D Loss Fake: 0.0001, \n",
      "Epoch [168/300], Step [20/234], D Loss: 0.2376, G Loss: 8.9531; D Loss Real: 0.2375, ; D Loss Fake: 0.0001, \n",
      "Epoch [168/300], Step [40/234], D Loss: 0.0565, G Loss: 6.8028; D Loss Real: 0.0005, ; D Loss Fake: 0.0560, \n",
      "Epoch [168/300], Step [60/234], D Loss: 0.0010, G Loss: 13.4142; D Loss Real: 0.0010, ; D Loss Fake: 0.0000, \n",
      "Epoch [168/300], Step [80/234], D Loss: 0.0074, G Loss: 8.5415; D Loss Real: 0.0072, ; D Loss Fake: 0.0002, \n",
      "Epoch [168/300], Step [100/234], D Loss: 0.0819, G Loss: 0.0096; D Loss Real: 0.0001, ; D Loss Fake: 0.0818, \n",
      "Epoch [168/300], Step [120/234], D Loss: 0.0307, G Loss: 5.5919; D Loss Real: 0.0255, ; D Loss Fake: 0.0052, \n",
      "Epoch [168/300], Step [140/234], D Loss: 0.0136, G Loss: 8.7437; D Loss Real: 0.0135, ; D Loss Fake: 0.0001, \n",
      "Epoch [168/300], Step [160/234], D Loss: 0.0419, G Loss: 5.8524; D Loss Real: 0.0353, ; D Loss Fake: 0.0066, \n",
      "Epoch [168/300], Step [180/234], D Loss: 0.0070, G Loss: 5.8831; D Loss Real: 0.0042, ; D Loss Fake: 0.0028, \n",
      "Epoch [168/300], Step [200/234], D Loss: 0.0223, G Loss: 11.8260; D Loss Real: 0.0223, ; D Loss Fake: 0.0000, \n",
      "Epoch [168/300], Step [220/234], D Loss: 0.0032, G Loss: 7.5186; D Loss Real: 0.0022, ; D Loss Fake: 0.0010, \n",
      "Epoch [169/300], Step [20/234], D Loss: 0.0965, G Loss: -0.0028; D Loss Real: 0.0965, ; D Loss Fake: 0.0000, \n",
      "Epoch [169/300], Step [40/234], D Loss: 0.0322, G Loss: 14.2716; D Loss Real: 0.0322, ; D Loss Fake: 0.0000, \n",
      "Epoch [169/300], Step [60/234], D Loss: 0.0086, G Loss: 5.5049; D Loss Real: 0.0016, ; D Loss Fake: 0.0070, \n",
      "Epoch [169/300], Step [80/234], D Loss: 0.2247, G Loss: 6.9985; D Loss Real: 0.1057, ; D Loss Fake: 0.1190, \n",
      "Epoch [169/300], Step [100/234], D Loss: 0.0016, G Loss: 9.7523; D Loss Real: 0.0015, ; D Loss Fake: 0.0000, \n",
      "Epoch [169/300], Step [120/234], D Loss: 0.0026, G Loss: 11.1538; D Loss Real: 0.0025, ; D Loss Fake: 0.0001, \n",
      "Epoch [169/300], Step [140/234], D Loss: 0.0207, G Loss: 6.2010; D Loss Real: 0.0005, ; D Loss Fake: 0.0202, \n",
      "Epoch [169/300], Step [160/234], D Loss: 0.0589, G Loss: 9.1839; D Loss Real: 0.0589, ; D Loss Fake: 0.0000, \n",
      "Epoch [169/300], Step [180/234], D Loss: 0.0057, G Loss: 7.9705; D Loss Real: 0.0031, ; D Loss Fake: 0.0026, \n",
      "Epoch [169/300], Step [200/234], D Loss: 0.0042, G Loss: 8.7014; D Loss Real: 0.0041, ; D Loss Fake: 0.0001, \n",
      "Epoch [169/300], Step [220/234], D Loss: 0.0013, G Loss: 9.5118; D Loss Real: 0.0011, ; D Loss Fake: 0.0002, \n",
      "Epoch [170/300], Step [20/234], D Loss: 0.0006, G Loss: 8.8207; D Loss Real: 0.0002, ; D Loss Fake: 0.0004, \n",
      "Epoch [170/300], Step [40/234], D Loss: 0.0013, G Loss: 12.6743; D Loss Real: 0.0013, ; D Loss Fake: 0.0000, \n",
      "Epoch [170/300], Step [60/234], D Loss: 0.0036, G Loss: 7.0442; D Loss Real: 0.0029, ; D Loss Fake: 0.0007, \n",
      "Epoch [170/300], Step [80/234], D Loss: 0.0192, G Loss: 6.4167; D Loss Real: 0.0031, ; D Loss Fake: 0.0161, \n",
      "Epoch [170/300], Step [100/234], D Loss: 0.1008, G Loss: 7.0592; D Loss Real: 0.0150, ; D Loss Fake: 0.0858, \n",
      "Epoch [170/300], Step [120/234], D Loss: 0.0266, G Loss: 5.2181; D Loss Real: 0.0121, ; D Loss Fake: 0.0146, \n",
      "Epoch [170/300], Step [140/234], D Loss: 0.0007, G Loss: 11.7669; D Loss Real: 0.0007, ; D Loss Fake: 0.0000, \n",
      "Epoch [170/300], Step [160/234], D Loss: 0.0196, G Loss: 6.1629; D Loss Real: 0.0117, ; D Loss Fake: 0.0079, \n",
      "Epoch [170/300], Step [180/234], D Loss: 0.0009, G Loss: 8.8600; D Loss Real: 0.0006, ; D Loss Fake: 0.0004, \n",
      "Epoch [170/300], Step [200/234], D Loss: 0.0230, G Loss: 5.3316; D Loss Real: 0.0121, ; D Loss Fake: 0.0108, \n",
      "Epoch [170/300], Step [220/234], D Loss: 0.0136, G Loss: 5.0461; D Loss Real: 0.0061, ; D Loss Fake: 0.0075, \n",
      "Epoch [171/300], Step [20/234], D Loss: 0.0310, G Loss: 0.0032; D Loss Real: 0.0217, ; D Loss Fake: 0.0092, \n",
      "Epoch [171/300], Step [40/234], D Loss: 0.0037, G Loss: 9.3135; D Loss Real: 0.0034, ; D Loss Fake: 0.0003, \n",
      "Epoch [171/300], Step [60/234], D Loss: 0.0082, G Loss: 7.1952; D Loss Real: 0.0066, ; D Loss Fake: 0.0016, \n",
      "Epoch [171/300], Step [80/234], D Loss: 0.0016, G Loss: 10.5794; D Loss Real: 0.0016, ; D Loss Fake: 0.0001, \n",
      "Epoch [171/300], Step [100/234], D Loss: 0.0065, G Loss: 10.1231; D Loss Real: 0.0065, ; D Loss Fake: 0.0001, \n",
      "Epoch [171/300], Step [120/234], D Loss: 0.0083, G Loss: 10.4534; D Loss Real: 0.0083, ; D Loss Fake: 0.0001, \n",
      "Epoch [171/300], Step [140/234], D Loss: 0.0033, G Loss: 11.6212; D Loss Real: 0.0033, ; D Loss Fake: 0.0000, \n",
      "Epoch [171/300], Step [160/234], D Loss: 0.0064, G Loss: 9.2857; D Loss Real: 0.0063, ; D Loss Fake: 0.0001, \n",
      "Epoch [171/300], Step [180/234], D Loss: 0.0002, G Loss: 12.6074; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [171/300], Step [200/234], D Loss: 0.0016, G Loss: 9.8823; D Loss Real: 0.0012, ; D Loss Fake: 0.0004, \n",
      "Epoch [171/300], Step [220/234], D Loss: 0.0080, G Loss: 7.5487; D Loss Real: 0.0073, ; D Loss Fake: 0.0007, \n",
      "Epoch [172/300], Step [20/234], D Loss: 0.0033, G Loss: 7.8760; D Loss Real: 0.0025, ; D Loss Fake: 0.0008, \n",
      "Epoch [172/300], Step [40/234], D Loss: 0.0050, G Loss: 7.8047; D Loss Real: 0.0045, ; D Loss Fake: 0.0005, \n",
      "Epoch [172/300], Step [60/234], D Loss: 0.0149, G Loss: 5.5393; D Loss Real: 0.0094, ; D Loss Fake: 0.0055, \n",
      "Epoch [172/300], Step [80/234], D Loss: 0.0400, G Loss: 5.9306; D Loss Real: 0.0022, ; D Loss Fake: 0.0378, \n",
      "Epoch [172/300], Step [100/234], D Loss: 0.0068, G Loss: 10.3745; D Loss Real: 0.0065, ; D Loss Fake: 0.0003, \n",
      "Epoch [172/300], Step [120/234], D Loss: 0.0076, G Loss: 6.6546; D Loss Real: 0.0023, ; D Loss Fake: 0.0052, \n",
      "Epoch [172/300], Step [140/234], D Loss: 0.0008, G Loss: 8.5594; D Loss Real: 0.0004, ; D Loss Fake: 0.0004, \n",
      "Epoch [172/300], Step [160/234], D Loss: 0.1984, G Loss: 0.0066; D Loss Real: 0.1984, ; D Loss Fake: 0.0000, \n",
      "Epoch [172/300], Step [180/234], D Loss: 0.0067, G Loss: 5.9552; D Loss Real: 0.0011, ; D Loss Fake: 0.0057, \n",
      "Epoch [172/300], Step [200/234], D Loss: 0.1187, G Loss: 6.7705; D Loss Real: 0.0050, ; D Loss Fake: 0.1138, \n",
      "Epoch [172/300], Step [220/234], D Loss: 0.0159, G Loss: 4.4753; D Loss Real: 0.0000, ; D Loss Fake: 0.0159, \n",
      "Epoch [173/300], Step [20/234], D Loss: 0.0040, G Loss: 9.8062; D Loss Real: 0.0004, ; D Loss Fake: 0.0035, \n",
      "Epoch [173/300], Step [40/234], D Loss: 0.0097, G Loss: 5.8685; D Loss Real: 0.0076, ; D Loss Fake: 0.0022, \n",
      "Epoch [173/300], Step [60/234], D Loss: 0.0330, G Loss: 7.5714; D Loss Real: 0.0069, ; D Loss Fake: 0.0260, \n",
      "Epoch [173/300], Step [80/234], D Loss: 0.0638, G Loss: 0.0036; D Loss Real: 0.0008, ; D Loss Fake: 0.0630, \n",
      "Epoch [173/300], Step [100/234], D Loss: 0.3578, G Loss: 7.2009; D Loss Real: 0.3577, ; D Loss Fake: 0.0001, \n",
      "Epoch [173/300], Step [120/234], D Loss: 0.0835, G Loss: 7.0290; D Loss Real: 0.0819, ; D Loss Fake: 0.0016, \n",
      "Epoch [173/300], Step [140/234], D Loss: 0.0120, G Loss: 5.1393; D Loss Real: 0.0047, ; D Loss Fake: 0.0072, \n",
      "Epoch [173/300], Step [160/234], D Loss: 0.0090, G Loss: 5.8791; D Loss Real: 0.0019, ; D Loss Fake: 0.0072, \n",
      "Epoch [173/300], Step [180/234], D Loss: 0.1260, G Loss: 7.2491; D Loss Real: 0.0042, ; D Loss Fake: 0.1218, \n",
      "Epoch [173/300], Step [200/234], D Loss: 0.0004, G Loss: 13.0432; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [173/300], Step [220/234], D Loss: 0.0021, G Loss: 7.6257; D Loss Real: 0.0017, ; D Loss Fake: 0.0004, \n",
      "Epoch [174/300], Step [20/234], D Loss: 1.7285, G Loss: 8.3684; D Loss Real: 1.7285, ; D Loss Fake: 0.0000, \n",
      "Epoch [174/300], Step [40/234], D Loss: 0.2138, G Loss: 8.0792; D Loss Real: 0.0247, ; D Loss Fake: 0.1891, \n",
      "Epoch [174/300], Step [60/234], D Loss: 0.1098, G Loss: 5.7875; D Loss Real: 0.0004, ; D Loss Fake: 0.1094, \n",
      "Epoch [174/300], Step [80/234], D Loss: 0.0165, G Loss: 6.2243; D Loss Real: 0.0007, ; D Loss Fake: 0.0158, \n",
      "Epoch [174/300], Step [100/234], D Loss: 0.0395, G Loss: 5.9723; D Loss Real: 0.0000, ; D Loss Fake: 0.0394, \n",
      "Epoch [174/300], Step [120/234], D Loss: 0.0037, G Loss: 9.5859; D Loss Real: 0.0035, ; D Loss Fake: 0.0003, \n",
      "Epoch [174/300], Step [140/234], D Loss: 0.0031, G Loss: 7.3127; D Loss Real: 0.0019, ; D Loss Fake: 0.0012, \n",
      "Epoch [174/300], Step [160/234], D Loss: 0.0088, G Loss: 11.5238; D Loss Real: 0.0088, ; D Loss Fake: 0.0000, \n",
      "Epoch [174/300], Step [180/234], D Loss: 0.0282, G Loss: 9.7712; D Loss Real: 0.0281, ; D Loss Fake: 0.0001, \n",
      "Epoch [174/300], Step [200/234], D Loss: 0.0255, G Loss: 13.0921; D Loss Real: 0.0255, ; D Loss Fake: 0.0000, \n",
      "Epoch [174/300], Step [220/234], D Loss: 0.0063, G Loss: 6.6828; D Loss Real: 0.0018, ; D Loss Fake: 0.0045, \n",
      "Epoch [175/300], Step [20/234], D Loss: 0.0013, G Loss: 12.3463; D Loss Real: 0.0012, ; D Loss Fake: 0.0000, \n",
      "Epoch [175/300], Step [40/234], D Loss: 0.0100, G Loss: 10.4042; D Loss Real: 0.0099, ; D Loss Fake: 0.0001, \n",
      "Epoch [175/300], Step [60/234], D Loss: 0.0240, G Loss: 5.1924; D Loss Real: 0.0001, ; D Loss Fake: 0.0239, \n",
      "Epoch [175/300], Step [80/234], D Loss: 0.0165, G Loss: 5.4780; D Loss Real: 0.0004, ; D Loss Fake: 0.0160, \n",
      "Epoch [175/300], Step [100/234], D Loss: 0.1364, G Loss: 3.9660; D Loss Real: 0.0830, ; D Loss Fake: 0.0534, \n",
      "Epoch [175/300], Step [120/234], D Loss: 0.0448, G Loss: 5.4871; D Loss Real: 0.0333, ; D Loss Fake: 0.0115, \n",
      "Epoch [175/300], Step [140/234], D Loss: 0.0067, G Loss: 9.9330; D Loss Real: 0.0066, ; D Loss Fake: 0.0001, \n",
      "Epoch [175/300], Step [160/234], D Loss: 0.0235, G Loss: 4.3540; D Loss Real: 0.0043, ; D Loss Fake: 0.0192, \n",
      "Epoch [175/300], Step [180/234], D Loss: 0.0060, G Loss: 6.5948; D Loss Real: 0.0034, ; D Loss Fake: 0.0025, \n",
      "Epoch [175/300], Step [200/234], D Loss: 0.0029, G Loss: 5.9561; D Loss Real: 0.0001, ; D Loss Fake: 0.0029, \n",
      "Epoch [175/300], Step [220/234], D Loss: 0.0335, G Loss: 7.8890; D Loss Real: 0.0333, ; D Loss Fake: 0.0003, \n",
      "Epoch [176/300], Step [20/234], D Loss: 0.0378, G Loss: 9.6149; D Loss Real: 0.0378, ; D Loss Fake: 0.0000, \n",
      "Epoch [176/300], Step [40/234], D Loss: 0.0008, G Loss: 8.4298; D Loss Real: 0.0006, ; D Loss Fake: 0.0003, \n",
      "Epoch [176/300], Step [60/234], D Loss: 0.0058, G Loss: 10.3770; D Loss Real: 0.0057, ; D Loss Fake: 0.0000, \n",
      "Epoch [176/300], Step [80/234], D Loss: 0.0205, G Loss: 7.5946; D Loss Real: 0.0174, ; D Loss Fake: 0.0031, \n",
      "Epoch [176/300], Step [100/234], D Loss: 0.0001, G Loss: 12.2400; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [176/300], Step [120/234], D Loss: 0.1379, G Loss: 5.6838; D Loss Real: 0.0069, ; D Loss Fake: 0.1310, \n",
      "Epoch [176/300], Step [140/234], D Loss: 0.0410, G Loss: 12.8206; D Loss Real: 0.0410, ; D Loss Fake: 0.0000, \n",
      "Epoch [176/300], Step [160/234], D Loss: 0.0296, G Loss: 7.2459; D Loss Real: 0.0290, ; D Loss Fake: 0.0005, \n",
      "Epoch [176/300], Step [180/234], D Loss: 0.0133, G Loss: 5.1653; D Loss Real: 0.0019, ; D Loss Fake: 0.0114, \n",
      "Epoch [176/300], Step [200/234], D Loss: 0.0013, G Loss: 9.2816; D Loss Real: 0.0005, ; D Loss Fake: 0.0008, \n",
      "Epoch [176/300], Step [220/234], D Loss: 0.0419, G Loss: 5.6921; D Loss Real: 0.0010, ; D Loss Fake: 0.0410, \n",
      "Epoch [177/300], Step [20/234], D Loss: 0.0240, G Loss: 11.3291; D Loss Real: 0.0021, ; D Loss Fake: 0.0219, \n",
      "Epoch [177/300], Step [40/234], D Loss: 0.0218, G Loss: 10.4629; D Loss Real: 0.0217, ; D Loss Fake: 0.0000, \n",
      "Epoch [177/300], Step [60/234], D Loss: 0.0703, G Loss: 5.4659; D Loss Real: 0.0004, ; D Loss Fake: 0.0699, \n",
      "Epoch [177/300], Step [80/234], D Loss: 0.0053, G Loss: 5.5547; D Loss Real: 0.0004, ; D Loss Fake: 0.0049, \n",
      "Epoch [177/300], Step [100/234], D Loss: 0.0151, G Loss: 5.0854; D Loss Real: 0.0011, ; D Loss Fake: 0.0140, \n",
      "Epoch [177/300], Step [120/234], D Loss: 0.0123, G Loss: 5.2409; D Loss Real: 0.0006, ; D Loss Fake: 0.0117, \n",
      "Epoch [177/300], Step [140/234], D Loss: 0.0134, G Loss: 5.6286; D Loss Real: 0.0084, ; D Loss Fake: 0.0050, \n",
      "Epoch [177/300], Step [160/234], D Loss: 0.0052, G Loss: 7.6916; D Loss Real: 0.0034, ; D Loss Fake: 0.0018, \n",
      "Epoch [177/300], Step [180/234], D Loss: 0.0068, G Loss: 7.4218; D Loss Real: 0.0048, ; D Loss Fake: 0.0021, \n",
      "Epoch [177/300], Step [200/234], D Loss: 0.0085, G Loss: 6.8319; D Loss Real: 0.0078, ; D Loss Fake: 0.0007, \n",
      "Epoch [177/300], Step [220/234], D Loss: 0.0328, G Loss: 3.9932; D Loss Real: 0.0005, ; D Loss Fake: 0.0323, \n",
      "Epoch [178/300], Step [20/234], D Loss: 0.0048, G Loss: 13.5708; D Loss Real: 0.0048, ; D Loss Fake: 0.0000, \n",
      "Epoch [178/300], Step [40/234], D Loss: 0.0004, G Loss: -0.0044; D Loss Real: 0.0004, ; D Loss Fake: 0.0001, \n",
      "Epoch [178/300], Step [60/234], D Loss: 0.0433, G Loss: 6.5693; D Loss Real: 0.0394, ; D Loss Fake: 0.0039, \n",
      "Epoch [178/300], Step [80/234], D Loss: 0.0003, G Loss: 10.1487; D Loss Real: 0.0002, ; D Loss Fake: 0.0001, \n",
      "Epoch [178/300], Step [100/234], D Loss: 0.0129, G Loss: 0.0046; D Loss Real: 0.0126, ; D Loss Fake: 0.0003, \n",
      "Epoch [178/300], Step [120/234], D Loss: 0.0097, G Loss: 8.1704; D Loss Real: 0.0075, ; D Loss Fake: 0.0021, \n",
      "Epoch [178/300], Step [140/234], D Loss: 0.0155, G Loss: 6.3183; D Loss Real: 0.0132, ; D Loss Fake: 0.0023, \n",
      "Epoch [178/300], Step [160/234], D Loss: 0.0048, G Loss: 6.8769; D Loss Real: 0.0038, ; D Loss Fake: 0.0011, \n",
      "Epoch [178/300], Step [180/234], D Loss: 0.0138, G Loss: 5.5307; D Loss Real: 0.0003, ; D Loss Fake: 0.0135, \n",
      "Epoch [178/300], Step [200/234], D Loss: 0.0521, G Loss: 4.9714; D Loss Real: 0.0069, ; D Loss Fake: 0.0452, \n",
      "Epoch [178/300], Step [220/234], D Loss: 0.0683, G Loss: 0.0097; D Loss Real: 0.0397, ; D Loss Fake: 0.0286, \n",
      "Epoch [179/300], Step [20/234], D Loss: 0.0907, G Loss: 12.9262; D Loss Real: 0.0906, ; D Loss Fake: 0.0001, \n",
      "Epoch [179/300], Step [40/234], D Loss: 0.0360, G Loss: 5.6308; D Loss Real: 0.0328, ; D Loss Fake: 0.0032, \n",
      "Epoch [179/300], Step [60/234], D Loss: 0.1041, G Loss: 6.1346; D Loss Real: 0.0469, ; D Loss Fake: 0.0572, \n",
      "Epoch [179/300], Step [80/234], D Loss: 0.0177, G Loss: -0.0136; D Loss Real: 0.0175, ; D Loss Fake: 0.0002, \n",
      "Epoch [179/300], Step [100/234], D Loss: 0.0022, G Loss: 0.0094; D Loss Real: 0.0021, ; D Loss Fake: 0.0000, \n",
      "Epoch [179/300], Step [120/234], D Loss: 0.0750, G Loss: 5.6137; D Loss Real: 0.0003, ; D Loss Fake: 0.0746, \n",
      "Epoch [179/300], Step [140/234], D Loss: 0.0041, G Loss: 10.8456; D Loss Real: 0.0041, ; D Loss Fake: 0.0000, \n",
      "Epoch [179/300], Step [160/234], D Loss: 0.0079, G Loss: 7.5863; D Loss Real: 0.0045, ; D Loss Fake: 0.0034, \n",
      "Epoch [179/300], Step [180/234], D Loss: 1.2398, G Loss: 0.0047; D Loss Real: 0.0008, ; D Loss Fake: 1.2390, \n",
      "Epoch [179/300], Step [200/234], D Loss: 0.0346, G Loss: 5.6674; D Loss Real: 0.0235, ; D Loss Fake: 0.0111, \n",
      "Epoch [179/300], Step [220/234], D Loss: 0.7964, G Loss: 12.8147; D Loss Real: 0.0060, ; D Loss Fake: 0.7904, \n",
      "Epoch [180/300], Step [20/234], D Loss: 0.0115, G Loss: 5.9900; D Loss Real: 0.0065, ; D Loss Fake: 0.0049, \n",
      "Epoch [180/300], Step [40/234], D Loss: 0.0154, G Loss: 5.7477; D Loss Real: 0.0065, ; D Loss Fake: 0.0089, \n",
      "Epoch [180/300], Step [60/234], D Loss: 0.0014, G Loss: 0.0018; D Loss Real: 0.0008, ; D Loss Fake: 0.0006, \n",
      "Epoch [180/300], Step [80/234], D Loss: 0.2259, G Loss: 8.5285; D Loss Real: 0.0127, ; D Loss Fake: 0.2132, \n",
      "Epoch [180/300], Step [100/234], D Loss: 0.0083, G Loss: 11.2366; D Loss Real: 0.0083, ; D Loss Fake: 0.0000, \n",
      "Epoch [180/300], Step [120/234], D Loss: 0.0119, G Loss: 5.9178; D Loss Real: 0.0097, ; D Loss Fake: 0.0022, \n",
      "Epoch [180/300], Step [140/234], D Loss: 0.0020, G Loss: 6.8026; D Loss Real: 0.0010, ; D Loss Fake: 0.0010, \n",
      "Epoch [180/300], Step [160/234], D Loss: 0.0103, G Loss: 7.8066; D Loss Real: 0.0101, ; D Loss Fake: 0.0003, \n",
      "Epoch [180/300], Step [180/234], D Loss: 0.0027, G Loss: 10.8581; D Loss Real: 0.0026, ; D Loss Fake: 0.0000, \n",
      "Epoch [180/300], Step [200/234], D Loss: 0.0060, G Loss: 9.4240; D Loss Real: 0.0059, ; D Loss Fake: 0.0001, \n",
      "Epoch [180/300], Step [220/234], D Loss: 0.0557, G Loss: 7.6805; D Loss Real: 0.0553, ; D Loss Fake: 0.0003, \n",
      "Epoch [181/300], Step [20/234], D Loss: 0.3048, G Loss: 7.9370; D Loss Real: 0.0043, ; D Loss Fake: 0.3004, \n",
      "Epoch [181/300], Step [40/234], D Loss: 0.0690, G Loss: 8.1080; D Loss Real: 0.0035, ; D Loss Fake: 0.0655, \n",
      "Epoch [181/300], Step [60/234], D Loss: 0.0026, G Loss: 7.1934; D Loss Real: 0.0018, ; D Loss Fake: 0.0008, \n",
      "Epoch [181/300], Step [80/234], D Loss: 0.0039, G Loss: 12.0537; D Loss Real: 0.0039, ; D Loss Fake: 0.0000, \n",
      "Epoch [181/300], Step [100/234], D Loss: 0.0038, G Loss: 10.2254; D Loss Real: 0.0036, ; D Loss Fake: 0.0001, \n",
      "Epoch [181/300], Step [120/234], D Loss: 0.0160, G Loss: 5.2459; D Loss Real: 0.0001, ; D Loss Fake: 0.0160, \n",
      "Epoch [181/300], Step [140/234], D Loss: 0.4684, G Loss: 10.5096; D Loss Real: 0.0297, ; D Loss Fake: 0.4387, \n",
      "Epoch [181/300], Step [160/234], D Loss: 0.0303, G Loss: 5.4667; D Loss Real: 0.0239, ; D Loss Fake: 0.0064, \n",
      "Epoch [181/300], Step [180/234], D Loss: 0.0124, G Loss: 7.6798; D Loss Real: 0.0117, ; D Loss Fake: 0.0006, \n",
      "Epoch [181/300], Step [200/234], D Loss: 0.0474, G Loss: 9.5722; D Loss Real: 0.0474, ; D Loss Fake: 0.0000, \n",
      "Epoch [181/300], Step [220/234], D Loss: 0.0133, G Loss: 14.1048; D Loss Real: 0.0133, ; D Loss Fake: 0.0000, \n",
      "Epoch [182/300], Step [20/234], D Loss: 0.0022, G Loss: 9.1703; D Loss Real: 0.0021, ; D Loss Fake: 0.0001, \n",
      "Epoch [182/300], Step [40/234], D Loss: 0.0019, G Loss: 8.3996; D Loss Real: 0.0016, ; D Loss Fake: 0.0004, \n",
      "Epoch [182/300], Step [60/234], D Loss: 0.0051, G Loss: 6.5678; D Loss Real: 0.0035, ; D Loss Fake: 0.0016, \n",
      "Epoch [182/300], Step [80/234], D Loss: 0.0020, G Loss: 8.3738; D Loss Real: 0.0015, ; D Loss Fake: 0.0005, \n",
      "Epoch [182/300], Step [100/234], D Loss: 0.0028, G Loss: 8.5092; D Loss Real: 0.0026, ; D Loss Fake: 0.0002, \n",
      "Epoch [182/300], Step [120/234], D Loss: 0.0062, G Loss: 6.8274; D Loss Real: 0.0032, ; D Loss Fake: 0.0030, \n",
      "Epoch [182/300], Step [140/234], D Loss: 0.0688, G Loss: 5.6752; D Loss Real: 0.0008, ; D Loss Fake: 0.0680, \n",
      "Epoch [182/300], Step [160/234], D Loss: 0.0075, G Loss: 9.5313; D Loss Real: 0.0074, ; D Loss Fake: 0.0001, \n",
      "Epoch [182/300], Step [180/234], D Loss: 0.2677, G Loss: 9.2754; D Loss Real: 0.0011, ; D Loss Fake: 0.2666, \n",
      "Epoch [182/300], Step [200/234], D Loss: 0.0044, G Loss: 9.9426; D Loss Real: 0.0040, ; D Loss Fake: 0.0004, \n",
      "Epoch [182/300], Step [220/234], D Loss: 0.0147, G Loss: 7.3264; D Loss Real: 0.0133, ; D Loss Fake: 0.0014, \n",
      "Epoch [183/300], Step [20/234], D Loss: 0.0100, G Loss: 10.7530; D Loss Real: 0.0098, ; D Loss Fake: 0.0002, \n",
      "Epoch [183/300], Step [40/234], D Loss: 0.0337, G Loss: 7.6501; D Loss Real: 0.0282, ; D Loss Fake: 0.0055, \n",
      "Epoch [183/300], Step [60/234], D Loss: 0.0649, G Loss: 6.7462; D Loss Real: 0.0005, ; D Loss Fake: 0.0645, \n",
      "Epoch [183/300], Step [80/234], D Loss: 0.0080, G Loss: 13.8571; D Loss Real: 0.0058, ; D Loss Fake: 0.0022, \n",
      "Epoch [183/300], Step [100/234], D Loss: 0.1527, G Loss: 6.4424; D Loss Real: 0.0067, ; D Loss Fake: 0.1459, \n",
      "Epoch [183/300], Step [120/234], D Loss: 0.0475, G Loss: 5.4121; D Loss Real: 0.0005, ; D Loss Fake: 0.0470, \n",
      "Epoch [183/300], Step [140/234], D Loss: 0.0379, G Loss: 5.8175; D Loss Real: 0.0037, ; D Loss Fake: 0.0342, \n",
      "Epoch [183/300], Step [160/234], D Loss: 0.0036, G Loss: 8.6081; D Loss Real: 0.0020, ; D Loss Fake: 0.0017, \n",
      "Epoch [183/300], Step [180/234], D Loss: 0.0174, G Loss: 7.5043; D Loss Real: 0.0164, ; D Loss Fake: 0.0010, \n",
      "Epoch [183/300], Step [200/234], D Loss: 0.0097, G Loss: 6.4610; D Loss Real: 0.0085, ; D Loss Fake: 0.0012, \n",
      "Epoch [183/300], Step [220/234], D Loss: 0.0074, G Loss: 6.8163; D Loss Real: 0.0012, ; D Loss Fake: 0.0062, \n",
      "Epoch [184/300], Step [20/234], D Loss: 0.0115, G Loss: 10.2413; D Loss Real: 0.0114, ; D Loss Fake: 0.0000, \n",
      "Epoch [184/300], Step [40/234], D Loss: 0.0170, G Loss: 5.8449; D Loss Real: 0.0035, ; D Loss Fake: 0.0135, \n",
      "Epoch [184/300], Step [60/234], D Loss: 0.0452, G Loss: 6.1173; D Loss Real: 0.0421, ; D Loss Fake: 0.0031, \n",
      "Epoch [184/300], Step [80/234], D Loss: 0.0051, G Loss: 0.0079; D Loss Real: 0.0051, ; D Loss Fake: 0.0000, \n",
      "Epoch [184/300], Step [100/234], D Loss: 0.0083, G Loss: 10.4175; D Loss Real: 0.0083, ; D Loss Fake: 0.0000, \n",
      "Epoch [184/300], Step [120/234], D Loss: 0.0142, G Loss: 7.5632; D Loss Real: 0.0136, ; D Loss Fake: 0.0006, \n",
      "Epoch [184/300], Step [140/234], D Loss: 0.0470, G Loss: 10.1694; D Loss Real: 0.0470, ; D Loss Fake: 0.0000, \n",
      "Epoch [184/300], Step [160/234], D Loss: 0.0053, G Loss: 12.1875; D Loss Real: 0.0052, ; D Loss Fake: 0.0000, \n",
      "Epoch [184/300], Step [180/234], D Loss: 0.0049, G Loss: 8.7441; D Loss Real: 0.0041, ; D Loss Fake: 0.0008, \n",
      "Epoch [184/300], Step [200/234], D Loss: 0.0031, G Loss: 11.3336; D Loss Real: 0.0030, ; D Loss Fake: 0.0000, \n",
      "Epoch [184/300], Step [220/234], D Loss: 0.0350, G Loss: 5.9028; D Loss Real: 0.0007, ; D Loss Fake: 0.0344, \n",
      "Epoch [185/300], Step [20/234], D Loss: 0.0020, G Loss: 10.3611; D Loss Real: 0.0007, ; D Loss Fake: 0.0012, \n",
      "Epoch [185/300], Step [40/234], D Loss: 0.0089, G Loss: 10.3845; D Loss Real: 0.0089, ; D Loss Fake: 0.0000, \n",
      "Epoch [185/300], Step [60/234], D Loss: 0.0094, G Loss: 8.0423; D Loss Real: 0.0090, ; D Loss Fake: 0.0004, \n",
      "Epoch [185/300], Step [80/234], D Loss: 0.1160, G Loss: 10.9138; D Loss Real: 0.1160, ; D Loss Fake: 0.0000, \n",
      "Epoch [185/300], Step [100/234], D Loss: 0.0027, G Loss: 9.8652; D Loss Real: 0.0022, ; D Loss Fake: 0.0005, \n",
      "Epoch [185/300], Step [120/234], D Loss: 0.0040, G Loss: 11.0889; D Loss Real: 0.0040, ; D Loss Fake: 0.0000, \n",
      "Epoch [185/300], Step [140/234], D Loss: 0.0114, G Loss: 9.7123; D Loss Real: 0.0103, ; D Loss Fake: 0.0011, \n",
      "Epoch [185/300], Step [160/234], D Loss: 0.0684, G Loss: 7.5173; D Loss Real: 0.0026, ; D Loss Fake: 0.0658, \n",
      "Epoch [185/300], Step [180/234], D Loss: 0.0138, G Loss: 5.7295; D Loss Real: 0.0082, ; D Loss Fake: 0.0055, \n",
      "Epoch [185/300], Step [200/234], D Loss: 0.0497, G Loss: 5.2626; D Loss Real: 0.0002, ; D Loss Fake: 0.0495, \n",
      "Epoch [185/300], Step [220/234], D Loss: 0.0096, G Loss: 6.8058; D Loss Real: 0.0077, ; D Loss Fake: 0.0018, \n",
      "Epoch [186/300], Step [20/234], D Loss: 0.0041, G Loss: 0.0068; D Loss Real: 0.0038, ; D Loss Fake: 0.0004, \n",
      "Epoch [186/300], Step [40/234], D Loss: 0.1629, G Loss: 7.8188; D Loss Real: 0.0026, ; D Loss Fake: 0.1604, \n",
      "Epoch [186/300], Step [60/234], D Loss: 0.0661, G Loss: 5.7300; D Loss Real: 0.0029, ; D Loss Fake: 0.0632, \n",
      "Epoch [186/300], Step [80/234], D Loss: 0.0047, G Loss: 7.1629; D Loss Real: 0.0041, ; D Loss Fake: 0.0006, \n",
      "Epoch [186/300], Step [100/234], D Loss: 0.0137, G Loss: 5.4091; D Loss Real: 0.0052, ; D Loss Fake: 0.0085, \n",
      "Epoch [186/300], Step [120/234], D Loss: 0.0181, G Loss: 4.7448; D Loss Real: 0.0004, ; D Loss Fake: 0.0178, \n",
      "Epoch [186/300], Step [140/234], D Loss: 0.0186, G Loss: 5.3271; D Loss Real: 0.0059, ; D Loss Fake: 0.0127, \n",
      "Epoch [186/300], Step [160/234], D Loss: 0.0017, G Loss: -0.0109; D Loss Real: 0.0014, ; D Loss Fake: 0.0002, \n",
      "Epoch [186/300], Step [180/234], D Loss: 0.0525, G Loss: 6.1361; D Loss Real: 0.0329, ; D Loss Fake: 0.0195, \n",
      "Epoch [186/300], Step [200/234], D Loss: 0.0048, G Loss: 8.4403; D Loss Real: 0.0029, ; D Loss Fake: 0.0019, \n",
      "Epoch [186/300], Step [220/234], D Loss: 0.0633, G Loss: 8.6591; D Loss Real: 0.0632, ; D Loss Fake: 0.0001, \n",
      "Epoch [187/300], Step [20/234], D Loss: 0.0022, G Loss: 0.0160; D Loss Real: 0.0002, ; D Loss Fake: 0.0020, \n",
      "Epoch [187/300], Step [40/234], D Loss: 0.0034, G Loss: 8.8711; D Loss Real: 0.0011, ; D Loss Fake: 0.0023, \n",
      "Epoch [187/300], Step [60/234], D Loss: 0.0207, G Loss: 10.0978; D Loss Real: 0.0207, ; D Loss Fake: 0.0000, \n",
      "Epoch [187/300], Step [80/234], D Loss: 0.0042, G Loss: 7.1276; D Loss Real: 0.0032, ; D Loss Fake: 0.0011, \n",
      "Epoch [187/300], Step [100/234], D Loss: 0.0649, G Loss: 11.2176; D Loss Real: 0.0649, ; D Loss Fake: 0.0000, \n",
      "Epoch [187/300], Step [120/234], D Loss: 0.0463, G Loss: 5.9217; D Loss Real: 0.0046, ; D Loss Fake: 0.0417, \n",
      "Epoch [187/300], Step [140/234], D Loss: 0.0261, G Loss: 6.5490; D Loss Real: 0.0013, ; D Loss Fake: 0.0248, \n",
      "Epoch [187/300], Step [160/234], D Loss: 0.0003, G Loss: 15.6573; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [187/300], Step [180/234], D Loss: 0.0035, G Loss: 10.9992; D Loss Real: 0.0035, ; D Loss Fake: 0.0000, \n",
      "Epoch [187/300], Step [200/234], D Loss: 0.0920, G Loss: 10.3880; D Loss Real: 0.0920, ; D Loss Fake: 0.0000, \n",
      "Epoch [187/300], Step [220/234], D Loss: 0.0035, G Loss: 6.7230; D Loss Real: 0.0013, ; D Loss Fake: 0.0022, \n",
      "Epoch [188/300], Step [20/234], D Loss: 0.0137, G Loss: 6.6871; D Loss Real: 0.0124, ; D Loss Fake: 0.0012, \n",
      "Epoch [188/300], Step [40/234], D Loss: 0.0021, G Loss: 0.0022; D Loss Real: 0.0014, ; D Loss Fake: 0.0007, \n",
      "Epoch [188/300], Step [60/234], D Loss: 0.0112, G Loss: 6.2246; D Loss Real: 0.0077, ; D Loss Fake: 0.0036, \n",
      "Epoch [188/300], Step [80/234], D Loss: 0.0044, G Loss: -0.0095; D Loss Real: 0.0007, ; D Loss Fake: 0.0037, \n",
      "Epoch [188/300], Step [100/234], D Loss: 0.1901, G Loss: 6.5632; D Loss Real: 0.0010, ; D Loss Fake: 0.1891, \n",
      "Epoch [188/300], Step [120/234], D Loss: 0.0081, G Loss: 11.7263; D Loss Real: 0.0081, ; D Loss Fake: 0.0000, \n",
      "Epoch [188/300], Step [140/234], D Loss: 0.0024, G Loss: 7.4011; D Loss Real: 0.0009, ; D Loss Fake: 0.0015, \n",
      "Epoch [188/300], Step [160/234], D Loss: 0.0053, G Loss: 6.8880; D Loss Real: 0.0032, ; D Loss Fake: 0.0021, \n",
      "Epoch [188/300], Step [180/234], D Loss: 0.0285, G Loss: 5.6144; D Loss Real: 0.0211, ; D Loss Fake: 0.0075, \n",
      "Epoch [188/300], Step [200/234], D Loss: 0.0007, G Loss: 8.9942; D Loss Real: 0.0005, ; D Loss Fake: 0.0002, \n",
      "Epoch [188/300], Step [220/234], D Loss: 0.0222, G Loss: 11.5458; D Loss Real: 0.0220, ; D Loss Fake: 0.0002, \n",
      "Epoch [189/300], Step [20/234], D Loss: 0.0876, G Loss: 5.2124; D Loss Real: 0.0003, ; D Loss Fake: 0.0872, \n",
      "Epoch [189/300], Step [40/234], D Loss: 0.0035, G Loss: 9.8024; D Loss Real: 0.0035, ; D Loss Fake: 0.0000, \n",
      "Epoch [189/300], Step [60/234], D Loss: 0.0124, G Loss: 6.4784; D Loss Real: 0.0111, ; D Loss Fake: 0.0013, \n",
      "Epoch [189/300], Step [80/234], D Loss: 0.0014, G Loss: 8.8202; D Loss Real: 0.0012, ; D Loss Fake: 0.0002, \n",
      "Epoch [189/300], Step [100/234], D Loss: 0.0056, G Loss: 6.6943; D Loss Real: 0.0040, ; D Loss Fake: 0.0016, \n",
      "Epoch [189/300], Step [120/234], D Loss: 0.0074, G Loss: 8.4509; D Loss Real: 0.0009, ; D Loss Fake: 0.0065, \n",
      "Epoch [189/300], Step [140/234], D Loss: 0.0037, G Loss: 6.8615; D Loss Real: 0.0024, ; D Loss Fake: 0.0013, \n",
      "Epoch [189/300], Step [160/234], D Loss: 0.0294, G Loss: 7.7642; D Loss Real: 0.0289, ; D Loss Fake: 0.0004, \n",
      "Epoch [189/300], Step [180/234], D Loss: 0.0281, G Loss: 6.1071; D Loss Real: 0.0267, ; D Loss Fake: 0.0014, \n",
      "Epoch [189/300], Step [200/234], D Loss: 0.0208, G Loss: 9.8331; D Loss Real: 0.0207, ; D Loss Fake: 0.0001, \n",
      "Epoch [189/300], Step [220/234], D Loss: 0.0022, G Loss: 7.4496; D Loss Real: 0.0013, ; D Loss Fake: 0.0009, \n",
      "Epoch [190/300], Step [20/234], D Loss: 0.1409, G Loss: 10.7867; D Loss Real: 0.1409, ; D Loss Fake: 0.0000, \n",
      "Epoch [190/300], Step [40/234], D Loss: 0.0026, G Loss: 7.6366; D Loss Real: 0.0015, ; D Loss Fake: 0.0011, \n",
      "Epoch [190/300], Step [60/234], D Loss: 0.0035, G Loss: 7.5865; D Loss Real: 0.0026, ; D Loss Fake: 0.0009, \n",
      "Epoch [190/300], Step [80/234], D Loss: 0.0243, G Loss: 7.2706; D Loss Real: 0.0235, ; D Loss Fake: 0.0008, \n",
      "Epoch [190/300], Step [100/234], D Loss: 0.0054, G Loss: 6.0012; D Loss Real: 0.0001, ; D Loss Fake: 0.0053, \n",
      "Epoch [190/300], Step [120/234], D Loss: 0.0061, G Loss: 11.5628; D Loss Real: 0.0061, ; D Loss Fake: 0.0000, \n",
      "Epoch [190/300], Step [140/234], D Loss: 0.0397, G Loss: 5.1118; D Loss Real: 0.0131, ; D Loss Fake: 0.0267, \n",
      "Epoch [190/300], Step [160/234], D Loss: 0.0035, G Loss: 8.6841; D Loss Real: 0.0034, ; D Loss Fake: 0.0001, \n",
      "Epoch [190/300], Step [180/234], D Loss: 0.0013, G Loss: 8.8447; D Loss Real: 0.0011, ; D Loss Fake: 0.0001, \n",
      "Epoch [190/300], Step [200/234], D Loss: 0.2806, G Loss: 15.0783; D Loss Real: 0.0016, ; D Loss Fake: 0.2790, \n",
      "Epoch [190/300], Step [220/234], D Loss: 0.0005, G Loss: 8.8660; D Loss Real: 0.0001, ; D Loss Fake: 0.0004, \n",
      "Epoch [191/300], Step [20/234], D Loss: 0.0217, G Loss: 9.6410; D Loss Real: 0.0216, ; D Loss Fake: 0.0002, \n",
      "Epoch [191/300], Step [40/234], D Loss: 0.0097, G Loss: 5.9785; D Loss Real: 0.0025, ; D Loss Fake: 0.0072, \n",
      "Epoch [191/300], Step [60/234], D Loss: 0.0091, G Loss: 0.0051; D Loss Real: 0.0043, ; D Loss Fake: 0.0047, \n",
      "Epoch [191/300], Step [80/234], D Loss: 0.0707, G Loss: 5.5755; D Loss Real: 0.0003, ; D Loss Fake: 0.0704, \n",
      "Epoch [191/300], Step [100/234], D Loss: 0.0264, G Loss: 13.3529; D Loss Real: 0.0264, ; D Loss Fake: 0.0000, \n",
      "Epoch [191/300], Step [120/234], D Loss: 0.0029, G Loss: 7.7488; D Loss Real: 0.0018, ; D Loss Fake: 0.0010, \n",
      "Epoch [191/300], Step [140/234], D Loss: 0.0034, G Loss: 6.9430; D Loss Real: 0.0009, ; D Loss Fake: 0.0025, \n",
      "Epoch [191/300], Step [160/234], D Loss: 0.0025, G Loss: 12.4382; D Loss Real: 0.0025, ; D Loss Fake: 0.0000, \n",
      "Epoch [191/300], Step [180/234], D Loss: 0.0040, G Loss: 6.0025; D Loss Real: 0.0020, ; D Loss Fake: 0.0020, \n",
      "Epoch [191/300], Step [200/234], D Loss: 0.0283, G Loss: 5.3645; D Loss Real: 0.0162, ; D Loss Fake: 0.0121, \n",
      "Epoch [191/300], Step [220/234], D Loss: 0.0751, G Loss: 18.7641; D Loss Real: 0.0751, ; D Loss Fake: -0.0000, \n",
      "Epoch [192/300], Step [20/234], D Loss: 0.0358, G Loss: 5.3119; D Loss Real: 0.0008, ; D Loss Fake: 0.0350, \n",
      "Epoch [192/300], Step [40/234], D Loss: 0.0068, G Loss: 11.1946; D Loss Real: 0.0068, ; D Loss Fake: 0.0000, \n",
      "Epoch [192/300], Step [60/234], D Loss: 0.0399, G Loss: 6.4066; D Loss Real: 0.0379, ; D Loss Fake: 0.0021, \n",
      "Epoch [192/300], Step [80/234], D Loss: 0.0062, G Loss: 10.1094; D Loss Real: 0.0061, ; D Loss Fake: 0.0000, \n",
      "Epoch [192/300], Step [100/234], D Loss: 0.0074, G Loss: 8.5788; D Loss Real: 0.0073, ; D Loss Fake: 0.0001, \n",
      "Epoch [192/300], Step [120/234], D Loss: 0.0424, G Loss: 5.3609; D Loss Real: 0.0355, ; D Loss Fake: 0.0069, \n",
      "Epoch [192/300], Step [140/234], D Loss: 0.0013, G Loss: 7.3948; D Loss Real: 0.0007, ; D Loss Fake: 0.0006, \n",
      "Epoch [192/300], Step [160/234], D Loss: 0.0067, G Loss: 8.8952; D Loss Real: 0.0065, ; D Loss Fake: 0.0002, \n",
      "Epoch [192/300], Step [180/234], D Loss: 0.0566, G Loss: 12.7124; D Loss Real: 0.0566, ; D Loss Fake: 0.0000, \n",
      "Epoch [192/300], Step [200/234], D Loss: 0.0186, G Loss: 12.0510; D Loss Real: 0.0186, ; D Loss Fake: 0.0000, \n",
      "Epoch [192/300], Step [220/234], D Loss: 0.0026, G Loss: 12.7447; D Loss Real: 0.0026, ; D Loss Fake: 0.0000, \n",
      "Epoch [193/300], Step [20/234], D Loss: 0.0071, G Loss: 6.0732; D Loss Real: 0.0008, ; D Loss Fake: 0.0063, \n",
      "Epoch [193/300], Step [40/234], D Loss: 0.0037, G Loss: 7.5537; D Loss Real: 0.0027, ; D Loss Fake: 0.0011, \n",
      "Epoch [193/300], Step [60/234], D Loss: 0.3138, G Loss: 10.0709; D Loss Real: 0.0024, ; D Loss Fake: 0.3114, \n",
      "Epoch [193/300], Step [80/234], D Loss: 0.0131, G Loss: 0.0149; D Loss Real: 0.0074, ; D Loss Fake: 0.0057, \n",
      "Epoch [193/300], Step [100/234], D Loss: 0.0041, G Loss: 8.0460; D Loss Real: 0.0031, ; D Loss Fake: 0.0010, \n",
      "Epoch [193/300], Step [120/234], D Loss: 0.0041, G Loss: 8.6242; D Loss Real: 0.0038, ; D Loss Fake: 0.0003, \n",
      "Epoch [193/300], Step [140/234], D Loss: 0.0034, G Loss: 10.2264; D Loss Real: 0.0031, ; D Loss Fake: 0.0002, \n",
      "Epoch [193/300], Step [160/234], D Loss: 0.0169, G Loss: 5.7908; D Loss Real: 0.0129, ; D Loss Fake: 0.0040, \n",
      "Epoch [193/300], Step [180/234], D Loss: 0.0064, G Loss: 6.6975; D Loss Real: 0.0028, ; D Loss Fake: 0.0036, \n",
      "Epoch [193/300], Step [200/234], D Loss: 0.0679, G Loss: 5.1482; D Loss Real: 0.0003, ; D Loss Fake: 0.0677, \n",
      "Epoch [193/300], Step [220/234], D Loss: 0.0111, G Loss: 7.2955; D Loss Real: 0.0100, ; D Loss Fake: 0.0011, \n",
      "Epoch [194/300], Step [20/234], D Loss: 0.0367, G Loss: 5.4891; D Loss Real: 0.0114, ; D Loss Fake: 0.0253, \n",
      "Epoch [194/300], Step [40/234], D Loss: 0.1703, G Loss: 5.6089; D Loss Real: 0.1682, ; D Loss Fake: 0.0021, \n",
      "Epoch [194/300], Step [60/234], D Loss: 0.0077, G Loss: 6.4689; D Loss Real: 0.0040, ; D Loss Fake: 0.0036, \n",
      "Epoch [194/300], Step [80/234], D Loss: 0.1031, G Loss: 5.8183; D Loss Real: 0.0111, ; D Loss Fake: 0.0919, \n",
      "Epoch [194/300], Step [100/234], D Loss: 0.0261, G Loss: 9.1457; D Loss Real: 0.0259, ; D Loss Fake: 0.0002, \n",
      "Epoch [194/300], Step [120/234], D Loss: 0.0339, G Loss: 11.8976; D Loss Real: 0.0339, ; D Loss Fake: 0.0001, \n",
      "Epoch [194/300], Step [140/234], D Loss: 0.0178, G Loss: 5.9596; D Loss Real: 0.0002, ; D Loss Fake: 0.0176, \n",
      "Epoch [194/300], Step [160/234], D Loss: 0.0105, G Loss: 6.5975; D Loss Real: 0.0062, ; D Loss Fake: 0.0043, \n",
      "Epoch [194/300], Step [180/234], D Loss: 0.0008, G Loss: 9.1831; D Loss Real: 0.0007, ; D Loss Fake: 0.0001, \n",
      "Epoch [194/300], Step [200/234], D Loss: 0.0012, G Loss: 7.8442; D Loss Real: 0.0008, ; D Loss Fake: 0.0004, \n",
      "Epoch [194/300], Step [220/234], D Loss: 0.0718, G Loss: -0.0034; D Loss Real: 0.0718, ; D Loss Fake: 0.0000, \n",
      "Epoch [195/300], Step [20/234], D Loss: 0.0039, G Loss: 8.6090; D Loss Real: 0.0016, ; D Loss Fake: 0.0023, \n",
      "Epoch [195/300], Step [40/234], D Loss: 0.0730, G Loss: 0.0022; D Loss Real: 0.0726, ; D Loss Fake: 0.0004, \n",
      "Epoch [195/300], Step [60/234], D Loss: 0.0028, G Loss: 6.4540; D Loss Real: 0.0003, ; D Loss Fake: 0.0025, \n",
      "Epoch [195/300], Step [80/234], D Loss: 0.1079, G Loss: 21.3369; D Loss Real: 0.1079, ; D Loss Fake: -0.0000, \n",
      "Epoch [195/300], Step [100/234], D Loss: 0.1333, G Loss: 10.2972; D Loss Real: 0.1333, ; D Loss Fake: 0.0000, \n",
      "Epoch [195/300], Step [120/234], D Loss: 0.0521, G Loss: 11.4578; D Loss Real: 0.0520, ; D Loss Fake: 0.0002, \n",
      "Epoch [195/300], Step [140/234], D Loss: 0.0038, G Loss: 12.4506; D Loss Real: 0.0038, ; D Loss Fake: 0.0000, \n",
      "Epoch [195/300], Step [160/234], D Loss: 0.0225, G Loss: 8.3733; D Loss Real: 0.0223, ; D Loss Fake: 0.0002, \n",
      "Epoch [195/300], Step [180/234], D Loss: 0.0018, G Loss: 0.0134; D Loss Real: 0.0017, ; D Loss Fake: 0.0001, \n",
      "Epoch [195/300], Step [200/234], D Loss: 0.0028, G Loss: 9.1332; D Loss Real: 0.0027, ; D Loss Fake: 0.0001, \n",
      "Epoch [195/300], Step [220/234], D Loss: 0.3408, G Loss: 5.0581; D Loss Real: 0.3407, ; D Loss Fake: 0.0001, \n",
      "Epoch [196/300], Step [20/234], D Loss: 0.0229, G Loss: 6.0255; D Loss Real: 0.0002, ; D Loss Fake: 0.0227, \n",
      "Epoch [196/300], Step [40/234], D Loss: 0.1312, G Loss: -0.0016; D Loss Real: 0.0019, ; D Loss Fake: 0.1293, \n",
      "Epoch [196/300], Step [60/234], D Loss: 0.0116, G Loss: 9.1644; D Loss Real: 0.0115, ; D Loss Fake: 0.0001, \n",
      "Epoch [196/300], Step [80/234], D Loss: 0.0122, G Loss: 6.0759; D Loss Real: 0.0005, ; D Loss Fake: 0.0117, \n",
      "Epoch [196/300], Step [100/234], D Loss: 0.0038, G Loss: 5.8524; D Loss Real: 0.0007, ; D Loss Fake: 0.0031, \n",
      "Epoch [196/300], Step [120/234], D Loss: 0.0869, G Loss: 6.2113; D Loss Real: 0.0000, ; D Loss Fake: 0.0868, \n",
      "Epoch [196/300], Step [140/234], D Loss: 0.0098, G Loss: 6.4438; D Loss Real: 0.0075, ; D Loss Fake: 0.0023, \n",
      "Epoch [196/300], Step [160/234], D Loss: 0.0678, G Loss: 5.8933; D Loss Real: 0.0024, ; D Loss Fake: 0.0654, \n",
      "Epoch [196/300], Step [180/234], D Loss: 0.0111, G Loss: 5.6271; D Loss Real: 0.0027, ; D Loss Fake: 0.0084, \n",
      "Epoch [196/300], Step [200/234], D Loss: 0.0568, G Loss: 12.0649; D Loss Real: 0.0568, ; D Loss Fake: 0.0001, \n",
      "Epoch [196/300], Step [220/234], D Loss: 0.0246, G Loss: 5.3544; D Loss Real: 0.0047, ; D Loss Fake: 0.0199, \n",
      "Epoch [197/300], Step [20/234], D Loss: 0.0130, G Loss: 5.3822; D Loss Real: 0.0039, ; D Loss Fake: 0.0091, \n",
      "Epoch [197/300], Step [40/234], D Loss: 0.0004, G Loss: 8.5502; D Loss Real: 0.0002, ; D Loss Fake: 0.0002, \n",
      "Epoch [197/300], Step [60/234], D Loss: 0.0035, G Loss: -0.0043; D Loss Real: 0.0034, ; D Loss Fake: 0.0000, \n",
      "Epoch [197/300], Step [80/234], D Loss: 0.0081, G Loss: 6.2511; D Loss Real: 0.0029, ; D Loss Fake: 0.0051, \n",
      "Epoch [197/300], Step [100/234], D Loss: 0.0016, G Loss: 11.8822; D Loss Real: 0.0016, ; D Loss Fake: 0.0000, \n",
      "Epoch [197/300], Step [120/234], D Loss: 0.0021, G Loss: 12.2672; D Loss Real: 0.0021, ; D Loss Fake: 0.0000, \n",
      "Epoch [197/300], Step [140/234], D Loss: 0.0832, G Loss: 7.5890; D Loss Real: 0.0091, ; D Loss Fake: 0.0741, \n",
      "Epoch [197/300], Step [160/234], D Loss: 0.0003, G Loss: 10.3288; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [197/300], Step [180/234], D Loss: 0.0659, G Loss: 6.8824; D Loss Real: 0.0411, ; D Loss Fake: 0.0248, \n",
      "Epoch [197/300], Step [200/234], D Loss: 0.0058, G Loss: 11.5640; D Loss Real: 0.0058, ; D Loss Fake: 0.0000, \n",
      "Epoch [197/300], Step [220/234], D Loss: 0.0418, G Loss: 10.7958; D Loss Real: 0.0418, ; D Loss Fake: 0.0000, \n",
      "Epoch [198/300], Step [20/234], D Loss: 0.0068, G Loss: -0.0075; D Loss Real: 0.0068, ; D Loss Fake: 0.0000, \n",
      "Epoch [198/300], Step [40/234], D Loss: 0.0105, G Loss: 7.6368; D Loss Real: 0.0087, ; D Loss Fake: 0.0018, \n",
      "Epoch [198/300], Step [60/234], D Loss: 0.0131, G Loss: 0.0150; D Loss Real: 0.0068, ; D Loss Fake: 0.0063, \n",
      "Epoch [198/300], Step [80/234], D Loss: 0.0032, G Loss: 0.0127; D Loss Real: 0.0002, ; D Loss Fake: 0.0031, \n",
      "Epoch [198/300], Step [100/234], D Loss: 0.0019, G Loss: 8.5796; D Loss Real: 0.0017, ; D Loss Fake: 0.0002, \n",
      "Epoch [198/300], Step [120/234], D Loss: 0.0460, G Loss: 12.6785; D Loss Real: 0.0460, ; D Loss Fake: 0.0000, \n",
      "Epoch [198/300], Step [140/234], D Loss: 0.0022, G Loss: 8.3429; D Loss Real: 0.0019, ; D Loss Fake: 0.0003, \n",
      "Epoch [198/300], Step [160/234], D Loss: 0.0031, G Loss: 8.0283; D Loss Real: 0.0003, ; D Loss Fake: 0.0028, \n",
      "Epoch [198/300], Step [180/234], D Loss: 0.0264, G Loss: 6.0456; D Loss Real: 0.0243, ; D Loss Fake: 0.0021, \n",
      "Epoch [198/300], Step [200/234], D Loss: 0.0011, G Loss: 7.5572; D Loss Real: 0.0003, ; D Loss Fake: 0.0008, \n",
      "Epoch [198/300], Step [220/234], D Loss: 0.0206, G Loss: 6.9411; D Loss Real: 0.0182, ; D Loss Fake: 0.0024, \n",
      "Epoch [199/300], Step [20/234], D Loss: 0.0392, G Loss: 5.9325; D Loss Real: 0.0037, ; D Loss Fake: 0.0356, \n",
      "Epoch [199/300], Step [40/234], D Loss: 0.1074, G Loss: 7.2913; D Loss Real: 0.0958, ; D Loss Fake: 0.0116, \n",
      "Epoch [199/300], Step [60/234], D Loss: 0.0448, G Loss: 5.4384; D Loss Real: 0.0080, ; D Loss Fake: 0.0368, \n",
      "Epoch [199/300], Step [80/234], D Loss: 0.0036, G Loss: 13.8537; D Loss Real: 0.0036, ; D Loss Fake: 0.0000, \n",
      "Epoch [199/300], Step [100/234], D Loss: 0.0052, G Loss: 7.2832; D Loss Real: 0.0030, ; D Loss Fake: 0.0022, \n",
      "Epoch [199/300], Step [120/234], D Loss: 0.0032, G Loss: 8.7021; D Loss Real: 0.0026, ; D Loss Fake: 0.0006, \n",
      "Epoch [199/300], Step [140/234], D Loss: 0.0426, G Loss: 5.7446; D Loss Real: 0.0025, ; D Loss Fake: 0.0401, \n",
      "Epoch [199/300], Step [160/234], D Loss: 0.0517, G Loss: 9.8922; D Loss Real: 0.0517, ; D Loss Fake: 0.0001, \n",
      "Epoch [199/300], Step [180/234], D Loss: 0.0041, G Loss: 8.6220; D Loss Real: 0.0038, ; D Loss Fake: 0.0002, \n",
      "Epoch [199/300], Step [200/234], D Loss: 0.0246, G Loss: 4.8992; D Loss Real: 0.0014, ; D Loss Fake: 0.0232, \n",
      "Epoch [199/300], Step [220/234], D Loss: 0.3157, G Loss: 8.3299; D Loss Real: 0.3157, ; D Loss Fake: 0.0000, \n",
      "Epoch [200/300], Step [20/234], D Loss: 0.0180, G Loss: 6.2246; D Loss Real: 0.0008, ; D Loss Fake: 0.0172, \n",
      "Epoch [200/300], Step [40/234], D Loss: 0.0038, G Loss: 9.3718; D Loss Real: 0.0037, ; D Loss Fake: 0.0001, \n",
      "Epoch [200/300], Step [60/234], D Loss: 0.1047, G Loss: 7.7035; D Loss Real: 0.0008, ; D Loss Fake: 0.1039, \n",
      "Epoch [200/300], Step [80/234], D Loss: 0.0651, G Loss: 10.1461; D Loss Real: 0.0648, ; D Loss Fake: 0.0002, \n",
      "Epoch [200/300], Step [100/234], D Loss: 0.0040, G Loss: 5.5144; D Loss Real: 0.0008, ; D Loss Fake: 0.0033, \n",
      "Epoch [200/300], Step [120/234], D Loss: 0.0117, G Loss: 5.4010; D Loss Real: 0.0040, ; D Loss Fake: 0.0076, \n",
      "Epoch [200/300], Step [140/234], D Loss: 0.2595, G Loss: 12.9494; D Loss Real: 0.0109, ; D Loss Fake: 0.2486, \n",
      "Epoch [200/300], Step [160/234], D Loss: 0.0010, G Loss: 13.6928; D Loss Real: 0.0009, ; D Loss Fake: 0.0001, \n",
      "Epoch [200/300], Step [180/234], D Loss: 0.0334, G Loss: 9.7671; D Loss Real: 0.0334, ; D Loss Fake: 0.0000, \n",
      "Epoch [200/300], Step [200/234], D Loss: 0.0275, G Loss: 6.5458; D Loss Real: 0.0231, ; D Loss Fake: 0.0044, \n",
      "Epoch [200/300], Step [220/234], D Loss: 0.0064, G Loss: 9.1631; D Loss Real: 0.0062, ; D Loss Fake: 0.0002, \n",
      "Epoch [201/300], Step [20/234], D Loss: 0.1749, G Loss: 11.0084; D Loss Real: 0.0047, ; D Loss Fake: 0.1702, \n",
      "Epoch [201/300], Step [40/234], D Loss: 0.5087, G Loss: 7.8570; D Loss Real: 0.5087, ; D Loss Fake: 0.0000, \n",
      "Epoch [201/300], Step [60/234], D Loss: 0.0028, G Loss: 16.6698; D Loss Real: 0.0028, ; D Loss Fake: 0.0000, \n",
      "Epoch [201/300], Step [80/234], D Loss: 0.0073, G Loss: 16.4841; D Loss Real: 0.0073, ; D Loss Fake: 0.0000, \n",
      "Epoch [201/300], Step [100/234], D Loss: 0.0035, G Loss: 7.8810; D Loss Real: 0.0021, ; D Loss Fake: 0.0014, \n",
      "Epoch [201/300], Step [120/234], D Loss: 0.0239, G Loss: 6.5392; D Loss Real: 0.0003, ; D Loss Fake: 0.0236, \n",
      "Epoch [201/300], Step [140/234], D Loss: 0.0133, G Loss: 5.4879; D Loss Real: 0.0022, ; D Loss Fake: 0.0111, \n",
      "Epoch [201/300], Step [160/234], D Loss: 0.0510, G Loss: 7.7948; D Loss Real: 0.0000, ; D Loss Fake: 0.0509, \n",
      "Epoch [201/300], Step [180/234], D Loss: 0.0232, G Loss: 0.0080; D Loss Real: 0.0099, ; D Loss Fake: 0.0134, \n",
      "Epoch [201/300], Step [200/234], D Loss: 0.0452, G Loss: 6.9663; D Loss Real: 0.0002, ; D Loss Fake: 0.0450, \n",
      "Epoch [201/300], Step [220/234], D Loss: 0.0031, G Loss: 8.8639; D Loss Real: 0.0029, ; D Loss Fake: 0.0001, \n",
      "Epoch [202/300], Step [20/234], D Loss: 0.0226, G Loss: 7.5788; D Loss Real: 0.0020, ; D Loss Fake: 0.0207, \n",
      "Epoch [202/300], Step [40/234], D Loss: 0.0436, G Loss: 5.9969; D Loss Real: 0.0028, ; D Loss Fake: 0.0408, \n",
      "Epoch [202/300], Step [60/234], D Loss: 0.0046, G Loss: 6.3821; D Loss Real: 0.0004, ; D Loss Fake: 0.0041, \n",
      "Epoch [202/300], Step [80/234], D Loss: 0.0178, G Loss: -0.0014; D Loss Real: 0.0174, ; D Loss Fake: 0.0004, \n",
      "Epoch [202/300], Step [100/234], D Loss: 0.0042, G Loss: 7.9283; D Loss Real: 0.0014, ; D Loss Fake: 0.0028, \n",
      "Epoch [202/300], Step [120/234], D Loss: 0.0016, G Loss: 7.7368; D Loss Real: 0.0011, ; D Loss Fake: 0.0005, \n",
      "Epoch [202/300], Step [140/234], D Loss: 0.0089, G Loss: 5.6864; D Loss Real: 0.0020, ; D Loss Fake: 0.0069, \n",
      "Epoch [202/300], Step [160/234], D Loss: 0.0002, G Loss: 15.2699; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [202/300], Step [180/234], D Loss: 0.0019, G Loss: 6.6632; D Loss Real: 0.0001, ; D Loss Fake: 0.0019, \n",
      "Epoch [202/300], Step [200/234], D Loss: 0.0009, G Loss: 12.8507; D Loss Real: 0.0009, ; D Loss Fake: 0.0000, \n",
      "Epoch [202/300], Step [220/234], D Loss: 0.0215, G Loss: 5.1328; D Loss Real: 0.0003, ; D Loss Fake: 0.0213, \n",
      "Epoch [203/300], Step [20/234], D Loss: 0.0007, G Loss: 9.8617; D Loss Real: 0.0006, ; D Loss Fake: 0.0001, \n",
      "Epoch [203/300], Step [40/234], D Loss: 0.0212, G Loss: 6.4624; D Loss Real: 0.0187, ; D Loss Fake: 0.0025, \n",
      "Epoch [203/300], Step [60/234], D Loss: 0.0021, G Loss: 9.9516; D Loss Real: 0.0017, ; D Loss Fake: 0.0004, \n",
      "Epoch [203/300], Step [80/234], D Loss: 0.0085, G Loss: 7.2487; D Loss Real: 0.0039, ; D Loss Fake: 0.0046, \n",
      "Epoch [203/300], Step [100/234], D Loss: 0.0092, G Loss: 6.6399; D Loss Real: 0.0021, ; D Loss Fake: 0.0071, \n",
      "Epoch [203/300], Step [120/234], D Loss: 0.0030, G Loss: 6.9528; D Loss Real: 0.0016, ; D Loss Fake: 0.0014, \n",
      "Epoch [203/300], Step [140/234], D Loss: 0.1470, G Loss: 7.8233; D Loss Real: 0.0051, ; D Loss Fake: 0.1418, \n",
      "Epoch [203/300], Step [160/234], D Loss: 0.0001, G Loss: 12.2828; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [203/300], Step [180/234], D Loss: 0.0034, G Loss: 6.4133; D Loss Real: 0.0009, ; D Loss Fake: 0.0025, \n",
      "Epoch [203/300], Step [200/234], D Loss: 0.0172, G Loss: 5.4219; D Loss Real: 0.0054, ; D Loss Fake: 0.0118, \n",
      "Epoch [203/300], Step [220/234], D Loss: 0.0184, G Loss: 8.7553; D Loss Real: 0.0183, ; D Loss Fake: 0.0001, \n",
      "Epoch [204/300], Step [20/234], D Loss: 0.0096, G Loss: 9.5199; D Loss Real: 0.0095, ; D Loss Fake: 0.0001, \n",
      "Epoch [204/300], Step [40/234], D Loss: 0.0041, G Loss: 11.2645; D Loss Real: 0.0039, ; D Loss Fake: 0.0002, \n",
      "Epoch [204/300], Step [60/234], D Loss: 0.0099, G Loss: 5.8434; D Loss Real: 0.0004, ; D Loss Fake: 0.0094, \n",
      "Epoch [204/300], Step [80/234], D Loss: 0.0040, G Loss: 6.8294; D Loss Real: 0.0015, ; D Loss Fake: 0.0025, \n",
      "Epoch [204/300], Step [100/234], D Loss: 0.0753, G Loss: 6.2766; D Loss Real: 0.0002, ; D Loss Fake: 0.0751, \n",
      "Epoch [204/300], Step [120/234], D Loss: 0.0158, G Loss: 5.7602; D Loss Real: 0.0107, ; D Loss Fake: 0.0050, \n",
      "Epoch [204/300], Step [140/234], D Loss: 0.0335, G Loss: 6.4916; D Loss Real: 0.0021, ; D Loss Fake: 0.0314, \n",
      "Epoch [204/300], Step [160/234], D Loss: 0.0092, G Loss: 7.7924; D Loss Real: 0.0022, ; D Loss Fake: 0.0070, \n",
      "Epoch [204/300], Step [180/234], D Loss: 0.0045, G Loss: 8.5928; D Loss Real: 0.0043, ; D Loss Fake: 0.0002, \n",
      "Epoch [204/300], Step [200/234], D Loss: 0.0086, G Loss: 5.6267; D Loss Real: 0.0026, ; D Loss Fake: 0.0060, \n",
      "Epoch [204/300], Step [220/234], D Loss: 0.2297, G Loss: 12.0385; D Loss Real: 0.2297, ; D Loss Fake: 0.0000, \n",
      "Epoch [205/300], Step [20/234], D Loss: 0.0669, G Loss: 5.9321; D Loss Real: 0.0290, ; D Loss Fake: 0.0379, \n",
      "Epoch [205/300], Step [40/234], D Loss: 0.0369, G Loss: 5.2225; D Loss Real: 0.0009, ; D Loss Fake: 0.0360, \n",
      "Epoch [205/300], Step [60/234], D Loss: 0.0290, G Loss: 4.9217; D Loss Real: 0.0002, ; D Loss Fake: 0.0288, \n",
      "Epoch [205/300], Step [80/234], D Loss: 0.0086, G Loss: 0.0242; D Loss Real: 0.0086, ; D Loss Fake: 0.0000, \n",
      "Epoch [205/300], Step [100/234], D Loss: 0.0102, G Loss: 7.7736; D Loss Real: 0.0027, ; D Loss Fake: 0.0075, \n",
      "Epoch [205/300], Step [120/234], D Loss: 0.0085, G Loss: 0.0080; D Loss Real: 0.0006, ; D Loss Fake: 0.0079, \n",
      "Epoch [205/300], Step [140/234], D Loss: 0.0891, G Loss: 6.8210; D Loss Real: 0.0642, ; D Loss Fake: 0.0248, \n",
      "Epoch [205/300], Step [160/234], D Loss: 0.1660, G Loss: 5.5059; D Loss Real: 0.1648, ; D Loss Fake: 0.0012, \n",
      "Epoch [205/300], Step [180/234], D Loss: 0.0009, G Loss: 7.9615; D Loss Real: 0.0002, ; D Loss Fake: 0.0006, \n",
      "Epoch [205/300], Step [200/234], D Loss: 0.0133, G Loss: 6.4144; D Loss Real: 0.0001, ; D Loss Fake: 0.0131, \n",
      "Epoch [205/300], Step [220/234], D Loss: 0.0402, G Loss: 0.0023; D Loss Real: 0.0386, ; D Loss Fake: 0.0016, \n",
      "Epoch [206/300], Step [20/234], D Loss: 0.0034, G Loss: 0.0009; D Loss Real: 0.0031, ; D Loss Fake: 0.0003, \n",
      "Epoch [206/300], Step [40/234], D Loss: 0.0081, G Loss: 0.0026; D Loss Real: 0.0080, ; D Loss Fake: 0.0000, \n",
      "Epoch [206/300], Step [60/234], D Loss: 0.0209, G Loss: 5.9427; D Loss Real: 0.0169, ; D Loss Fake: 0.0039, \n",
      "Epoch [206/300], Step [80/234], D Loss: 0.0011, G Loss: 10.5131; D Loss Real: 0.0011, ; D Loss Fake: 0.0000, \n",
      "Epoch [206/300], Step [100/234], D Loss: 0.0058, G Loss: 5.4285; D Loss Real: 0.0003, ; D Loss Fake: 0.0056, \n",
      "Epoch [206/300], Step [120/234], D Loss: 0.0040, G Loss: 9.5284; D Loss Real: 0.0039, ; D Loss Fake: 0.0001, \n",
      "Epoch [206/300], Step [140/234], D Loss: 0.0019, G Loss: 8.8806; D Loss Real: 0.0018, ; D Loss Fake: 0.0001, \n",
      "Epoch [206/300], Step [160/234], D Loss: 0.0191, G Loss: 8.6607; D Loss Real: 0.0190, ; D Loss Fake: 0.0001, \n",
      "Epoch [206/300], Step [180/234], D Loss: 0.0151, G Loss: 10.2971; D Loss Real: 0.0150, ; D Loss Fake: 0.0001, \n",
      "Epoch [206/300], Step [200/234], D Loss: 0.0041, G Loss: 8.6164; D Loss Real: 0.0039, ; D Loss Fake: 0.0002, \n",
      "Epoch [206/300], Step [220/234], D Loss: 0.0890, G Loss: 6.1590; D Loss Real: 0.0016, ; D Loss Fake: 0.0874, \n",
      "Epoch [207/300], Step [20/234], D Loss: 0.0197, G Loss: 9.4406; D Loss Real: 0.0196, ; D Loss Fake: 0.0001, \n",
      "Epoch [207/300], Step [40/234], D Loss: 0.1817, G Loss: 7.5060; D Loss Real: 0.0002, ; D Loss Fake: 0.1815, \n",
      "Epoch [207/300], Step [60/234], D Loss: 0.0103, G Loss: 7.5255; D Loss Real: 0.0100, ; D Loss Fake: 0.0003, \n",
      "Epoch [207/300], Step [80/234], D Loss: 0.0193, G Loss: 7.4130; D Loss Real: 0.0186, ; D Loss Fake: 0.0007, \n",
      "Epoch [207/300], Step [100/234], D Loss: 0.0027, G Loss: 12.4598; D Loss Real: 0.0027, ; D Loss Fake: 0.0000, \n",
      "Epoch [207/300], Step [120/234], D Loss: 0.0041, G Loss: 8.3087; D Loss Real: 0.0036, ; D Loss Fake: 0.0005, \n",
      "Epoch [207/300], Step [140/234], D Loss: 0.1529, G Loss: 7.9287; D Loss Real: 0.0071, ; D Loss Fake: 0.1459, \n",
      "Epoch [207/300], Step [160/234], D Loss: 0.0158, G Loss: 6.9350; D Loss Real: 0.0100, ; D Loss Fake: 0.0057, \n",
      "Epoch [207/300], Step [180/234], D Loss: 0.0531, G Loss: 6.2543; D Loss Real: 0.0012, ; D Loss Fake: 0.0520, \n",
      "Epoch [207/300], Step [200/234], D Loss: 0.0042, G Loss: 8.5289; D Loss Real: 0.0031, ; D Loss Fake: 0.0011, \n",
      "Epoch [207/300], Step [220/234], D Loss: 0.0990, G Loss: 8.3511; D Loss Real: 0.0988, ; D Loss Fake: 0.0002, \n",
      "Epoch [208/300], Step [20/234], D Loss: 0.0180, G Loss: 6.6500; D Loss Real: 0.0001, ; D Loss Fake: 0.0179, \n",
      "Epoch [208/300], Step [40/234], D Loss: 0.0024, G Loss: 7.3493; D Loss Real: 0.0011, ; D Loss Fake: 0.0013, \n",
      "Epoch [208/300], Step [60/234], D Loss: 0.0007, G Loss: 9.5488; D Loss Real: 0.0006, ; D Loss Fake: 0.0001, \n",
      "Epoch [208/300], Step [80/234], D Loss: 0.1705, G Loss: 7.9476; D Loss Real: 0.0014, ; D Loss Fake: 0.1690, \n",
      "Epoch [208/300], Step [100/234], D Loss: 0.0016, G Loss: 7.1951; D Loss Real: 0.0003, ; D Loss Fake: 0.0014, \n",
      "Epoch [208/300], Step [120/234], D Loss: 0.0020, G Loss: 7.7938; D Loss Real: 0.0010, ; D Loss Fake: 0.0010, \n",
      "Epoch [208/300], Step [140/234], D Loss: 0.0005, G Loss: 9.9231; D Loss Real: 0.0005, ; D Loss Fake: 0.0000, \n",
      "Epoch [208/300], Step [160/234], D Loss: 0.0023, G Loss: 6.9520; D Loss Real: 0.0004, ; D Loss Fake: 0.0019, \n",
      "Epoch [208/300], Step [180/234], D Loss: 0.0080, G Loss: 8.2448; D Loss Real: 0.0079, ; D Loss Fake: 0.0001, \n",
      "Epoch [208/300], Step [200/234], D Loss: 0.0047, G Loss: 12.2081; D Loss Real: 0.0047, ; D Loss Fake: 0.0000, \n",
      "Epoch [208/300], Step [220/234], D Loss: 0.0284, G Loss: 5.7279; D Loss Real: 0.0010, ; D Loss Fake: 0.0273, \n",
      "Epoch [209/300], Step [20/234], D Loss: 0.0188, G Loss: 14.2677; D Loss Real: 0.0188, ; D Loss Fake: 0.0000, \n",
      "Epoch [209/300], Step [40/234], D Loss: 0.0437, G Loss: 10.6569; D Loss Real: 0.0434, ; D Loss Fake: 0.0003, \n",
      "Epoch [209/300], Step [60/234], D Loss: 0.0004, G Loss: 20.3894; D Loss Real: 0.0004, ; D Loss Fake: -0.0000, \n",
      "Epoch [209/300], Step [80/234], D Loss: 0.0023, G Loss: 8.7448; D Loss Real: 0.0020, ; D Loss Fake: 0.0003, \n",
      "Epoch [209/300], Step [100/234], D Loss: 0.0083, G Loss: 8.7200; D Loss Real: 0.0037, ; D Loss Fake: 0.0046, \n",
      "Epoch [209/300], Step [120/234], D Loss: 0.0006, G Loss: 7.9637; D Loss Real: 0.0003, ; D Loss Fake: 0.0003, \n",
      "Epoch [209/300], Step [140/234], D Loss: 0.0022, G Loss: 9.3470; D Loss Real: 0.0020, ; D Loss Fake: 0.0002, \n",
      "Epoch [209/300], Step [160/234], D Loss: 0.0033, G Loss: 0.0196; D Loss Real: 0.0025, ; D Loss Fake: 0.0008, \n",
      "Epoch [209/300], Step [180/234], D Loss: 0.0011, G Loss: 7.9921; D Loss Real: 0.0008, ; D Loss Fake: 0.0003, \n",
      "Epoch [209/300], Step [200/234], D Loss: 0.0102, G Loss: 5.8269; D Loss Real: 0.0002, ; D Loss Fake: 0.0100, \n",
      "Epoch [209/300], Step [220/234], D Loss: 0.0001, G Loss: 12.5044; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [210/300], Step [20/234], D Loss: 0.0228, G Loss: 7.3804; D Loss Real: 0.0212, ; D Loss Fake: 0.0015, \n",
      "Epoch [210/300], Step [40/234], D Loss: 0.0370, G Loss: 4.9260; D Loss Real: 0.0005, ; D Loss Fake: 0.0365, \n",
      "Epoch [210/300], Step [60/234], D Loss: 0.0003, G Loss: 9.7163; D Loss Real: 0.0002, ; D Loss Fake: 0.0001, \n",
      "Epoch [210/300], Step [80/234], D Loss: 0.1227, G Loss: 7.6218; D Loss Real: 0.0013, ; D Loss Fake: 0.1214, \n",
      "Epoch [210/300], Step [100/234], D Loss: 0.0270, G Loss: 13.7369; D Loss Real: 0.0270, ; D Loss Fake: 0.0000, \n",
      "Epoch [210/300], Step [120/234], D Loss: 0.0762, G Loss: 12.9532; D Loss Real: 0.0761, ; D Loss Fake: 0.0000, \n",
      "Epoch [210/300], Step [140/234], D Loss: 0.0196, G Loss: 6.6346; D Loss Real: 0.0031, ; D Loss Fake: 0.0165, \n",
      "Epoch [210/300], Step [160/234], D Loss: 0.0221, G Loss: 5.2289; D Loss Real: 0.0020, ; D Loss Fake: 0.0201, \n",
      "Epoch [210/300], Step [180/234], D Loss: 0.0106, G Loss: 7.1950; D Loss Real: 0.0005, ; D Loss Fake: 0.0101, \n",
      "Epoch [210/300], Step [200/234], D Loss: 0.0495, G Loss: 9.5788; D Loss Real: 0.0488, ; D Loss Fake: 0.0007, \n",
      "Epoch [210/300], Step [220/234], D Loss: 0.0571, G Loss: 6.4629; D Loss Real: 0.0025, ; D Loss Fake: 0.0546, \n",
      "Epoch [211/300], Step [20/234], D Loss: 0.0051, G Loss: 6.1939; D Loss Real: 0.0003, ; D Loss Fake: 0.0048, \n",
      "Epoch [211/300], Step [40/234], D Loss: 0.0077, G Loss: 9.3423; D Loss Real: 0.0071, ; D Loss Fake: 0.0007, \n",
      "Epoch [211/300], Step [60/234], D Loss: 0.0216, G Loss: 0.0020; D Loss Real: 0.0205, ; D Loss Fake: 0.0011, \n",
      "Epoch [211/300], Step [80/234], D Loss: 0.0102, G Loss: 6.0432; D Loss Real: 0.0034, ; D Loss Fake: 0.0068, \n",
      "Epoch [211/300], Step [100/234], D Loss: 0.1297, G Loss: 7.4083; D Loss Real: 0.0738, ; D Loss Fake: 0.0559, \n",
      "Epoch [211/300], Step [120/234], D Loss: 0.0193, G Loss: 14.8254; D Loss Real: 0.0193, ; D Loss Fake: 0.0000, \n",
      "Epoch [211/300], Step [140/234], D Loss: 0.0198, G Loss: -0.0025; D Loss Real: 0.0197, ; D Loss Fake: 0.0001, \n",
      "Epoch [211/300], Step [160/234], D Loss: 0.3559, G Loss: 13.1364; D Loss Real: 0.0033, ; D Loss Fake: 0.3526, \n",
      "Epoch [211/300], Step [180/234], D Loss: 0.0076, G Loss: 7.9922; D Loss Real: 0.0063, ; D Loss Fake: 0.0013, \n",
      "Epoch [211/300], Step [200/234], D Loss: 0.0393, G Loss: 11.6807; D Loss Real: 0.0392, ; D Loss Fake: 0.0001, \n",
      "Epoch [211/300], Step [220/234], D Loss: 0.0169, G Loss: 5.8421; D Loss Real: 0.0119, ; D Loss Fake: 0.0051, \n",
      "Epoch [212/300], Step [20/234], D Loss: 0.0017, G Loss: 9.4769; D Loss Real: 0.0015, ; D Loss Fake: 0.0002, \n",
      "Epoch [212/300], Step [40/234], D Loss: 0.0046, G Loss: 5.9640; D Loss Real: 0.0015, ; D Loss Fake: 0.0031, \n",
      "Epoch [212/300], Step [60/234], D Loss: 0.0195, G Loss: 4.8929; D Loss Real: 0.0049, ; D Loss Fake: 0.0145, \n",
      "Epoch [212/300], Step [80/234], D Loss: 0.0013, G Loss: 8.3842; D Loss Real: 0.0001, ; D Loss Fake: 0.0012, \n",
      "Epoch [212/300], Step [100/234], D Loss: 0.0017, G Loss: 7.2211; D Loss Real: 0.0001, ; D Loss Fake: 0.0016, \n",
      "Epoch [212/300], Step [120/234], D Loss: 0.0581, G Loss: 9.4188; D Loss Real: 0.0578, ; D Loss Fake: 0.0002, \n",
      "Epoch [212/300], Step [140/234], D Loss: 0.0098, G Loss: 8.1655; D Loss Real: 0.0095, ; D Loss Fake: 0.0003, \n",
      "Epoch [212/300], Step [160/234], D Loss: 0.0059, G Loss: 7.0952; D Loss Real: 0.0040, ; D Loss Fake: 0.0018, \n",
      "Epoch [212/300], Step [180/234], D Loss: 0.0028, G Loss: 7.6434; D Loss Real: 0.0014, ; D Loss Fake: 0.0014, \n",
      "Epoch [212/300], Step [200/234], D Loss: 0.0096, G Loss: 10.1633; D Loss Real: 0.0096, ; D Loss Fake: 0.0000, \n",
      "Epoch [212/300], Step [220/234], D Loss: 0.0002, G Loss: 9.1620; D Loss Real: 0.0001, ; D Loss Fake: 0.0001, \n",
      "Epoch [213/300], Step [20/234], D Loss: 0.0887, G Loss: 7.8228; D Loss Real: 0.0801, ; D Loss Fake: 0.0086, \n",
      "Epoch [213/300], Step [40/234], D Loss: 0.0003, G Loss: 10.0295; D Loss Real: 0.0000, ; D Loss Fake: 0.0003, \n",
      "Epoch [213/300], Step [60/234], D Loss: 0.0034, G Loss: 9.6900; D Loss Real: 0.0016, ; D Loss Fake: 0.0018, \n",
      "Epoch [213/300], Step [80/234], D Loss: 0.0018, G Loss: 7.6696; D Loss Real: 0.0012, ; D Loss Fake: 0.0007, \n",
      "Epoch [213/300], Step [100/234], D Loss: 0.0141, G Loss: 0.0035; D Loss Real: 0.0010, ; D Loss Fake: 0.0132, \n",
      "Epoch [213/300], Step [120/234], D Loss: 0.0013, G Loss: 9.0705; D Loss Real: 0.0009, ; D Loss Fake: 0.0005, \n",
      "Epoch [213/300], Step [140/234], D Loss: 0.0378, G Loss: 8.4853; D Loss Real: 0.0376, ; D Loss Fake: 0.0002, \n",
      "Epoch [213/300], Step [160/234], D Loss: 0.0131, G Loss: 6.1711; D Loss Real: 0.0105, ; D Loss Fake: 0.0026, \n",
      "Epoch [213/300], Step [180/234], D Loss: 0.0004, G Loss: 9.3395; D Loss Real: 0.0003, ; D Loss Fake: 0.0001, \n",
      "Epoch [213/300], Step [200/234], D Loss: 0.0080, G Loss: 8.0644; D Loss Real: 0.0076, ; D Loss Fake: 0.0003, \n",
      "Epoch [213/300], Step [220/234], D Loss: 0.0003, G Loss: 15.0252; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [214/300], Step [20/234], D Loss: 0.0159, G Loss: 7.4152; D Loss Real: 0.0142, ; D Loss Fake: 0.0017, \n",
      "Epoch [214/300], Step [40/234], D Loss: 0.0255, G Loss: 10.1138; D Loss Real: 0.0243, ; D Loss Fake: 0.0012, \n",
      "Epoch [214/300], Step [60/234], D Loss: 0.0003, G Loss: 11.4623; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [214/300], Step [80/234], D Loss: 0.0012, G Loss: -0.0154; D Loss Real: 0.0012, ; D Loss Fake: 0.0000, \n",
      "Epoch [214/300], Step [100/234], D Loss: 0.0067, G Loss: 6.4098; D Loss Real: 0.0038, ; D Loss Fake: 0.0029, \n",
      "Epoch [214/300], Step [120/234], D Loss: 0.0385, G Loss: 6.6622; D Loss Real: 0.0369, ; D Loss Fake: 0.0016, \n",
      "Epoch [214/300], Step [140/234], D Loss: 0.0281, G Loss: 7.7040; D Loss Real: 0.0216, ; D Loss Fake: 0.0064, \n",
      "Epoch [214/300], Step [160/234], D Loss: 0.0053, G Loss: 6.4294; D Loss Real: 0.0020, ; D Loss Fake: 0.0033, \n",
      "Epoch [214/300], Step [180/234], D Loss: 0.0627, G Loss: 0.0013; D Loss Real: 0.0613, ; D Loss Fake: 0.0014, \n",
      "Epoch [214/300], Step [200/234], D Loss: 0.1406, G Loss: 13.0830; D Loss Real: 0.1406, ; D Loss Fake: 0.0000, \n",
      "Epoch [214/300], Step [220/234], D Loss: 0.0028, G Loss: 0.0126; D Loss Real: 0.0028, ; D Loss Fake: 0.0000, \n",
      "Epoch [215/300], Step [20/234], D Loss: 0.0635, G Loss: 5.4291; D Loss Real: 0.0027, ; D Loss Fake: 0.0608, \n",
      "Epoch [215/300], Step [40/234], D Loss: 0.0101, G Loss: 15.6266; D Loss Real: 0.0101, ; D Loss Fake: 0.0000, \n",
      "Epoch [215/300], Step [60/234], D Loss: 0.0018, G Loss: 7.6252; D Loss Real: 0.0010, ; D Loss Fake: 0.0008, \n",
      "Epoch [215/300], Step [80/234], D Loss: 0.0049, G Loss: 0.0035; D Loss Real: 0.0037, ; D Loss Fake: 0.0012, \n",
      "Epoch [215/300], Step [100/234], D Loss: 0.0026, G Loss: 6.9968; D Loss Real: 0.0008, ; D Loss Fake: 0.0018, \n",
      "Epoch [215/300], Step [120/234], D Loss: 0.0034, G Loss: 7.4346; D Loss Real: 0.0018, ; D Loss Fake: 0.0016, \n",
      "Epoch [215/300], Step [140/234], D Loss: 0.0088, G Loss: 7.9676; D Loss Real: 0.0081, ; D Loss Fake: 0.0007, \n",
      "Epoch [215/300], Step [160/234], D Loss: 0.0014, G Loss: 9.4125; D Loss Real: 0.0013, ; D Loss Fake: 0.0001, \n",
      "Epoch [215/300], Step [180/234], D Loss: 0.0067, G Loss: 8.7683; D Loss Real: 0.0064, ; D Loss Fake: 0.0003, \n",
      "Epoch [215/300], Step [200/234], D Loss: 0.0074, G Loss: 8.2065; D Loss Real: 0.0056, ; D Loss Fake: 0.0018, \n",
      "Epoch [215/300], Step [220/234], D Loss: 0.0007, G Loss: 19.7482; D Loss Real: 0.0007, ; D Loss Fake: -0.0000, \n",
      "Epoch [216/300], Step [20/234], D Loss: 0.0128, G Loss: 5.7322; D Loss Real: 0.0025, ; D Loss Fake: 0.0103, \n",
      "Epoch [216/300], Step [40/234], D Loss: 0.0185, G Loss: 7.8650; D Loss Real: 0.0025, ; D Loss Fake: 0.0160, \n",
      "Epoch [216/300], Step [60/234], D Loss: 0.0063, G Loss: 12.1372; D Loss Real: 0.0058, ; D Loss Fake: 0.0005, \n",
      "Epoch [216/300], Step [80/234], D Loss: 0.0184, G Loss: 5.5323; D Loss Real: 0.0020, ; D Loss Fake: 0.0164, \n",
      "Epoch [216/300], Step [100/234], D Loss: 0.0021, G Loss: -0.0002; D Loss Real: 0.0009, ; D Loss Fake: 0.0012, \n",
      "Epoch [216/300], Step [120/234], D Loss: 0.0092, G Loss: 8.5117; D Loss Real: 0.0091, ; D Loss Fake: 0.0001, \n",
      "Epoch [216/300], Step [140/234], D Loss: 0.1228, G Loss: 7.5494; D Loss Real: 0.1220, ; D Loss Fake: 0.0008, \n",
      "Epoch [216/300], Step [160/234], D Loss: 0.0070, G Loss: 6.2357; D Loss Real: 0.0037, ; D Loss Fake: 0.0033, \n",
      "Epoch [216/300], Step [180/234], D Loss: 0.0042, G Loss: 8.3927; D Loss Real: 0.0023, ; D Loss Fake: 0.0019, \n",
      "Epoch [216/300], Step [200/234], D Loss: 0.0020, G Loss: 10.3712; D Loss Real: 0.0020, ; D Loss Fake: 0.0000, \n",
      "Epoch [216/300], Step [220/234], D Loss: 0.0022, G Loss: 11.4926; D Loss Real: 0.0022, ; D Loss Fake: 0.0000, \n",
      "Epoch [217/300], Step [20/234], D Loss: 0.0189, G Loss: 6.6809; D Loss Real: 0.0022, ; D Loss Fake: 0.0167, \n",
      "Epoch [217/300], Step [40/234], D Loss: 0.0071, G Loss: 6.2425; D Loss Real: 0.0010, ; D Loss Fake: 0.0061, \n",
      "Epoch [217/300], Step [60/234], D Loss: 0.0009, G Loss: 10.5818; D Loss Real: 0.0009, ; D Loss Fake: 0.0000, \n",
      "Epoch [217/300], Step [80/234], D Loss: 0.1333, G Loss: 16.1880; D Loss Real: 0.1333, ; D Loss Fake: 0.0000, \n",
      "Epoch [217/300], Step [100/234], D Loss: 0.0559, G Loss: 5.9668; D Loss Real: 0.0007, ; D Loss Fake: 0.0552, \n",
      "Epoch [217/300], Step [120/234], D Loss: 0.0260, G Loss: 5.3691; D Loss Real: 0.0007, ; D Loss Fake: 0.0253, \n",
      "Epoch [217/300], Step [140/234], D Loss: 0.0336, G Loss: 0.0018; D Loss Real: 0.0002, ; D Loss Fake: 0.0334, \n",
      "Epoch [217/300], Step [160/234], D Loss: 0.1059, G Loss: 7.0764; D Loss Real: 0.0013, ; D Loss Fake: 0.1046, \n",
      "Epoch [217/300], Step [180/234], D Loss: 0.0356, G Loss: 5.7197; D Loss Real: 0.0321, ; D Loss Fake: 0.0035, \n",
      "Epoch [217/300], Step [200/234], D Loss: 0.0057, G Loss: 6.1262; D Loss Real: 0.0021, ; D Loss Fake: 0.0036, \n",
      "Epoch [217/300], Step [220/234], D Loss: 0.0225, G Loss: 7.2115; D Loss Real: 0.0219, ; D Loss Fake: 0.0006, \n",
      "Epoch [218/300], Step [20/234], D Loss: 0.5284, G Loss: 13.4457; D Loss Real: 0.0003, ; D Loss Fake: 0.5282, \n",
      "Epoch [218/300], Step [40/234], D Loss: 0.0063, G Loss: 14.8775; D Loss Real: 0.0063, ; D Loss Fake: 0.0000, \n",
      "Epoch [218/300], Step [60/234], D Loss: 0.0013, G Loss: 7.4246; D Loss Real: 0.0004, ; D Loss Fake: 0.0009, \n",
      "Epoch [218/300], Step [80/234], D Loss: 0.0023, G Loss: 7.2879; D Loss Real: 0.0002, ; D Loss Fake: 0.0021, \n",
      "Epoch [218/300], Step [100/234], D Loss: 0.1934, G Loss: 9.9994; D Loss Real: 0.1932, ; D Loss Fake: 0.0002, \n",
      "Epoch [218/300], Step [120/234], D Loss: 0.0147, G Loss: 6.4039; D Loss Real: 0.0103, ; D Loss Fake: 0.0044, \n",
      "Epoch [218/300], Step [140/234], D Loss: 0.0069, G Loss: 7.7158; D Loss Real: 0.0064, ; D Loss Fake: 0.0005, \n",
      "Epoch [218/300], Step [160/234], D Loss: 0.0041, G Loss: -0.0018; D Loss Real: 0.0038, ; D Loss Fake: 0.0003, \n",
      "Epoch [218/300], Step [180/234], D Loss: 0.0059, G Loss: 7.1497; D Loss Real: 0.0031, ; D Loss Fake: 0.0028, \n",
      "Epoch [218/300], Step [200/234], D Loss: 0.2914, G Loss: 11.0684; D Loss Real: 0.0087, ; D Loss Fake: 0.2827, \n",
      "Epoch [218/300], Step [220/234], D Loss: 0.0007, G Loss: 9.7790; D Loss Real: 0.0006, ; D Loss Fake: 0.0001, \n",
      "Epoch [219/300], Step [20/234], D Loss: 0.2553, G Loss: 10.5112; D Loss Real: 0.0002, ; D Loss Fake: 0.2552, \n",
      "Epoch [219/300], Step [40/234], D Loss: 0.0631, G Loss: 8.1824; D Loss Real: 0.0630, ; D Loss Fake: 0.0001, \n",
      "Epoch [219/300], Step [60/234], D Loss: 0.0070, G Loss: 5.5846; D Loss Real: 0.0033, ; D Loss Fake: 0.0037, \n",
      "Epoch [219/300], Step [80/234], D Loss: 0.0020, G Loss: 10.9701; D Loss Real: 0.0020, ; D Loss Fake: 0.0000, \n",
      "Epoch [219/300], Step [100/234], D Loss: 0.0048, G Loss: 7.0414; D Loss Real: 0.0020, ; D Loss Fake: 0.0028, \n",
      "Epoch [219/300], Step [120/234], D Loss: 0.3153, G Loss: 7.8632; D Loss Real: 0.3153, ; D Loss Fake: 0.0001, \n",
      "Epoch [219/300], Step [140/234], D Loss: 0.0139, G Loss: 14.2521; D Loss Real: 0.0139, ; D Loss Fake: 0.0000, \n",
      "Epoch [219/300], Step [160/234], D Loss: 0.0209, G Loss: 9.5225; D Loss Real: 0.0208, ; D Loss Fake: 0.0001, \n",
      "Epoch [219/300], Step [180/234], D Loss: 0.0943, G Loss: -0.0009; D Loss Real: 0.0940, ; D Loss Fake: 0.0003, \n",
      "Epoch [219/300], Step [200/234], D Loss: 0.0056, G Loss: 11.5782; D Loss Real: 0.0056, ; D Loss Fake: 0.0000, \n",
      "Epoch [219/300], Step [220/234], D Loss: 0.0141, G Loss: 7.3911; D Loss Real: 0.0127, ; D Loss Fake: 0.0014, \n",
      "Epoch [220/300], Step [20/234], D Loss: 0.0042, G Loss: -0.0069; D Loss Real: 0.0041, ; D Loss Fake: 0.0001, \n",
      "Epoch [220/300], Step [40/234], D Loss: 0.0046, G Loss: 7.9893; D Loss Real: 0.0017, ; D Loss Fake: 0.0029, \n",
      "Epoch [220/300], Step [60/234], D Loss: 0.0512, G Loss: 7.4089; D Loss Real: 0.0005, ; D Loss Fake: 0.0507, \n",
      "Epoch [220/300], Step [80/234], D Loss: 0.0004, G Loss: 14.0728; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [220/300], Step [100/234], D Loss: 0.0197, G Loss: 4.9557; D Loss Real: 0.0014, ; D Loss Fake: 0.0183, \n",
      "Epoch [220/300], Step [120/234], D Loss: 0.0012, G Loss: 10.1982; D Loss Real: 0.0011, ; D Loss Fake: 0.0001, \n",
      "Epoch [220/300], Step [140/234], D Loss: 0.0148, G Loss: 5.1041; D Loss Real: 0.0004, ; D Loss Fake: 0.0145, \n",
      "Epoch [220/300], Step [160/234], D Loss: 0.0610, G Loss: 5.2526; D Loss Real: 0.0072, ; D Loss Fake: 0.0538, \n",
      "Epoch [220/300], Step [180/234], D Loss: 0.0005, G Loss: -0.0118; D Loss Real: 0.0004, ; D Loss Fake: 0.0001, \n",
      "Epoch [220/300], Step [200/234], D Loss: 0.0004, G Loss: 8.0992; D Loss Real: 0.0002, ; D Loss Fake: 0.0002, \n",
      "Epoch [220/300], Step [220/234], D Loss: 0.0099, G Loss: 6.0674; D Loss Real: 0.0078, ; D Loss Fake: 0.0021, \n",
      "Epoch [221/300], Step [20/234], D Loss: 0.0314, G Loss: 10.6038; D Loss Real: 0.0314, ; D Loss Fake: 0.0000, \n",
      "Epoch [221/300], Step [40/234], D Loss: 0.0400, G Loss: 8.6408; D Loss Real: 0.0059, ; D Loss Fake: 0.0341, \n",
      "Epoch [221/300], Step [60/234], D Loss: 0.0199, G Loss: 8.0268; D Loss Real: 0.0010, ; D Loss Fake: 0.0189, \n",
      "Epoch [221/300], Step [80/234], D Loss: 0.0306, G Loss: 5.5378; D Loss Real: 0.0243, ; D Loss Fake: 0.0063, \n",
      "Epoch [221/300], Step [100/234], D Loss: 0.0905, G Loss: 7.0118; D Loss Real: 0.0037, ; D Loss Fake: 0.0868, \n",
      "Epoch [221/300], Step [120/234], D Loss: 0.0232, G Loss: 5.6341; D Loss Real: 0.0014, ; D Loss Fake: 0.0218, \n",
      "Epoch [221/300], Step [140/234], D Loss: 0.1747, G Loss: 8.4820; D Loss Real: 0.0068, ; D Loss Fake: 0.1678, \n",
      "Epoch [221/300], Step [160/234], D Loss: 0.0850, G Loss: 13.7957; D Loss Real: 0.0850, ; D Loss Fake: 0.0000, \n",
      "Epoch [221/300], Step [180/234], D Loss: 0.0292, G Loss: 0.0066; D Loss Real: 0.0006, ; D Loss Fake: 0.0286, \n",
      "Epoch [221/300], Step [200/234], D Loss: 0.0067, G Loss: 6.0221; D Loss Real: 0.0017, ; D Loss Fake: 0.0051, \n",
      "Epoch [221/300], Step [220/234], D Loss: 0.0001, G Loss: 12.3706; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [222/300], Step [20/234], D Loss: 0.0027, G Loss: 17.8578; D Loss Real: 0.0027, ; D Loss Fake: 0.0000, \n",
      "Epoch [222/300], Step [40/234], D Loss: 0.0074, G Loss: 6.5272; D Loss Real: 0.0003, ; D Loss Fake: 0.0071, \n",
      "Epoch [222/300], Step [60/234], D Loss: 0.0159, G Loss: 6.0094; D Loss Real: 0.0103, ; D Loss Fake: 0.0055, \n",
      "Epoch [222/300], Step [80/234], D Loss: 0.4294, G Loss: 10.3886; D Loss Real: 0.0007, ; D Loss Fake: 0.4287, \n",
      "Epoch [222/300], Step [100/234], D Loss: 0.0054, G Loss: 0.0031; D Loss Real: 0.0037, ; D Loss Fake: 0.0017, \n",
      "Epoch [222/300], Step [120/234], D Loss: 0.0155, G Loss: 5.3677; D Loss Real: 0.0010, ; D Loss Fake: 0.0144, \n",
      "Epoch [222/300], Step [140/234], D Loss: 0.0073, G Loss: 6.2116; D Loss Real: 0.0003, ; D Loss Fake: 0.0069, \n",
      "Epoch [222/300], Step [160/234], D Loss: 0.0068, G Loss: 9.1939; D Loss Real: 0.0063, ; D Loss Fake: 0.0005, \n",
      "Epoch [222/300], Step [180/234], D Loss: 0.1412, G Loss: 5.2471; D Loss Real: 0.1053, ; D Loss Fake: 0.0359, \n",
      "Epoch [222/300], Step [200/234], D Loss: 0.0540, G Loss: 11.9375; D Loss Real: 0.0539, ; D Loss Fake: 0.0001, \n",
      "Epoch [222/300], Step [220/234], D Loss: 0.0120, G Loss: 7.6586; D Loss Real: 0.0116, ; D Loss Fake: 0.0004, \n",
      "Epoch [223/300], Step [20/234], D Loss: 0.0018, G Loss: 10.0603; D Loss Real: 0.0017, ; D Loss Fake: 0.0001, \n",
      "Epoch [223/300], Step [40/234], D Loss: 0.0416, G Loss: 0.0005; D Loss Real: 0.0249, ; D Loss Fake: 0.0167, \n",
      "Epoch [223/300], Step [60/234], D Loss: 0.0096, G Loss: 0.0113; D Loss Real: 0.0093, ; D Loss Fake: 0.0004, \n",
      "Epoch [223/300], Step [80/234], D Loss: 0.0148, G Loss: 8.5211; D Loss Real: 0.0108, ; D Loss Fake: 0.0041, \n",
      "Epoch [223/300], Step [100/234], D Loss: 0.0195, G Loss: 6.9054; D Loss Real: 0.0171, ; D Loss Fake: 0.0024, \n",
      "Epoch [223/300], Step [120/234], D Loss: 0.0213, G Loss: 10.1081; D Loss Real: 0.0213, ; D Loss Fake: 0.0000, \n",
      "Epoch [223/300], Step [140/234], D Loss: 0.0685, G Loss: 9.8924; D Loss Real: 0.0684, ; D Loss Fake: 0.0001, \n",
      "Epoch [223/300], Step [160/234], D Loss: 0.0048, G Loss: 11.0947; D Loss Real: 0.0048, ; D Loss Fake: 0.0000, \n",
      "Epoch [223/300], Step [180/234], D Loss: 0.1797, G Loss: 7.3753; D Loss Real: 0.0004, ; D Loss Fake: 0.1794, \n",
      "Epoch [223/300], Step [200/234], D Loss: 0.0025, G Loss: 8.2578; D Loss Real: 0.0023, ; D Loss Fake: 0.0002, \n",
      "Epoch [223/300], Step [220/234], D Loss: 0.0599, G Loss: 9.6659; D Loss Real: 0.0599, ; D Loss Fake: 0.0000, \n",
      "Epoch [224/300], Step [20/234], D Loss: 0.0002, G Loss: 12.9736; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [224/300], Step [40/234], D Loss: 0.0043, G Loss: 12.7810; D Loss Real: 0.0043, ; D Loss Fake: 0.0000, \n",
      "Epoch [224/300], Step [60/234], D Loss: 0.1076, G Loss: 5.4972; D Loss Real: 0.0003, ; D Loss Fake: 0.1073, \n",
      "Epoch [224/300], Step [80/234], D Loss: 0.0141, G Loss: 18.3032; D Loss Real: 0.0141, ; D Loss Fake: 0.0000, \n",
      "Epoch [224/300], Step [100/234], D Loss: 0.0016, G Loss: 8.8022; D Loss Real: 0.0013, ; D Loss Fake: 0.0003, \n",
      "Epoch [224/300], Step [120/234], D Loss: 0.0158, G Loss: 6.1456; D Loss Real: 0.0004, ; D Loss Fake: 0.0154, \n",
      "Epoch [224/300], Step [140/234], D Loss: 0.0079, G Loss: 8.6390; D Loss Real: 0.0074, ; D Loss Fake: 0.0004, \n",
      "Epoch [224/300], Step [160/234], D Loss: 0.3523, G Loss: 7.5986; D Loss Real: 0.3520, ; D Loss Fake: 0.0003, \n",
      "Epoch [224/300], Step [180/234], D Loss: 0.0473, G Loss: -0.0046; D Loss Real: 0.0069, ; D Loss Fake: 0.0404, \n",
      "Epoch [224/300], Step [200/234], D Loss: 0.0026, G Loss: 6.7767; D Loss Real: 0.0004, ; D Loss Fake: 0.0022, \n",
      "Epoch [224/300], Step [220/234], D Loss: 0.0121, G Loss: 10.9983; D Loss Real: 0.0121, ; D Loss Fake: 0.0000, \n",
      "Epoch [225/300], Step [20/234], D Loss: 0.0079, G Loss: 17.2881; D Loss Real: 0.0079, ; D Loss Fake: 0.0000, \n",
      "Epoch [225/300], Step [40/234], D Loss: 0.0131, G Loss: 5.5201; D Loss Real: 0.0004, ; D Loss Fake: 0.0128, \n",
      "Epoch [225/300], Step [60/234], D Loss: 0.0020, G Loss: 8.5296; D Loss Real: 0.0018, ; D Loss Fake: 0.0003, \n",
      "Epoch [225/300], Step [80/234], D Loss: 0.1160, G Loss: 6.6591; D Loss Real: 0.0018, ; D Loss Fake: 0.1141, \n",
      "Epoch [225/300], Step [100/234], D Loss: 0.0057, G Loss: 10.0385; D Loss Real: 0.0056, ; D Loss Fake: 0.0001, \n",
      "Epoch [225/300], Step [120/234], D Loss: 0.0105, G Loss: 5.7004; D Loss Real: 0.0004, ; D Loss Fake: 0.0101, \n",
      "Epoch [225/300], Step [140/234], D Loss: 0.0009, G Loss: 10.5647; D Loss Real: 0.0009, ; D Loss Fake: 0.0000, \n",
      "Epoch [225/300], Step [160/234], D Loss: 0.0062, G Loss: 6.2364; D Loss Real: 0.0018, ; D Loss Fake: 0.0044, \n",
      "Epoch [225/300], Step [180/234], D Loss: 0.0291, G Loss: 10.9047; D Loss Real: 0.0291, ; D Loss Fake: 0.0001, \n",
      "Epoch [225/300], Step [200/234], D Loss: 0.0088, G Loss: 5.9431; D Loss Real: 0.0009, ; D Loss Fake: 0.0079, \n",
      "Epoch [225/300], Step [220/234], D Loss: 0.0985, G Loss: 4.8933; D Loss Real: 0.0916, ; D Loss Fake: 0.0069, \n",
      "Epoch [226/300], Step [20/234], D Loss: 0.0067, G Loss: 15.1453; D Loss Real: 0.0067, ; D Loss Fake: 0.0000, \n",
      "Epoch [226/300], Step [40/234], D Loss: 0.0657, G Loss: 14.2951; D Loss Real: 0.0657, ; D Loss Fake: 0.0000, \n",
      "Epoch [226/300], Step [60/234], D Loss: 0.0064, G Loss: 14.4896; D Loss Real: 0.0064, ; D Loss Fake: 0.0000, \n",
      "Epoch [226/300], Step [80/234], D Loss: 0.0014, G Loss: 8.1364; D Loss Real: 0.0010, ; D Loss Fake: 0.0004, \n",
      "Epoch [226/300], Step [100/234], D Loss: 0.0197, G Loss: 6.4505; D Loss Real: 0.0013, ; D Loss Fake: 0.0184, \n",
      "Epoch [226/300], Step [120/234], D Loss: 0.0058, G Loss: 8.7508; D Loss Real: 0.0054, ; D Loss Fake: 0.0004, \n",
      "Epoch [226/300], Step [140/234], D Loss: 0.0035, G Loss: 0.0104; D Loss Real: 0.0035, ; D Loss Fake: 0.0001, \n",
      "Epoch [226/300], Step [160/234], D Loss: 0.0224, G Loss: 5.4757; D Loss Real: 0.0058, ; D Loss Fake: 0.0166, \n",
      "Epoch [226/300], Step [180/234], D Loss: 0.0092, G Loss: -0.0161; D Loss Real: 0.0000, ; D Loss Fake: 0.0092, \n",
      "Epoch [226/300], Step [200/234], D Loss: 0.0123, G Loss: 5.9020; D Loss Real: 0.0006, ; D Loss Fake: 0.0117, \n",
      "Epoch [226/300], Step [220/234], D Loss: 0.0597, G Loss: 5.9095; D Loss Real: 0.0085, ; D Loss Fake: 0.0512, \n",
      "Epoch [227/300], Step [20/234], D Loss: 0.0011, G Loss: -0.0102; D Loss Real: 0.0011, ; D Loss Fake: 0.0000, \n",
      "Epoch [227/300], Step [40/234], D Loss: 0.0439, G Loss: 6.5397; D Loss Real: 0.0003, ; D Loss Fake: 0.0436, \n",
      "Epoch [227/300], Step [60/234], D Loss: 0.0056, G Loss: 7.8250; D Loss Real: 0.0045, ; D Loss Fake: 0.0011, \n",
      "Epoch [227/300], Step [80/234], D Loss: 0.0044, G Loss: 8.5153; D Loss Real: 0.0028, ; D Loss Fake: 0.0015, \n",
      "Epoch [227/300], Step [100/234], D Loss: 0.0017, G Loss: -0.0081; D Loss Real: 0.0005, ; D Loss Fake: 0.0012, \n",
      "Epoch [227/300], Step [120/234], D Loss: 0.0040, G Loss: 7.7503; D Loss Real: 0.0006, ; D Loss Fake: 0.0034, \n",
      "Epoch [227/300], Step [140/234], D Loss: 0.0081, G Loss: 6.1704; D Loss Real: 0.0020, ; D Loss Fake: 0.0061, \n",
      "Epoch [227/300], Step [160/234], D Loss: 0.0023, G Loss: 8.5019; D Loss Real: 0.0020, ; D Loss Fake: 0.0004, \n",
      "Epoch [227/300], Step [180/234], D Loss: 0.0019, G Loss: 10.7981; D Loss Real: 0.0019, ; D Loss Fake: 0.0000, \n",
      "Epoch [227/300], Step [200/234], D Loss: 0.0018, G Loss: 10.4969; D Loss Real: 0.0017, ; D Loss Fake: 0.0000, \n",
      "Epoch [227/300], Step [220/234], D Loss: 0.0476, G Loss: 7.0193; D Loss Real: 0.0471, ; D Loss Fake: 0.0005, \n",
      "Epoch [228/300], Step [20/234], D Loss: 0.0024, G Loss: 8.3207; D Loss Real: 0.0021, ; D Loss Fake: 0.0003, \n",
      "Epoch [228/300], Step [40/234], D Loss: 0.0486, G Loss: 5.8925; D Loss Real: 0.0010, ; D Loss Fake: 0.0476, \n",
      "Epoch [228/300], Step [60/234], D Loss: 0.0257, G Loss: 9.2854; D Loss Real: 0.0255, ; D Loss Fake: 0.0002, \n",
      "Epoch [228/300], Step [80/234], D Loss: 0.0139, G Loss: 12.2103; D Loss Real: 0.0139, ; D Loss Fake: 0.0001, \n",
      "Epoch [228/300], Step [100/234], D Loss: 0.0921, G Loss: 8.4872; D Loss Real: 0.0029, ; D Loss Fake: 0.0891, \n",
      "Epoch [228/300], Step [120/234], D Loss: 0.0206, G Loss: 5.5901; D Loss Real: 0.0161, ; D Loss Fake: 0.0044, \n",
      "Epoch [228/300], Step [140/234], D Loss: 0.0143, G Loss: 9.2590; D Loss Real: 0.0142, ; D Loss Fake: 0.0001, \n",
      "Epoch [228/300], Step [160/234], D Loss: 0.0137, G Loss: 7.3551; D Loss Real: 0.0132, ; D Loss Fake: 0.0005, \n",
      "Epoch [228/300], Step [180/234], D Loss: 0.0484, G Loss: 8.2749; D Loss Real: 0.0483, ; D Loss Fake: 0.0002, \n",
      "Epoch [228/300], Step [200/234], D Loss: 0.0003, G Loss: 12.2922; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [228/300], Step [220/234], D Loss: 0.0059, G Loss: 6.4907; D Loss Real: 0.0041, ; D Loss Fake: 0.0018, \n",
      "Epoch [229/300], Step [20/234], D Loss: 0.0057, G Loss: 9.3391; D Loss Real: 0.0055, ; D Loss Fake: 0.0002, \n",
      "Epoch [229/300], Step [40/234], D Loss: 0.2575, G Loss: 18.5871; D Loss Real: 0.2575, ; D Loss Fake: 0.0000, \n",
      "Epoch [229/300], Step [60/234], D Loss: 0.0086, G Loss: 6.6650; D Loss Real: 0.0042, ; D Loss Fake: 0.0044, \n",
      "Epoch [229/300], Step [80/234], D Loss: 0.0401, G Loss: 7.4768; D Loss Real: 0.0392, ; D Loss Fake: 0.0009, \n",
      "Epoch [229/300], Step [100/234], D Loss: 0.0021, G Loss: 8.5901; D Loss Real: 0.0018, ; D Loss Fake: 0.0003, \n",
      "Epoch [229/300], Step [120/234], D Loss: 0.0187, G Loss: 6.2450; D Loss Real: 0.0015, ; D Loss Fake: 0.0172, \n",
      "Epoch [229/300], Step [140/234], D Loss: 0.0851, G Loss: 13.9852; D Loss Real: 0.0851, ; D Loss Fake: 0.0000, \n",
      "Epoch [229/300], Step [160/234], D Loss: 0.0008, G Loss: 12.7652; D Loss Real: 0.0008, ; D Loss Fake: 0.0000, \n",
      "Epoch [229/300], Step [180/234], D Loss: 0.0039, G Loss: 8.5229; D Loss Real: 0.0038, ; D Loss Fake: 0.0001, \n",
      "Epoch [229/300], Step [200/234], D Loss: 0.0095, G Loss: 5.8036; D Loss Real: 0.0048, ; D Loss Fake: 0.0048, \n",
      "Epoch [229/300], Step [220/234], D Loss: 0.0034, G Loss: 10.4120; D Loss Real: 0.0033, ; D Loss Fake: 0.0001, \n",
      "Epoch [230/300], Step [20/234], D Loss: 0.0019, G Loss: 8.9932; D Loss Real: 0.0017, ; D Loss Fake: 0.0001, \n",
      "Epoch [230/300], Step [40/234], D Loss: 0.0047, G Loss: 10.1815; D Loss Real: 0.0044, ; D Loss Fake: 0.0003, \n",
      "Epoch [230/300], Step [60/234], D Loss: 0.0004, G Loss: 7.9086; D Loss Real: 0.0001, ; D Loss Fake: 0.0003, \n",
      "Epoch [230/300], Step [80/234], D Loss: 0.0179, G Loss: -0.0067; D Loss Real: 0.0037, ; D Loss Fake: 0.0143, \n",
      "Epoch [230/300], Step [100/234], D Loss: 0.0242, G Loss: 6.4376; D Loss Real: 0.0172, ; D Loss Fake: 0.0070, \n",
      "Epoch [230/300], Step [120/234], D Loss: 0.0016, G Loss: 8.3111; D Loss Real: 0.0012, ; D Loss Fake: 0.0004, \n",
      "Epoch [230/300], Step [140/234], D Loss: 0.0133, G Loss: 5.5737; D Loss Real: 0.0078, ; D Loss Fake: 0.0055, \n",
      "Epoch [230/300], Step [160/234], D Loss: 0.0008, G Loss: 13.8607; D Loss Real: 0.0008, ; D Loss Fake: 0.0000, \n",
      "Epoch [230/300], Step [180/234], D Loss: 0.0004, G Loss: 9.3669; D Loss Real: 0.0001, ; D Loss Fake: 0.0003, \n",
      "Epoch [230/300], Step [200/234], D Loss: 0.0175, G Loss: 15.4827; D Loss Real: 0.0175, ; D Loss Fake: 0.0000, \n",
      "Epoch [230/300], Step [220/234], D Loss: 0.0154, G Loss: 10.6896; D Loss Real: 0.0154, ; D Loss Fake: 0.0000, \n",
      "Epoch [231/300], Step [20/234], D Loss: 0.0033, G Loss: 12.1841; D Loss Real: 0.0032, ; D Loss Fake: 0.0001, \n",
      "Epoch [231/300], Step [40/234], D Loss: 0.0451, G Loss: 14.2985; D Loss Real: 0.0451, ; D Loss Fake: 0.0000, \n",
      "Epoch [231/300], Step [60/234], D Loss: 0.0013, G Loss: 11.1906; D Loss Real: 0.0009, ; D Loss Fake: 0.0004, \n",
      "Epoch [231/300], Step [80/234], D Loss: 0.0495, G Loss: 7.3358; D Loss Real: 0.0084, ; D Loss Fake: 0.0411, \n",
      "Epoch [231/300], Step [100/234], D Loss: 0.0042, G Loss: 12.4557; D Loss Real: 0.0042, ; D Loss Fake: 0.0000, \n",
      "Epoch [231/300], Step [120/234], D Loss: 0.0083, G Loss: 5.4610; D Loss Real: 0.0012, ; D Loss Fake: 0.0071, \n",
      "Epoch [231/300], Step [140/234], D Loss: 0.0020, G Loss: 10.0327; D Loss Real: 0.0020, ; D Loss Fake: 0.0001, \n",
      "Epoch [231/300], Step [160/234], D Loss: 0.0022, G Loss: 8.5024; D Loss Real: 0.0020, ; D Loss Fake: 0.0002, \n",
      "Epoch [231/300], Step [180/234], D Loss: 0.0092, G Loss: 7.1625; D Loss Real: 0.0069, ; D Loss Fake: 0.0023, \n",
      "Epoch [231/300], Step [200/234], D Loss: 0.0043, G Loss: 7.6795; D Loss Real: 0.0011, ; D Loss Fake: 0.0032, \n",
      "Epoch [231/300], Step [220/234], D Loss: 0.0032, G Loss: 7.0368; D Loss Real: 0.0005, ; D Loss Fake: 0.0027, \n",
      "Epoch [232/300], Step [20/234], D Loss: 0.0104, G Loss: 11.5590; D Loss Real: 0.0104, ; D Loss Fake: 0.0000, \n",
      "Epoch [232/300], Step [40/234], D Loss: 0.2671, G Loss: 12.2251; D Loss Real: 0.0001, ; D Loss Fake: 0.2670, \n",
      "Epoch [232/300], Step [60/234], D Loss: 0.0305, G Loss: 13.0387; D Loss Real: 0.0304, ; D Loss Fake: 0.0001, \n",
      "Epoch [232/300], Step [80/234], D Loss: 0.0190, G Loss: 9.8730; D Loss Real: 0.0189, ; D Loss Fake: 0.0001, \n",
      "Epoch [232/300], Step [100/234], D Loss: 0.0042, G Loss: 7.8717; D Loss Real: 0.0008, ; D Loss Fake: 0.0034, \n",
      "Epoch [232/300], Step [120/234], D Loss: 0.0028, G Loss: -0.0011; D Loss Real: 0.0017, ; D Loss Fake: 0.0011, \n",
      "Epoch [232/300], Step [140/234], D Loss: 0.0091, G Loss: 5.4268; D Loss Real: 0.0001, ; D Loss Fake: 0.0090, \n",
      "Epoch [232/300], Step [160/234], D Loss: 0.0065, G Loss: 8.3800; D Loss Real: 0.0058, ; D Loss Fake: 0.0007, \n",
      "Epoch [232/300], Step [180/234], D Loss: 0.0017, G Loss: 8.0184; D Loss Real: 0.0006, ; D Loss Fake: 0.0011, \n",
      "Epoch [232/300], Step [200/234], D Loss: 0.0972, G Loss: 6.2114; D Loss Real: 0.0009, ; D Loss Fake: 0.0963, \n",
      "Epoch [232/300], Step [220/234], D Loss: 0.0606, G Loss: 6.9916; D Loss Real: 0.0051, ; D Loss Fake: 0.0555, \n",
      "Epoch [233/300], Step [20/234], D Loss: 0.0021, G Loss: 9.1133; D Loss Real: 0.0016, ; D Loss Fake: 0.0006, \n",
      "Epoch [233/300], Step [40/234], D Loss: 0.0186, G Loss: 5.9131; D Loss Real: 0.0137, ; D Loss Fake: 0.0049, \n",
      "Epoch [233/300], Step [60/234], D Loss: 0.0207, G Loss: 17.1349; D Loss Real: 0.0207, ; D Loss Fake: 0.0000, \n",
      "Epoch [233/300], Step [80/234], D Loss: 0.0017, G Loss: 8.9366; D Loss Real: 0.0007, ; D Loss Fake: 0.0010, \n",
      "Epoch [233/300], Step [100/234], D Loss: 0.1126, G Loss: 0.0090; D Loss Real: 0.0165, ; D Loss Fake: 0.0962, \n",
      "Epoch [233/300], Step [120/234], D Loss: 0.0179, G Loss: 11.7492; D Loss Real: 0.0179, ; D Loss Fake: 0.0000, \n",
      "Epoch [233/300], Step [140/234], D Loss: 0.0234, G Loss: 8.5197; D Loss Real: 0.0231, ; D Loss Fake: 0.0003, \n",
      "Epoch [233/300], Step [160/234], D Loss: 0.0061, G Loss: 6.4993; D Loss Real: 0.0028, ; D Loss Fake: 0.0033, \n",
      "Epoch [233/300], Step [180/234], D Loss: 0.0393, G Loss: 6.3312; D Loss Real: 0.0367, ; D Loss Fake: 0.0025, \n",
      "Epoch [233/300], Step [200/234], D Loss: 0.0020, G Loss: 7.6294; D Loss Real: 0.0014, ; D Loss Fake: 0.0006, \n",
      "Epoch [233/300], Step [220/234], D Loss: 0.0033, G Loss: 7.1631; D Loss Real: 0.0020, ; D Loss Fake: 0.0013, \n",
      "Epoch [234/300], Step [20/234], D Loss: 0.0266, G Loss: 0.0090; D Loss Real: 0.0256, ; D Loss Fake: 0.0010, \n",
      "Epoch [234/300], Step [40/234], D Loss: 0.0090, G Loss: 5.5679; D Loss Real: 0.0020, ; D Loss Fake: 0.0070, \n",
      "Epoch [234/300], Step [60/234], D Loss: 0.0078, G Loss: 0.0058; D Loss Real: 0.0059, ; D Loss Fake: 0.0018, \n",
      "Epoch [234/300], Step [80/234], D Loss: 0.0073, G Loss: 5.4334; D Loss Real: 0.0029, ; D Loss Fake: 0.0044, \n",
      "Epoch [234/300], Step [100/234], D Loss: 0.0095, G Loss: 5.7889; D Loss Real: 0.0051, ; D Loss Fake: 0.0044, \n",
      "Epoch [234/300], Step [120/234], D Loss: 0.0006, G Loss: 12.7296; D Loss Real: 0.0004, ; D Loss Fake: 0.0003, \n",
      "Epoch [234/300], Step [140/234], D Loss: 0.0095, G Loss: 7.3896; D Loss Real: 0.0011, ; D Loss Fake: 0.0084, \n",
      "Epoch [234/300], Step [160/234], D Loss: 0.0319, G Loss: 4.9222; D Loss Real: 0.0052, ; D Loss Fake: 0.0267, \n",
      "Epoch [234/300], Step [180/234], D Loss: 0.0131, G Loss: 8.5766; D Loss Real: 0.0126, ; D Loss Fake: 0.0005, \n",
      "Epoch [234/300], Step [200/234], D Loss: 0.0070, G Loss: 7.7120; D Loss Real: 0.0061, ; D Loss Fake: 0.0009, \n",
      "Epoch [234/300], Step [220/234], D Loss: 0.0136, G Loss: 5.9005; D Loss Real: 0.0038, ; D Loss Fake: 0.0098, \n",
      "Epoch [235/300], Step [20/234], D Loss: 0.1543, G Loss: -0.0085; D Loss Real: 0.1158, ; D Loss Fake: 0.0385, \n",
      "Epoch [235/300], Step [40/234], D Loss: 0.0017, G Loss: 10.0604; D Loss Real: 0.0016, ; D Loss Fake: 0.0000, \n",
      "Epoch [235/300], Step [60/234], D Loss: 0.0026, G Loss: 9.6293; D Loss Real: 0.0025, ; D Loss Fake: 0.0001, \n",
      "Epoch [235/300], Step [80/234], D Loss: 0.0120, G Loss: 8.2379; D Loss Real: 0.0043, ; D Loss Fake: 0.0077, \n",
      "Epoch [235/300], Step [100/234], D Loss: 0.0051, G Loss: 7.4183; D Loss Real: 0.0005, ; D Loss Fake: 0.0046, \n",
      "Epoch [235/300], Step [120/234], D Loss: 0.0065, G Loss: 9.1229; D Loss Real: 0.0064, ; D Loss Fake: 0.0001, \n",
      "Epoch [235/300], Step [140/234], D Loss: 0.0178, G Loss: 6.2309; D Loss Real: 0.0110, ; D Loss Fake: 0.0068, \n",
      "Epoch [235/300], Step [160/234], D Loss: 0.0152, G Loss: 9.5002; D Loss Real: 0.0150, ; D Loss Fake: 0.0002, \n",
      "Epoch [235/300], Step [180/234], D Loss: 0.0425, G Loss: 8.2312; D Loss Real: 0.0424, ; D Loss Fake: 0.0001, \n",
      "Epoch [235/300], Step [200/234], D Loss: 0.0014, G Loss: 8.5688; D Loss Real: 0.0010, ; D Loss Fake: 0.0004, \n",
      "Epoch [235/300], Step [220/234], D Loss: 0.0061, G Loss: 11.2842; D Loss Real: 0.0061, ; D Loss Fake: 0.0000, \n",
      "Epoch [236/300], Step [20/234], D Loss: 0.0014, G Loss: 11.2610; D Loss Real: 0.0014, ; D Loss Fake: 0.0000, \n",
      "Epoch [236/300], Step [40/234], D Loss: 0.0013, G Loss: 9.5678; D Loss Real: 0.0012, ; D Loss Fake: 0.0001, \n",
      "Epoch [236/300], Step [60/234], D Loss: 0.0009, G Loss: 9.4038; D Loss Real: 0.0008, ; D Loss Fake: 0.0001, \n",
      "Epoch [236/300], Step [80/234], D Loss: 0.0001, G Loss: 9.8149; D Loss Real: 0.0001, ; D Loss Fake: 0.0001, \n",
      "Epoch [236/300], Step [100/234], D Loss: 0.0044, G Loss: 6.8298; D Loss Real: 0.0009, ; D Loss Fake: 0.0035, \n",
      "Epoch [236/300], Step [120/234], D Loss: 0.2474, G Loss: 15.7237; D Loss Real: 0.2474, ; D Loss Fake: 0.0000, \n",
      "Epoch [236/300], Step [140/234], D Loss: 0.0306, G Loss: 9.8759; D Loss Real: 0.0306, ; D Loss Fake: 0.0000, \n",
      "Epoch [236/300], Step [160/234], D Loss: 0.0148, G Loss: 5.8156; D Loss Real: 0.0107, ; D Loss Fake: 0.0042, \n",
      "Epoch [236/300], Step [180/234], D Loss: 0.0111, G Loss: 6.2736; D Loss Real: 0.0073, ; D Loss Fake: 0.0038, \n",
      "Epoch [236/300], Step [200/234], D Loss: 0.0008, G Loss: 0.0016; D Loss Real: 0.0007, ; D Loss Fake: 0.0001, \n",
      "Epoch [236/300], Step [220/234], D Loss: 0.0322, G Loss: 8.4085; D Loss Real: 0.0316, ; D Loss Fake: 0.0006, \n",
      "Epoch [237/300], Step [20/234], D Loss: 0.0244, G Loss: 6.0510; D Loss Real: 0.0061, ; D Loss Fake: 0.0183, \n",
      "Epoch [237/300], Step [40/234], D Loss: 0.0197, G Loss: 6.4678; D Loss Real: 0.0055, ; D Loss Fake: 0.0142, \n",
      "Epoch [237/300], Step [60/234], D Loss: 0.1006, G Loss: 14.7657; D Loss Real: 0.1005, ; D Loss Fake: 0.0000, \n",
      "Epoch [237/300], Step [80/234], D Loss: 0.0885, G Loss: 5.8966; D Loss Real: 0.0088, ; D Loss Fake: 0.0798, \n",
      "Epoch [237/300], Step [100/234], D Loss: 0.0227, G Loss: 5.2041; D Loss Real: 0.0022, ; D Loss Fake: 0.0205, \n",
      "Epoch [237/300], Step [120/234], D Loss: 0.0205, G Loss: 5.2094; D Loss Real: 0.0107, ; D Loss Fake: 0.0098, \n",
      "Epoch [237/300], Step [140/234], D Loss: 0.0050, G Loss: 6.8225; D Loss Real: 0.0026, ; D Loss Fake: 0.0024, \n",
      "Epoch [237/300], Step [160/234], D Loss: 0.0331, G Loss: 7.3715; D Loss Real: 0.0322, ; D Loss Fake: 0.0010, \n",
      "Epoch [237/300], Step [180/234], D Loss: 0.0561, G Loss: 7.7040; D Loss Real: 0.0556, ; D Loss Fake: 0.0005, \n",
      "Epoch [237/300], Step [200/234], D Loss: 0.0229, G Loss: 5.3912; D Loss Real: 0.0147, ; D Loss Fake: 0.0082, \n",
      "Epoch [237/300], Step [220/234], D Loss: 0.0027, G Loss: 12.6493; D Loss Real: 0.0027, ; D Loss Fake: 0.0000, \n",
      "Epoch [238/300], Step [20/234], D Loss: 0.0125, G Loss: 5.3742; D Loss Real: 0.0020, ; D Loss Fake: 0.0105, \n",
      "Epoch [238/300], Step [40/234], D Loss: 0.0137, G Loss: 7.6682; D Loss Real: 0.0127, ; D Loss Fake: 0.0010, \n",
      "Epoch [238/300], Step [60/234], D Loss: 0.0024, G Loss: 7.6857; D Loss Real: 0.0019, ; D Loss Fake: 0.0005, \n",
      "Epoch [238/300], Step [80/234], D Loss: 0.0010, G Loss: 8.2867; D Loss Real: 0.0006, ; D Loss Fake: 0.0004, \n",
      "Epoch [238/300], Step [100/234], D Loss: 0.0227, G Loss: 12.1701; D Loss Real: 0.0227, ; D Loss Fake: 0.0000, \n",
      "Epoch [238/300], Step [120/234], D Loss: 0.0258, G Loss: -0.0016; D Loss Real: 0.0085, ; D Loss Fake: 0.0173, \n",
      "Epoch [238/300], Step [140/234], D Loss: 0.0276, G Loss: 10.9732; D Loss Real: 0.0276, ; D Loss Fake: 0.0000, \n",
      "Epoch [238/300], Step [160/234], D Loss: 0.0062, G Loss: 5.6704; D Loss Real: 0.0032, ; D Loss Fake: 0.0031, \n",
      "Epoch [238/300], Step [180/234], D Loss: 0.0008, G Loss: 8.4771; D Loss Real: 0.0005, ; D Loss Fake: 0.0002, \n",
      "Epoch [238/300], Step [200/234], D Loss: 0.0081, G Loss: 6.3455; D Loss Real: 0.0064, ; D Loss Fake: 0.0017, \n",
      "Epoch [238/300], Step [220/234], D Loss: 0.0057, G Loss: 5.6488; D Loss Real: 0.0020, ; D Loss Fake: 0.0037, \n",
      "Epoch [239/300], Step [20/234], D Loss: 0.0059, G Loss: 18.6548; D Loss Real: 0.0059, ; D Loss Fake: 0.0000, \n",
      "Epoch [239/300], Step [40/234], D Loss: 0.0713, G Loss: 5.8877; D Loss Real: 0.0012, ; D Loss Fake: 0.0700, \n",
      "Epoch [239/300], Step [60/234], D Loss: 0.0193, G Loss: 9.7943; D Loss Real: 0.0192, ; D Loss Fake: 0.0000, \n",
      "Epoch [239/300], Step [80/234], D Loss: 0.0028, G Loss: 9.0561; D Loss Real: 0.0026, ; D Loss Fake: 0.0002, \n",
      "Epoch [239/300], Step [100/234], D Loss: 0.0268, G Loss: 13.1245; D Loss Real: 0.0268, ; D Loss Fake: 0.0000, \n",
      "Epoch [239/300], Step [120/234], D Loss: 0.0061, G Loss: 6.9319; D Loss Real: 0.0053, ; D Loss Fake: 0.0008, \n",
      "Epoch [239/300], Step [140/234], D Loss: 0.0368, G Loss: 8.0849; D Loss Real: 0.0364, ; D Loss Fake: 0.0005, \n",
      "Epoch [239/300], Step [160/234], D Loss: 0.2389, G Loss: 8.5003; D Loss Real: 0.0097, ; D Loss Fake: 0.2292, \n",
      "Epoch [239/300], Step [180/234], D Loss: 0.0126, G Loss: 6.0627; D Loss Real: 0.0054, ; D Loss Fake: 0.0072, \n",
      "Epoch [239/300], Step [200/234], D Loss: 0.0083, G Loss: 12.3960; D Loss Real: 0.0083, ; D Loss Fake: 0.0000, \n",
      "Epoch [239/300], Step [220/234], D Loss: 0.0016, G Loss: 12.0627; D Loss Real: 0.0016, ; D Loss Fake: 0.0000, \n",
      "Epoch [240/300], Step [20/234], D Loss: 0.0697, G Loss: 5.8092; D Loss Real: 0.0015, ; D Loss Fake: 0.0682, \n",
      "Epoch [240/300], Step [40/234], D Loss: 0.0362, G Loss: 8.7170; D Loss Real: 0.0020, ; D Loss Fake: 0.0342, \n",
      "Epoch [240/300], Step [60/234], D Loss: 0.0415, G Loss: 5.3025; D Loss Real: 0.0057, ; D Loss Fake: 0.0358, \n",
      "Epoch [240/300], Step [80/234], D Loss: 0.0025, G Loss: 8.3471; D Loss Real: 0.0021, ; D Loss Fake: 0.0004, \n",
      "Epoch [240/300], Step [100/234], D Loss: 0.0212, G Loss: 6.3795; D Loss Real: 0.0011, ; D Loss Fake: 0.0201, \n",
      "Epoch [240/300], Step [120/234], D Loss: 0.0077, G Loss: 12.8975; D Loss Real: 0.0077, ; D Loss Fake: 0.0000, \n",
      "Epoch [240/300], Step [140/234], D Loss: 0.0120, G Loss: 7.9003; D Loss Real: 0.0108, ; D Loss Fake: 0.0012, \n",
      "Epoch [240/300], Step [160/234], D Loss: 0.0018, G Loss: 8.3995; D Loss Real: 0.0016, ; D Loss Fake: 0.0002, \n",
      "Epoch [240/300], Step [180/234], D Loss: 0.0015, G Loss: 8.8053; D Loss Real: 0.0015, ; D Loss Fake: 0.0001, \n",
      "Epoch [240/300], Step [200/234], D Loss: 0.0703, G Loss: 5.4951; D Loss Real: 0.0010, ; D Loss Fake: 0.0693, \n",
      "Epoch [240/300], Step [220/234], D Loss: 0.0202, G Loss: 6.0875; D Loss Real: 0.0145, ; D Loss Fake: 0.0056, \n",
      "Epoch [241/300], Step [20/234], D Loss: 0.0311, G Loss: 6.2852; D Loss Real: 0.0061, ; D Loss Fake: 0.0249, \n",
      "Epoch [241/300], Step [40/234], D Loss: 0.0123, G Loss: 0.0054; D Loss Real: 0.0011, ; D Loss Fake: 0.0112, \n",
      "Epoch [241/300], Step [60/234], D Loss: 0.5675, G Loss: -0.0015; D Loss Real: 0.0002, ; D Loss Fake: 0.5673, \n",
      "Epoch [241/300], Step [80/234], D Loss: 0.0092, G Loss: 7.0436; D Loss Real: 0.0054, ; D Loss Fake: 0.0038, \n",
      "Epoch [241/300], Step [100/234], D Loss: 0.0441, G Loss: 13.9587; D Loss Real: 0.0441, ; D Loss Fake: 0.0000, \n",
      "Epoch [241/300], Step [120/234], D Loss: 0.1452, G Loss: 6.5218; D Loss Real: 0.0238, ; D Loss Fake: 0.1214, \n",
      "Epoch [241/300], Step [140/234], D Loss: 0.0046, G Loss: 6.1876; D Loss Real: 0.0009, ; D Loss Fake: 0.0037, \n",
      "Epoch [241/300], Step [160/234], D Loss: 0.0027, G Loss: 6.4923; D Loss Real: 0.0013, ; D Loss Fake: 0.0014, \n",
      "Epoch [241/300], Step [180/234], D Loss: 0.0067, G Loss: 5.9734; D Loss Real: 0.0008, ; D Loss Fake: 0.0059, \n",
      "Epoch [241/300], Step [200/234], D Loss: 0.0004, G Loss: 10.0742; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [241/300], Step [220/234], D Loss: 0.0056, G Loss: 5.2090; D Loss Real: 0.0001, ; D Loss Fake: 0.0055, \n",
      "Epoch [242/300], Step [20/234], D Loss: 0.1213, G Loss: 16.9171; D Loss Real: 0.1213, ; D Loss Fake: 0.0000, \n",
      "Epoch [242/300], Step [40/234], D Loss: 0.0099, G Loss: 11.9587; D Loss Real: 0.0099, ; D Loss Fake: 0.0000, \n",
      "Epoch [242/300], Step [60/234], D Loss: 0.0172, G Loss: 12.0758; D Loss Real: 0.0171, ; D Loss Fake: 0.0001, \n",
      "Epoch [242/300], Step [80/234], D Loss: 0.0042, G Loss: 6.4731; D Loss Real: 0.0014, ; D Loss Fake: 0.0028, \n",
      "Epoch [242/300], Step [100/234], D Loss: 0.0050, G Loss: 6.1934; D Loss Real: 0.0021, ; D Loss Fake: 0.0029, \n",
      "Epoch [242/300], Step [120/234], D Loss: 0.0256, G Loss: 11.1900; D Loss Real: 0.0256, ; D Loss Fake: 0.0000, \n",
      "Epoch [242/300], Step [140/234], D Loss: 0.0155, G Loss: 6.0187; D Loss Real: 0.0031, ; D Loss Fake: 0.0124, \n",
      "Epoch [242/300], Step [160/234], D Loss: 0.0492, G Loss: 8.9425; D Loss Real: 0.0484, ; D Loss Fake: 0.0008, \n",
      "Epoch [242/300], Step [180/234], D Loss: 0.0532, G Loss: 5.2566; D Loss Real: 0.0007, ; D Loss Fake: 0.0525, \n",
      "Epoch [242/300], Step [200/234], D Loss: 0.0046, G Loss: 6.5453; D Loss Real: 0.0020, ; D Loss Fake: 0.0026, \n",
      "Epoch [242/300], Step [220/234], D Loss: 0.0029, G Loss: 9.0090; D Loss Real: 0.0023, ; D Loss Fake: 0.0006, \n",
      "Epoch [243/300], Step [20/234], D Loss: 0.0446, G Loss: 15.8125; D Loss Real: 0.0446, ; D Loss Fake: 0.0000, \n",
      "Epoch [243/300], Step [40/234], D Loss: 0.0601, G Loss: -0.0055; D Loss Real: 0.0601, ; D Loss Fake: 0.0000, \n",
      "Epoch [243/300], Step [60/234], D Loss: 0.0009, G Loss: 12.3460; D Loss Real: 0.0009, ; D Loss Fake: 0.0000, \n",
      "Epoch [243/300], Step [80/234], D Loss: 0.0252, G Loss: 5.8595; D Loss Real: 0.0050, ; D Loss Fake: 0.0202, \n",
      "Epoch [243/300], Step [100/234], D Loss: 0.0182, G Loss: 5.6957; D Loss Real: 0.0003, ; D Loss Fake: 0.0179, \n",
      "Epoch [243/300], Step [120/234], D Loss: 0.0078, G Loss: 5.6066; D Loss Real: 0.0003, ; D Loss Fake: 0.0076, \n",
      "Epoch [243/300], Step [140/234], D Loss: 0.0598, G Loss: 11.0699; D Loss Real: 0.0598, ; D Loss Fake: 0.0000, \n",
      "Epoch [243/300], Step [160/234], D Loss: 0.0015, G Loss: 8.7037; D Loss Real: 0.0012, ; D Loss Fake: 0.0003, \n",
      "Epoch [243/300], Step [180/234], D Loss: 0.0065, G Loss: 8.4680; D Loss Real: 0.0059, ; D Loss Fake: 0.0007, \n",
      "Epoch [243/300], Step [200/234], D Loss: 0.0033, G Loss: 6.3033; D Loss Real: 0.0012, ; D Loss Fake: 0.0021, \n",
      "Epoch [243/300], Step [220/234], D Loss: 0.0015, G Loss: 9.5505; D Loss Real: 0.0014, ; D Loss Fake: 0.0001, \n",
      "Epoch [244/300], Step [20/234], D Loss: 0.0384, G Loss: 5.8494; D Loss Real: 0.0009, ; D Loss Fake: 0.0375, \n",
      "Epoch [244/300], Step [40/234], D Loss: 0.0230, G Loss: 4.9348; D Loss Real: 0.0024, ; D Loss Fake: 0.0206, \n",
      "Epoch [244/300], Step [60/234], D Loss: 0.0031, G Loss: 11.9961; D Loss Real: 0.0029, ; D Loss Fake: 0.0002, \n",
      "Epoch [244/300], Step [80/234], D Loss: 0.0010, G Loss: 13.8233; D Loss Real: 0.0010, ; D Loss Fake: 0.0000, \n",
      "Epoch [244/300], Step [100/234], D Loss: 0.0016, G Loss: 8.7759; D Loss Real: 0.0015, ; D Loss Fake: 0.0001, \n",
      "Epoch [244/300], Step [120/234], D Loss: 0.0009, G Loss: 11.8736; D Loss Real: 0.0009, ; D Loss Fake: 0.0000, \n",
      "Epoch [244/300], Step [140/234], D Loss: 0.0064, G Loss: 6.1911; D Loss Real: 0.0001, ; D Loss Fake: 0.0063, \n",
      "Epoch [244/300], Step [160/234], D Loss: 0.0025, G Loss: 10.7529; D Loss Real: 0.0024, ; D Loss Fake: 0.0000, \n",
      "Epoch [244/300], Step [180/234], D Loss: 0.1003, G Loss: 9.9775; D Loss Real: 0.1003, ; D Loss Fake: 0.0000, \n",
      "Epoch [244/300], Step [200/234], D Loss: 0.0015, G Loss: 9.7354; D Loss Real: 0.0014, ; D Loss Fake: 0.0001, \n",
      "Epoch [244/300], Step [220/234], D Loss: 0.0033, G Loss: 6.9944; D Loss Real: 0.0024, ; D Loss Fake: 0.0009, \n",
      "Epoch [245/300], Step [20/234], D Loss: 0.0014, G Loss: 7.3246; D Loss Real: 0.0001, ; D Loss Fake: 0.0014, \n",
      "Epoch [245/300], Step [40/234], D Loss: 0.0145, G Loss: 18.3732; D Loss Real: 0.0145, ; D Loss Fake: 0.0000, \n",
      "Epoch [245/300], Step [60/234], D Loss: 0.0178, G Loss: 5.2485; D Loss Real: 0.0039, ; D Loss Fake: 0.0139, \n",
      "Epoch [245/300], Step [80/234], D Loss: 0.0004, G Loss: -0.0065; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [245/300], Step [100/234], D Loss: 0.0990, G Loss: 4.7776; D Loss Real: 0.0922, ; D Loss Fake: 0.0068, \n",
      "Epoch [245/300], Step [120/234], D Loss: 0.0015, G Loss: 9.2148; D Loss Real: 0.0014, ; D Loss Fake: 0.0001, \n",
      "Epoch [245/300], Step [140/234], D Loss: 0.0073, G Loss: 6.6348; D Loss Real: 0.0047, ; D Loss Fake: 0.0026, \n",
      "Epoch [245/300], Step [160/234], D Loss: 0.0213, G Loss: 0.0144; D Loss Real: 0.0024, ; D Loss Fake: 0.0188, \n",
      "Epoch [245/300], Step [180/234], D Loss: 0.0126, G Loss: 13.5253; D Loss Real: 0.0126, ; D Loss Fake: 0.0000, \n",
      "Epoch [245/300], Step [200/234], D Loss: 0.0002, G Loss: 14.1045; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [245/300], Step [220/234], D Loss: 0.0137, G Loss: 8.4775; D Loss Real: 0.0123, ; D Loss Fake: 0.0014, \n",
      "Epoch [246/300], Step [20/234], D Loss: 0.0164, G Loss: 8.8203; D Loss Real: 0.0162, ; D Loss Fake: 0.0002, \n",
      "Epoch [246/300], Step [40/234], D Loss: 0.0278, G Loss: 5.7074; D Loss Real: 0.0009, ; D Loss Fake: 0.0269, \n",
      "Epoch [246/300], Step [60/234], D Loss: 0.3157, G Loss: 10.6132; D Loss Real: 0.3157, ; D Loss Fake: 0.0000, \n",
      "Epoch [246/300], Step [80/234], D Loss: 0.0026, G Loss: 12.4912; D Loss Real: 0.0026, ; D Loss Fake: 0.0000, \n",
      "Epoch [246/300], Step [100/234], D Loss: 0.0005, G Loss: 9.8825; D Loss Real: 0.0003, ; D Loss Fake: 0.0002, \n",
      "Epoch [246/300], Step [120/234], D Loss: 0.0278, G Loss: -0.0048; D Loss Real: 0.0040, ; D Loss Fake: 0.0239, \n",
      "Epoch [246/300], Step [140/234], D Loss: 0.0001, G Loss: 11.6127; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [246/300], Step [160/234], D Loss: 0.0012, G Loss: 10.7523; D Loss Real: 0.0011, ; D Loss Fake: 0.0001, \n",
      "Epoch [246/300], Step [180/234], D Loss: 0.0077, G Loss: 7.8059; D Loss Real: 0.0069, ; D Loss Fake: 0.0008, \n",
      "Epoch [246/300], Step [200/234], D Loss: 0.0003, G Loss: 11.1202; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [246/300], Step [220/234], D Loss: 0.0029, G Loss: 12.3389; D Loss Real: 0.0028, ; D Loss Fake: 0.0000, \n",
      "Epoch [247/300], Step [20/234], D Loss: 0.0109, G Loss: 10.4025; D Loss Real: 0.0108, ; D Loss Fake: 0.0001, \n",
      "Epoch [247/300], Step [40/234], D Loss: 0.0005, G Loss: 11.9957; D Loss Real: 0.0005, ; D Loss Fake: 0.0000, \n",
      "Epoch [247/300], Step [60/234], D Loss: 0.0072, G Loss: 6.5073; D Loss Real: 0.0048, ; D Loss Fake: 0.0024, \n",
      "Epoch [247/300], Step [80/234], D Loss: 0.0004, G Loss: 13.8910; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [247/300], Step [100/234], D Loss: 0.0045, G Loss: 6.1299; D Loss Real: 0.0012, ; D Loss Fake: 0.0033, \n",
      "Epoch [247/300], Step [120/234], D Loss: 0.0082, G Loss: 7.6958; D Loss Real: 0.0071, ; D Loss Fake: 0.0010, \n",
      "Epoch [247/300], Step [140/234], D Loss: 0.0011, G Loss: 14.0945; D Loss Real: 0.0011, ; D Loss Fake: 0.0000, \n",
      "Epoch [247/300], Step [160/234], D Loss: 0.0328, G Loss: 5.3780; D Loss Real: 0.0245, ; D Loss Fake: 0.0083, \n",
      "Epoch [247/300], Step [180/234], D Loss: 0.0075, G Loss: 5.6988; D Loss Real: 0.0013, ; D Loss Fake: 0.0062, \n",
      "Epoch [247/300], Step [200/234], D Loss: 0.0018, G Loss: 0.0076; D Loss Real: 0.0015, ; D Loss Fake: 0.0003, \n",
      "Epoch [247/300], Step [220/234], D Loss: 0.0089, G Loss: 6.9203; D Loss Real: 0.0083, ; D Loss Fake: 0.0006, \n",
      "Epoch [248/300], Step [20/234], D Loss: 0.0027, G Loss: 7.4140; D Loss Real: 0.0006, ; D Loss Fake: 0.0021, \n",
      "Epoch [248/300], Step [40/234], D Loss: 0.0191, G Loss: 5.5978; D Loss Real: 0.0011, ; D Loss Fake: 0.0180, \n",
      "Epoch [248/300], Step [60/234], D Loss: 0.0127, G Loss: 5.9305; D Loss Real: 0.0101, ; D Loss Fake: 0.0026, \n",
      "Epoch [248/300], Step [80/234], D Loss: 0.0072, G Loss: 0.0269; D Loss Real: 0.0072, ; D Loss Fake: 0.0000, \n",
      "Epoch [248/300], Step [100/234], D Loss: 0.0105, G Loss: 15.6878; D Loss Real: 0.0105, ; D Loss Fake: 0.0000, \n",
      "Epoch [248/300], Step [120/234], D Loss: 0.0118, G Loss: 8.7413; D Loss Real: 0.0113, ; D Loss Fake: 0.0005, \n",
      "Epoch [248/300], Step [140/234], D Loss: 0.5746, G Loss: 16.3892; D Loss Real: 0.0013, ; D Loss Fake: 0.5733, \n",
      "Epoch [248/300], Step [160/234], D Loss: 0.0026, G Loss: 11.5149; D Loss Real: 0.0026, ; D Loss Fake: 0.0001, \n",
      "Epoch [248/300], Step [180/234], D Loss: 0.0271, G Loss: 8.2401; D Loss Real: 0.0257, ; D Loss Fake: 0.0014, \n",
      "Epoch [248/300], Step [200/234], D Loss: 0.0212, G Loss: 0.0015; D Loss Real: 0.0210, ; D Loss Fake: 0.0002, \n",
      "Epoch [248/300], Step [220/234], D Loss: 0.0187, G Loss: 5.2680; D Loss Real: 0.0088, ; D Loss Fake: 0.0099, \n",
      "Epoch [249/300], Step [20/234], D Loss: 0.0004, G Loss: 13.1762; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [249/300], Step [40/234], D Loss: 0.0010, G Loss: 14.8942; D Loss Real: 0.0010, ; D Loss Fake: 0.0000, \n",
      "Epoch [249/300], Step [60/234], D Loss: 0.2378, G Loss: 12.1646; D Loss Real: 0.0085, ; D Loss Fake: 0.2293, \n",
      "Epoch [249/300], Step [80/234], D Loss: 0.0192, G Loss: 9.1906; D Loss Real: 0.0191, ; D Loss Fake: 0.0002, \n",
      "Epoch [249/300], Step [100/234], D Loss: 0.0009, G Loss: 7.7339; D Loss Real: 0.0004, ; D Loss Fake: 0.0005, \n",
      "Epoch [249/300], Step [120/234], D Loss: 0.0014, G Loss: 9.1155; D Loss Real: 0.0012, ; D Loss Fake: 0.0001, \n",
      "Epoch [249/300], Step [140/234], D Loss: 0.0184, G Loss: 9.4874; D Loss Real: 0.0174, ; D Loss Fake: 0.0009, \n",
      "Epoch [249/300], Step [160/234], D Loss: 0.0668, G Loss: 5.6532; D Loss Real: 0.0010, ; D Loss Fake: 0.0658, \n",
      "Epoch [249/300], Step [180/234], D Loss: 0.0281, G Loss: 8.3702; D Loss Real: 0.0279, ; D Loss Fake: 0.0002, \n",
      "Epoch [249/300], Step [200/234], D Loss: 0.0094, G Loss: 6.2110; D Loss Real: 0.0040, ; D Loss Fake: 0.0054, \n",
      "Epoch [249/300], Step [220/234], D Loss: 0.0499, G Loss: 5.1255; D Loss Real: 0.0379, ; D Loss Fake: 0.0120, \n",
      "Epoch [250/300], Step [20/234], D Loss: 0.0311, G Loss: 5.2556; D Loss Real: 0.0266, ; D Loss Fake: 0.0045, \n",
      "Epoch [250/300], Step [40/234], D Loss: 0.0024, G Loss: 10.9716; D Loss Real: 0.0024, ; D Loss Fake: 0.0000, \n",
      "Epoch [250/300], Step [60/234], D Loss: 0.0471, G Loss: 8.4900; D Loss Real: 0.0449, ; D Loss Fake: 0.0022, \n",
      "Epoch [250/300], Step [80/234], D Loss: 0.0748, G Loss: 13.2171; D Loss Real: 0.0748, ; D Loss Fake: 0.0000, \n",
      "Epoch [250/300], Step [100/234], D Loss: 0.0030, G Loss: 16.4824; D Loss Real: 0.0030, ; D Loss Fake: 0.0000, \n",
      "Epoch [250/300], Step [120/234], D Loss: 0.0065, G Loss: 7.3273; D Loss Real: 0.0002, ; D Loss Fake: 0.0063, \n",
      "Epoch [250/300], Step [140/234], D Loss: 0.0046, G Loss: 14.6480; D Loss Real: 0.0046, ; D Loss Fake: 0.0000, \n",
      "Epoch [250/300], Step [160/234], D Loss: 0.1658, G Loss: 12.2973; D Loss Real: 0.1658, ; D Loss Fake: 0.0000, \n",
      "Epoch [250/300], Step [180/234], D Loss: 0.0002, G Loss: 10.8446; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [250/300], Step [200/234], D Loss: 0.0445, G Loss: 6.0863; D Loss Real: 0.0420, ; D Loss Fake: 0.0025, \n",
      "Epoch [250/300], Step [220/234], D Loss: 0.0012, G Loss: 12.0311; D Loss Real: 0.0012, ; D Loss Fake: 0.0000, \n",
      "Epoch [251/300], Step [20/234], D Loss: 0.0020, G Loss: 10.1669; D Loss Real: 0.0006, ; D Loss Fake: 0.0013, \n",
      "Epoch [251/300], Step [40/234], D Loss: 0.2293, G Loss: 10.6799; D Loss Real: 0.0000, ; D Loss Fake: 0.2293, \n",
      "Epoch [251/300], Step [60/234], D Loss: 0.0367, G Loss: 5.2865; D Loss Real: 0.0006, ; D Loss Fake: 0.0361, \n",
      "Epoch [251/300], Step [80/234], D Loss: 0.0894, G Loss: 8.0162; D Loss Real: 0.0013, ; D Loss Fake: 0.0881, \n",
      "Epoch [251/300], Step [100/234], D Loss: 0.0035, G Loss: 8.7019; D Loss Real: 0.0019, ; D Loss Fake: 0.0016, \n",
      "Epoch [251/300], Step [120/234], D Loss: 0.0027, G Loss: 11.5785; D Loss Real: 0.0026, ; D Loss Fake: 0.0000, \n",
      "Epoch [251/300], Step [140/234], D Loss: 0.0002, G Loss: 12.4490; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [251/300], Step [160/234], D Loss: 0.0069, G Loss: 6.7123; D Loss Real: 0.0054, ; D Loss Fake: 0.0015, \n",
      "Epoch [251/300], Step [180/234], D Loss: 0.0022, G Loss: 8.9333; D Loss Real: 0.0010, ; D Loss Fake: 0.0012, \n",
      "Epoch [251/300], Step [200/234], D Loss: 0.0130, G Loss: 7.7657; D Loss Real: 0.0105, ; D Loss Fake: 0.0025, \n",
      "Epoch [251/300], Step [220/234], D Loss: 0.0118, G Loss: 7.7020; D Loss Real: 0.0114, ; D Loss Fake: 0.0004, \n",
      "Epoch [252/300], Step [20/234], D Loss: 0.0711, G Loss: 9.2985; D Loss Real: 0.0709, ; D Loss Fake: 0.0001, \n",
      "Epoch [252/300], Step [40/234], D Loss: 0.0018, G Loss: 10.7556; D Loss Real: 0.0018, ; D Loss Fake: 0.0000, \n",
      "Epoch [252/300], Step [60/234], D Loss: 0.0015, G Loss: 13.1163; D Loss Real: 0.0015, ; D Loss Fake: 0.0000, \n",
      "Epoch [252/300], Step [80/234], D Loss: 0.0595, G Loss: 6.0053; D Loss Real: 0.0091, ; D Loss Fake: 0.0505, \n",
      "Epoch [252/300], Step [100/234], D Loss: 0.0131, G Loss: 5.6068; D Loss Real: 0.0014, ; D Loss Fake: 0.0117, \n",
      "Epoch [252/300], Step [120/234], D Loss: 0.0257, G Loss: 6.8744; D Loss Real: 0.0005, ; D Loss Fake: 0.0252, \n",
      "Epoch [252/300], Step [140/234], D Loss: 0.0605, G Loss: 4.5456; D Loss Real: 0.0427, ; D Loss Fake: 0.0178, \n",
      "Epoch [252/300], Step [160/234], D Loss: 0.0025, G Loss: 0.0061; D Loss Real: 0.0010, ; D Loss Fake: 0.0015, \n",
      "Epoch [252/300], Step [180/234], D Loss: 0.0072, G Loss: 6.1320; D Loss Real: 0.0019, ; D Loss Fake: 0.0053, \n",
      "Epoch [252/300], Step [200/234], D Loss: 0.0384, G Loss: 5.0513; D Loss Real: 0.0001, ; D Loss Fake: 0.0383, \n",
      "Epoch [252/300], Step [220/234], D Loss: 0.0151, G Loss: 5.9950; D Loss Real: 0.0106, ; D Loss Fake: 0.0045, \n",
      "Epoch [253/300], Step [20/234], D Loss: 0.0245, G Loss: 12.9396; D Loss Real: 0.0245, ; D Loss Fake: 0.0000, \n",
      "Epoch [253/300], Step [40/234], D Loss: 0.1871, G Loss: 9.9342; D Loss Real: 0.0004, ; D Loss Fake: 0.1867, \n",
      "Epoch [253/300], Step [60/234], D Loss: 0.0130, G Loss: 8.1830; D Loss Real: 0.0096, ; D Loss Fake: 0.0034, \n",
      "Epoch [253/300], Step [80/234], D Loss: 0.0020, G Loss: 8.5499; D Loss Real: 0.0017, ; D Loss Fake: 0.0003, \n",
      "Epoch [253/300], Step [100/234], D Loss: 0.0051, G Loss: 6.7854; D Loss Real: 0.0035, ; D Loss Fake: 0.0016, \n",
      "Epoch [253/300], Step [120/234], D Loss: 0.0009, G Loss: 8.8223; D Loss Real: 0.0003, ; D Loss Fake: 0.0007, \n",
      "Epoch [253/300], Step [140/234], D Loss: 0.0269, G Loss: 5.4721; D Loss Real: 0.0193, ; D Loss Fake: 0.0076, \n",
      "Epoch [253/300], Step [160/234], D Loss: 0.0179, G Loss: 10.3871; D Loss Real: 0.0178, ; D Loss Fake: 0.0000, \n",
      "Epoch [253/300], Step [180/234], D Loss: 0.0023, G Loss: 11.8785; D Loss Real: 0.0023, ; D Loss Fake: 0.0000, \n",
      "Epoch [253/300], Step [200/234], D Loss: 0.0124, G Loss: 9.2712; D Loss Real: 0.0123, ; D Loss Fake: 0.0001, \n",
      "Epoch [253/300], Step [220/234], D Loss: 0.0007, G Loss: 7.9128; D Loss Real: 0.0004, ; D Loss Fake: 0.0002, \n",
      "Epoch [254/300], Step [20/234], D Loss: 0.0022, G Loss: 10.1578; D Loss Real: 0.0011, ; D Loss Fake: 0.0011, \n",
      "Epoch [254/300], Step [40/234], D Loss: 0.0434, G Loss: 13.5801; D Loss Real: 0.0434, ; D Loss Fake: 0.0000, \n",
      "Epoch [254/300], Step [60/234], D Loss: 0.0112, G Loss: -0.0039; D Loss Real: 0.0112, ; D Loss Fake: 0.0000, \n",
      "Epoch [254/300], Step [80/234], D Loss: 0.0118, G Loss: 7.0290; D Loss Real: 0.0063, ; D Loss Fake: 0.0056, \n",
      "Epoch [254/300], Step [100/234], D Loss: 0.0661, G Loss: 6.7300; D Loss Real: 0.0005, ; D Loss Fake: 0.0656, \n",
      "Epoch [254/300], Step [120/234], D Loss: 0.0026, G Loss: 9.6717; D Loss Real: 0.0022, ; D Loss Fake: 0.0004, \n",
      "Epoch [254/300], Step [140/234], D Loss: 0.3811, G Loss: 9.4638; D Loss Real: 0.3811, ; D Loss Fake: 0.0000, \n",
      "Epoch [254/300], Step [160/234], D Loss: 0.0330, G Loss: -0.0026; D Loss Real: 0.0013, ; D Loss Fake: 0.0317, \n",
      "Epoch [254/300], Step [180/234], D Loss: 0.0047, G Loss: 10.9827; D Loss Real: 0.0046, ; D Loss Fake: 0.0000, \n",
      "Epoch [254/300], Step [200/234], D Loss: 0.0072, G Loss: 6.2900; D Loss Real: 0.0033, ; D Loss Fake: 0.0039, \n",
      "Epoch [254/300], Step [220/234], D Loss: 0.0241, G Loss: 10.4088; D Loss Real: 0.0240, ; D Loss Fake: 0.0001, \n",
      "Epoch [255/300], Step [20/234], D Loss: 0.0001, G Loss: 17.4233; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [255/300], Step [40/234], D Loss: 0.0052, G Loss: 9.1484; D Loss Real: 0.0049, ; D Loss Fake: 0.0003, \n",
      "Epoch [255/300], Step [60/234], D Loss: 0.1504, G Loss: 8.3490; D Loss Real: 0.0002, ; D Loss Fake: 0.1501, \n",
      "Epoch [255/300], Step [80/234], D Loss: 0.0116, G Loss: 10.0097; D Loss Real: 0.0114, ; D Loss Fake: 0.0001, \n",
      "Epoch [255/300], Step [100/234], D Loss: 0.1218, G Loss: 6.6574; D Loss Real: 0.0012, ; D Loss Fake: 0.1206, \n",
      "Epoch [255/300], Step [120/234], D Loss: 0.0216, G Loss: 4.8619; D Loss Real: 0.0074, ; D Loss Fake: 0.0142, \n",
      "Epoch [255/300], Step [140/234], D Loss: 0.0030, G Loss: 11.0784; D Loss Real: 0.0029, ; D Loss Fake: 0.0001, \n",
      "Epoch [255/300], Step [160/234], D Loss: 0.0040, G Loss: 6.5621; D Loss Real: 0.0013, ; D Loss Fake: 0.0027, \n",
      "Epoch [255/300], Step [180/234], D Loss: 0.0620, G Loss: 7.5739; D Loss Real: 0.0609, ; D Loss Fake: 0.0011, \n",
      "Epoch [255/300], Step [200/234], D Loss: 0.0025, G Loss: 11.6798; D Loss Real: 0.0024, ; D Loss Fake: 0.0000, \n",
      "Epoch [255/300], Step [220/234], D Loss: 0.0127, G Loss: 0.0054; D Loss Real: 0.0122, ; D Loss Fake: 0.0004, \n",
      "Epoch [256/300], Step [20/234], D Loss: 0.1876, G Loss: 8.0864; D Loss Real: 0.0012, ; D Loss Fake: 0.1863, \n",
      "Epoch [256/300], Step [40/234], D Loss: 0.0182, G Loss: 0.0015; D Loss Real: 0.0012, ; D Loss Fake: 0.0170, \n",
      "Epoch [256/300], Step [60/234], D Loss: 0.0080, G Loss: 11.3933; D Loss Real: 0.0080, ; D Loss Fake: 0.0001, \n",
      "Epoch [256/300], Step [80/234], D Loss: 0.0095, G Loss: 7.3419; D Loss Real: 0.0065, ; D Loss Fake: 0.0030, \n",
      "Epoch [256/300], Step [100/234], D Loss: 0.0174, G Loss: 6.0846; D Loss Real: 0.0114, ; D Loss Fake: 0.0060, \n",
      "Epoch [256/300], Step [120/234], D Loss: 0.0146, G Loss: 5.8840; D Loss Real: 0.0037, ; D Loss Fake: 0.0108, \n",
      "Epoch [256/300], Step [140/234], D Loss: 0.0067, G Loss: 7.8720; D Loss Real: 0.0061, ; D Loss Fake: 0.0006, \n",
      "Epoch [256/300], Step [160/234], D Loss: 0.0042, G Loss: 17.3836; D Loss Real: 0.0042, ; D Loss Fake: 0.0000, \n",
      "Epoch [256/300], Step [180/234], D Loss: 0.0063, G Loss: 6.3448; D Loss Real: 0.0024, ; D Loss Fake: 0.0039, \n",
      "Epoch [256/300], Step [200/234], D Loss: 0.0419, G Loss: 7.5224; D Loss Real: 0.0108, ; D Loss Fake: 0.0311, \n",
      "Epoch [256/300], Step [220/234], D Loss: 0.0343, G Loss: 0.0212; D Loss Real: 0.0337, ; D Loss Fake: 0.0006, \n",
      "Epoch [257/300], Step [20/234], D Loss: 0.0082, G Loss: 13.0293; D Loss Real: 0.0082, ; D Loss Fake: 0.0000, \n",
      "Epoch [257/300], Step [40/234], D Loss: 0.0059, G Loss: -0.0022; D Loss Real: 0.0058, ; D Loss Fake: 0.0001, \n",
      "Epoch [257/300], Step [60/234], D Loss: 0.0450, G Loss: 0.0042; D Loss Real: 0.0255, ; D Loss Fake: 0.0194, \n",
      "Epoch [257/300], Step [80/234], D Loss: 0.0173, G Loss: 10.8410; D Loss Real: 0.0172, ; D Loss Fake: 0.0001, \n",
      "Epoch [257/300], Step [100/234], D Loss: 0.0015, G Loss: 7.5555; D Loss Real: 0.0009, ; D Loss Fake: 0.0006, \n",
      "Epoch [257/300], Step [120/234], D Loss: 0.2762, G Loss: 9.6287; D Loss Real: 0.0052, ; D Loss Fake: 0.2710, \n",
      "Epoch [257/300], Step [140/234], D Loss: 0.0101, G Loss: -0.0086; D Loss Real: 0.0100, ; D Loss Fake: 0.0001, \n",
      "Epoch [257/300], Step [160/234], D Loss: 0.0122, G Loss: 5.1906; D Loss Real: 0.0040, ; D Loss Fake: 0.0082, \n",
      "Epoch [257/300], Step [180/234], D Loss: 0.0036, G Loss: -0.0082; D Loss Real: 0.0036, ; D Loss Fake: 0.0000, \n",
      "Epoch [257/300], Step [200/234], D Loss: 0.0237, G Loss: 6.1978; D Loss Real: 0.0069, ; D Loss Fake: 0.0168, \n",
      "Epoch [257/300], Step [220/234], D Loss: 0.0078, G Loss: 0.0088; D Loss Real: 0.0013, ; D Loss Fake: 0.0066, \n",
      "Epoch [258/300], Step [20/234], D Loss: 0.0048, G Loss: 8.2711; D Loss Real: 0.0026, ; D Loss Fake: 0.0022, \n",
      "Epoch [258/300], Step [40/234], D Loss: 0.0003, G Loss: 9.8186; D Loss Real: 0.0002, ; D Loss Fake: 0.0001, \n",
      "Epoch [258/300], Step [60/234], D Loss: 0.0076, G Loss: 0.0010; D Loss Real: 0.0075, ; D Loss Fake: 0.0000, \n",
      "Epoch [258/300], Step [80/234], D Loss: 0.0141, G Loss: 6.0081; D Loss Real: 0.0100, ; D Loss Fake: 0.0041, \n",
      "Epoch [258/300], Step [100/234], D Loss: 0.0285, G Loss: 6.5634; D Loss Real: 0.0077, ; D Loss Fake: 0.0208, \n",
      "Epoch [258/300], Step [120/234], D Loss: 0.0069, G Loss: 12.9138; D Loss Real: 0.0069, ; D Loss Fake: 0.0000, \n",
      "Epoch [258/300], Step [140/234], D Loss: 0.0097, G Loss: 10.7126; D Loss Real: 0.0096, ; D Loss Fake: 0.0001, \n",
      "Epoch [258/300], Step [160/234], D Loss: 0.0071, G Loss: 5.9353; D Loss Real: 0.0030, ; D Loss Fake: 0.0041, \n",
      "Epoch [258/300], Step [180/234], D Loss: 0.0204, G Loss: 5.3234; D Loss Real: 0.0055, ; D Loss Fake: 0.0149, \n",
      "Epoch [258/300], Step [200/234], D Loss: 0.0256, G Loss: 5.9309; D Loss Real: 0.0015, ; D Loss Fake: 0.0241, \n",
      "Epoch [258/300], Step [220/234], D Loss: 0.0013, G Loss: 8.0594; D Loss Real: 0.0007, ; D Loss Fake: 0.0006, \n",
      "Epoch [259/300], Step [20/234], D Loss: 0.0018, G Loss: 9.8155; D Loss Real: 0.0011, ; D Loss Fake: 0.0008, \n",
      "Epoch [259/300], Step [40/234], D Loss: 0.0724, G Loss: 6.6197; D Loss Real: 0.0114, ; D Loss Fake: 0.0610, \n",
      "Epoch [259/300], Step [60/234], D Loss: 0.0092, G Loss: 9.3697; D Loss Real: 0.0084, ; D Loss Fake: 0.0008, \n",
      "Epoch [259/300], Step [80/234], D Loss: 0.0103, G Loss: 6.1800; D Loss Real: 0.0003, ; D Loss Fake: 0.0100, \n",
      "Epoch [259/300], Step [100/234], D Loss: 0.0265, G Loss: 6.6735; D Loss Real: 0.0245, ; D Loss Fake: 0.0019, \n",
      "Epoch [259/300], Step [120/234], D Loss: 0.0019, G Loss: 6.9530; D Loss Real: 0.0003, ; D Loss Fake: 0.0016, \n",
      "Epoch [259/300], Step [140/234], D Loss: 0.0083, G Loss: 11.4798; D Loss Real: 0.0083, ; D Loss Fake: 0.0000, \n",
      "Epoch [259/300], Step [160/234], D Loss: 0.0082, G Loss: 5.9917; D Loss Real: 0.0031, ; D Loss Fake: 0.0051, \n",
      "Epoch [259/300], Step [180/234], D Loss: 0.0098, G Loss: 15.0409; D Loss Real: 0.0098, ; D Loss Fake: 0.0000, \n",
      "Epoch [259/300], Step [200/234], D Loss: 0.0312, G Loss: 5.6918; D Loss Real: 0.0240, ; D Loss Fake: 0.0071, \n",
      "Epoch [259/300], Step [220/234], D Loss: 0.0063, G Loss: 6.1768; D Loss Real: 0.0018, ; D Loss Fake: 0.0046, \n",
      "Epoch [260/300], Step [20/234], D Loss: 0.0007, G Loss: 16.4290; D Loss Real: 0.0007, ; D Loss Fake: 0.0000, \n",
      "Epoch [260/300], Step [40/234], D Loss: 0.0584, G Loss: 5.6678; D Loss Real: 0.0017, ; D Loss Fake: 0.0568, \n",
      "Epoch [260/300], Step [60/234], D Loss: 0.0136, G Loss: 6.8490; D Loss Real: 0.0063, ; D Loss Fake: 0.0074, \n",
      "Epoch [260/300], Step [80/234], D Loss: 0.0118, G Loss: 5.5956; D Loss Real: 0.0014, ; D Loss Fake: 0.0104, \n",
      "Epoch [260/300], Step [100/234], D Loss: 0.0340, G Loss: 6.9234; D Loss Real: 0.0019, ; D Loss Fake: 0.0321, \n",
      "Epoch [260/300], Step [120/234], D Loss: 0.0438, G Loss: 5.5555; D Loss Real: 0.0017, ; D Loss Fake: 0.0420, \n",
      "Epoch [260/300], Step [140/234], D Loss: 0.0109, G Loss: 8.1340; D Loss Real: 0.0106, ; D Loss Fake: 0.0002, \n",
      "Epoch [260/300], Step [160/234], D Loss: 0.0038, G Loss: 11.4734; D Loss Real: 0.0037, ; D Loss Fake: 0.0000, \n",
      "Epoch [260/300], Step [180/234], D Loss: 0.0003, G Loss: 13.3189; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [260/300], Step [200/234], D Loss: 0.0221, G Loss: 6.6710; D Loss Real: 0.0000, ; D Loss Fake: 0.0221, \n",
      "Epoch [260/300], Step [220/234], D Loss: 0.0031, G Loss: 7.0881; D Loss Real: 0.0017, ; D Loss Fake: 0.0014, \n",
      "Epoch [261/300], Step [20/234], D Loss: 0.0730, G Loss: 7.3003; D Loss Real: 0.0723, ; D Loss Fake: 0.0007, \n",
      "Epoch [261/300], Step [40/234], D Loss: 0.0354, G Loss: 11.3582; D Loss Real: 0.0354, ; D Loss Fake: 0.0001, \n",
      "Epoch [261/300], Step [60/234], D Loss: 0.0107, G Loss: 7.7100; D Loss Real: 0.0100, ; D Loss Fake: 0.0008, \n",
      "Epoch [261/300], Step [80/234], D Loss: 0.0012, G Loss: 9.1281; D Loss Real: 0.0011, ; D Loss Fake: 0.0002, \n",
      "Epoch [261/300], Step [100/234], D Loss: 0.0048, G Loss: 7.5828; D Loss Real: 0.0019, ; D Loss Fake: 0.0029, \n",
      "Epoch [261/300], Step [120/234], D Loss: 0.0005, G Loss: 14.0700; D Loss Real: 0.0000, ; D Loss Fake: 0.0005, \n",
      "Epoch [261/300], Step [140/234], D Loss: 0.0228, G Loss: 9.9963; D Loss Real: 0.0222, ; D Loss Fake: 0.0005, \n",
      "Epoch [261/300], Step [160/234], D Loss: 0.0089, G Loss: 6.5865; D Loss Real: 0.0040, ; D Loss Fake: 0.0049, \n",
      "Epoch [261/300], Step [180/234], D Loss: 0.0083, G Loss: 5.7213; D Loss Real: 0.0011, ; D Loss Fake: 0.0072, \n",
      "Epoch [261/300], Step [200/234], D Loss: 0.0073, G Loss: -0.0057; D Loss Real: 0.0001, ; D Loss Fake: 0.0071, \n",
      "Epoch [261/300], Step [220/234], D Loss: 0.0092, G Loss: 5.8304; D Loss Real: 0.0017, ; D Loss Fake: 0.0075, \n",
      "Epoch [262/300], Step [20/234], D Loss: 0.0155, G Loss: 11.1299; D Loss Real: 0.0153, ; D Loss Fake: 0.0002, \n",
      "Epoch [262/300], Step [40/234], D Loss: 0.0152, G Loss: 9.6668; D Loss Real: 0.0146, ; D Loss Fake: 0.0006, \n",
      "Epoch [262/300], Step [60/234], D Loss: 0.0138, G Loss: 7.2227; D Loss Real: 0.0128, ; D Loss Fake: 0.0010, \n",
      "Epoch [262/300], Step [80/234], D Loss: 0.0117, G Loss: 7.1667; D Loss Real: 0.0004, ; D Loss Fake: 0.0113, \n",
      "Epoch [262/300], Step [100/234], D Loss: 0.0066, G Loss: 9.7641; D Loss Real: 0.0047, ; D Loss Fake: 0.0020, \n",
      "Epoch [262/300], Step [120/234], D Loss: 0.0137, G Loss: 8.9019; D Loss Real: 0.0135, ; D Loss Fake: 0.0001, \n",
      "Epoch [262/300], Step [140/234], D Loss: 0.0045, G Loss: 11.2307; D Loss Real: 0.0045, ; D Loss Fake: 0.0000, \n",
      "Epoch [262/300], Step [160/234], D Loss: 0.0504, G Loss: 5.4648; D Loss Real: 0.0258, ; D Loss Fake: 0.0246, \n",
      "Epoch [262/300], Step [180/234], D Loss: 0.0697, G Loss: 6.6213; D Loss Real: 0.0316, ; D Loss Fake: 0.0381, \n",
      "Epoch [262/300], Step [200/234], D Loss: 0.0017, G Loss: 9.4682; D Loss Real: 0.0016, ; D Loss Fake: 0.0001, \n",
      "Epoch [262/300], Step [220/234], D Loss: 0.0128, G Loss: 11.2339; D Loss Real: 0.0128, ; D Loss Fake: 0.0000, \n",
      "Epoch [263/300], Step [20/234], D Loss: 0.1497, G Loss: 11.1821; D Loss Real: 0.1494, ; D Loss Fake: 0.0003, \n",
      "Epoch [263/300], Step [40/234], D Loss: 0.0049, G Loss: 7.5449; D Loss Real: 0.0037, ; D Loss Fake: 0.0011, \n",
      "Epoch [263/300], Step [60/234], D Loss: 0.0844, G Loss: 6.9832; D Loss Real: 0.0783, ; D Loss Fake: 0.0061, \n",
      "Epoch [263/300], Step [80/234], D Loss: 0.0060, G Loss: 5.5415; D Loss Real: 0.0001, ; D Loss Fake: 0.0060, \n",
      "Epoch [263/300], Step [100/234], D Loss: 0.0822, G Loss: 4.8854; D Loss Real: 0.0303, ; D Loss Fake: 0.0519, \n",
      "Epoch [263/300], Step [120/234], D Loss: 0.0086, G Loss: 7.8375; D Loss Real: 0.0043, ; D Loss Fake: 0.0043, \n",
      "Epoch [263/300], Step [140/234], D Loss: 0.0015, G Loss: 9.7747; D Loss Real: 0.0013, ; D Loss Fake: 0.0001, \n",
      "Epoch [263/300], Step [160/234], D Loss: 0.0072, G Loss: 7.4559; D Loss Real: 0.0056, ; D Loss Fake: 0.0016, \n",
      "Epoch [263/300], Step [180/234], D Loss: 0.0068, G Loss: -0.0019; D Loss Real: 0.0001, ; D Loss Fake: 0.0067, \n",
      "Epoch [263/300], Step [200/234], D Loss: 0.0039, G Loss: 7.3136; D Loss Real: 0.0021, ; D Loss Fake: 0.0018, \n",
      "Epoch [263/300], Step [220/234], D Loss: 0.0172, G Loss: 6.0260; D Loss Real: 0.0003, ; D Loss Fake: 0.0169, \n",
      "Epoch [264/300], Step [20/234], D Loss: 0.0047, G Loss: 12.1004; D Loss Real: 0.0047, ; D Loss Fake: 0.0000, \n",
      "Epoch [264/300], Step [40/234], D Loss: 0.2749, G Loss: -0.0006; D Loss Real: 0.2749, ; D Loss Fake: 0.0000, \n",
      "Epoch [264/300], Step [60/234], D Loss: 0.0033, G Loss: 9.8917; D Loss Real: 0.0032, ; D Loss Fake: 0.0001, \n",
      "Epoch [264/300], Step [80/234], D Loss: 0.0031, G Loss: 8.4867; D Loss Real: 0.0026, ; D Loss Fake: 0.0005, \n",
      "Epoch [264/300], Step [100/234], D Loss: 0.0243, G Loss: 6.2044; D Loss Real: 0.0216, ; D Loss Fake: 0.0027, \n",
      "Epoch [264/300], Step [120/234], D Loss: 0.2751, G Loss: 9.1894; D Loss Real: 0.0175, ; D Loss Fake: 0.2576, \n",
      "Epoch [264/300], Step [140/234], D Loss: 0.0068, G Loss: 8.5431; D Loss Real: 0.0065, ; D Loss Fake: 0.0003, \n",
      "Epoch [264/300], Step [160/234], D Loss: 0.0477, G Loss: 0.0113; D Loss Real: 0.0000, ; D Loss Fake: 0.0477, \n",
      "Epoch [264/300], Step [180/234], D Loss: 0.0033, G Loss: 8.5697; D Loss Real: 0.0022, ; D Loss Fake: 0.0012, \n",
      "Epoch [264/300], Step [200/234], D Loss: 0.0028, G Loss: 16.3864; D Loss Real: 0.0028, ; D Loss Fake: 0.0000, \n",
      "Epoch [264/300], Step [220/234], D Loss: 0.0427, G Loss: 0.0072; D Loss Real: 0.0389, ; D Loss Fake: 0.0039, \n",
      "Epoch [265/300], Step [20/234], D Loss: 0.0014, G Loss: 9.7188; D Loss Real: 0.0014, ; D Loss Fake: 0.0001, \n",
      "Epoch [265/300], Step [40/234], D Loss: 0.0136, G Loss: 13.5020; D Loss Real: 0.0136, ; D Loss Fake: 0.0000, \n",
      "Epoch [265/300], Step [60/234], D Loss: 0.0463, G Loss: 7.0926; D Loss Real: 0.0454, ; D Loss Fake: 0.0009, \n",
      "Epoch [265/300], Step [100/234], D Loss: 0.0425, G Loss: 6.7888; D Loss Real: 0.0420, ; D Loss Fake: 0.0005, \n",
      "Epoch [265/300], Step [80/234], D Loss: 0.0169, G Loss: 8.4407; D Loss Real: 0.0166, ; D Loss Fake: 0.0003, \n",
      "Epoch [265/300], Step [120/234], D Loss: 0.0003, G Loss: 17.6834; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [265/300], Step [140/234], D Loss: 0.0274, G Loss: 8.9371; D Loss Real: 0.0272, ; D Loss Fake: 0.0002, \n",
      "Epoch [265/300], Step [160/234], D Loss: 0.0007, G Loss: 0.0044; D Loss Real: 0.0006, ; D Loss Fake: 0.0001, \n",
      "Epoch [265/300], Step [180/234], D Loss: 0.0011, G Loss: 0.0021; D Loss Real: 0.0008, ; D Loss Fake: 0.0002, \n",
      "Epoch [265/300], Step [200/234], D Loss: 0.0012, G Loss: 7.9849; D Loss Real: 0.0008, ; D Loss Fake: 0.0004, \n",
      "Epoch [265/300], Step [220/234], D Loss: 0.0065, G Loss: 14.2137; D Loss Real: 0.0065, ; D Loss Fake: 0.0000, \n",
      "Epoch [266/300], Step [20/234], D Loss: 0.0209, G Loss: 17.1224; D Loss Real: 0.0209, ; D Loss Fake: 0.0000, \n",
      "Epoch [266/300], Step [40/234], D Loss: 0.0347, G Loss: 6.2769; D Loss Real: 0.0287, ; D Loss Fake: 0.0060, \n",
      "Epoch [266/300], Step [60/234], D Loss: 0.0046, G Loss: 7.6768; D Loss Real: 0.0010, ; D Loss Fake: 0.0036, \n",
      "Epoch [266/300], Step [80/234], D Loss: 0.0060, G Loss: 10.3763; D Loss Real: 0.0059, ; D Loss Fake: 0.0000, \n",
      "Epoch [266/300], Step [100/234], D Loss: 0.0060, G Loss: 6.5686; D Loss Real: 0.0048, ; D Loss Fake: 0.0012, \n",
      "Epoch [266/300], Step [120/234], D Loss: 0.0049, G Loss: 6.5374; D Loss Real: 0.0001, ; D Loss Fake: 0.0048, \n",
      "Epoch [266/300], Step [140/234], D Loss: 0.0065, G Loss: 11.3942; D Loss Real: 0.0065, ; D Loss Fake: 0.0000, \n",
      "Epoch [266/300], Step [160/234], D Loss: 0.4564, G Loss: 16.9346; D Loss Real: 0.0028, ; D Loss Fake: 0.4536, \n",
      "Epoch [266/300], Step [180/234], D Loss: 0.0105, G Loss: 5.9867; D Loss Real: 0.0034, ; D Loss Fake: 0.0071, \n",
      "Epoch [266/300], Step [200/234], D Loss: 0.0219, G Loss: 6.4070; D Loss Real: 0.0202, ; D Loss Fake: 0.0016, \n",
      "Epoch [266/300], Step [220/234], D Loss: 0.0002, G Loss: 0.0013; D Loss Real: 0.0000, ; D Loss Fake: 0.0001, \n",
      "Epoch [267/300], Step [20/234], D Loss: 0.0019, G Loss: 6.7238; D Loss Real: 0.0001, ; D Loss Fake: 0.0018, \n",
      "Epoch [267/300], Step [40/234], D Loss: 0.0070, G Loss: 6.2113; D Loss Real: 0.0015, ; D Loss Fake: 0.0055, \n",
      "Epoch [267/300], Step [60/234], D Loss: 0.0006, G Loss: 10.4605; D Loss Real: 0.0005, ; D Loss Fake: 0.0000, \n",
      "Epoch [267/300], Step [80/234], D Loss: 0.0343, G Loss: 8.2959; D Loss Real: 0.0342, ; D Loss Fake: 0.0001, \n",
      "Epoch [267/300], Step [100/234], D Loss: 0.0160, G Loss: 12.2530; D Loss Real: 0.0160, ; D Loss Fake: 0.0000, \n",
      "Epoch [267/300], Step [120/234], D Loss: 0.0148, G Loss: 5.4502; D Loss Real: 0.0003, ; D Loss Fake: 0.0145, \n",
      "Epoch [267/300], Step [140/234], D Loss: 0.0086, G Loss: 10.1797; D Loss Real: 0.0085, ; D Loss Fake: 0.0000, \n",
      "Epoch [267/300], Step [160/234], D Loss: 0.0948, G Loss: 7.5962; D Loss Real: 0.0007, ; D Loss Fake: 0.0941, \n",
      "Epoch [267/300], Step [180/234], D Loss: 0.0042, G Loss: 10.0642; D Loss Real: 0.0039, ; D Loss Fake: 0.0003, \n",
      "Epoch [267/300], Step [200/234], D Loss: 0.0004, G Loss: 8.8843; D Loss Real: 0.0001, ; D Loss Fake: 0.0003, \n",
      "Epoch [267/300], Step [220/234], D Loss: 0.1815, G Loss: 7.4315; D Loss Real: 0.0005, ; D Loss Fake: 0.1810, \n",
      "Epoch [268/300], Step [20/234], D Loss: 0.0176, G Loss: 8.6713; D Loss Real: 0.0173, ; D Loss Fake: 0.0003, \n",
      "Epoch [268/300], Step [40/234], D Loss: 0.0333, G Loss: 5.7612; D Loss Real: 0.0112, ; D Loss Fake: 0.0221, \n",
      "Epoch [268/300], Step [60/234], D Loss: 0.0054, G Loss: 13.1064; D Loss Real: 0.0054, ; D Loss Fake: 0.0000, \n",
      "Epoch [268/300], Step [80/234], D Loss: 0.0045, G Loss: 7.5009; D Loss Real: 0.0025, ; D Loss Fake: 0.0020, \n",
      "Epoch [268/300], Step [100/234], D Loss: 0.0011, G Loss: -0.0038; D Loss Real: 0.0001, ; D Loss Fake: 0.0010, \n",
      "Epoch [268/300], Step [120/234], D Loss: 0.0035, G Loss: 6.5414; D Loss Real: 0.0008, ; D Loss Fake: 0.0027, \n",
      "Epoch [268/300], Step [140/234], D Loss: 0.0499, G Loss: 5.5831; D Loss Real: 0.0354, ; D Loss Fake: 0.0145, \n",
      "Epoch [268/300], Step [160/234], D Loss: 0.0008, G Loss: 8.9819; D Loss Real: 0.0007, ; D Loss Fake: 0.0001, \n",
      "Epoch [268/300], Step [180/234], D Loss: 0.0177, G Loss: 5.5191; D Loss Real: 0.0036, ; D Loss Fake: 0.0141, \n",
      "Epoch [268/300], Step [200/234], D Loss: 0.0532, G Loss: 4.8039; D Loss Real: 0.0376, ; D Loss Fake: 0.0157, \n",
      "Epoch [268/300], Step [220/234], D Loss: 0.0050, G Loss: 7.7689; D Loss Real: 0.0047, ; D Loss Fake: 0.0003, \n",
      "Epoch [269/300], Step [20/234], D Loss: 0.0045, G Loss: 11.6164; D Loss Real: 0.0040, ; D Loss Fake: 0.0005, \n",
      "Epoch [269/300], Step [40/234], D Loss: 0.0007, G Loss: 14.3256; D Loss Real: 0.0007, ; D Loss Fake: 0.0000, \n",
      "Epoch [269/300], Step [60/234], D Loss: 0.0012, G Loss: 10.6268; D Loss Real: 0.0011, ; D Loss Fake: 0.0001, \n",
      "Epoch [269/300], Step [80/234], D Loss: 0.1128, G Loss: 11.5061; D Loss Real: 0.1128, ; D Loss Fake: 0.0000, \n",
      "Epoch [269/300], Step [100/234], D Loss: 0.0006, G Loss: 10.3904; D Loss Real: 0.0004, ; D Loss Fake: 0.0002, \n",
      "Epoch [269/300], Step [120/234], D Loss: 0.0737, G Loss: 7.0678; D Loss Real: 0.0101, ; D Loss Fake: 0.0635, \n",
      "Epoch [269/300], Step [140/234], D Loss: 0.0088, G Loss: 10.1013; D Loss Real: 0.0087, ; D Loss Fake: 0.0001, \n",
      "Epoch [269/300], Step [160/234], D Loss: 0.0055, G Loss: 6.5554; D Loss Real: 0.0041, ; D Loss Fake: 0.0014, \n",
      "Epoch [269/300], Step [180/234], D Loss: 0.0126, G Loss: 10.9722; D Loss Real: 0.0125, ; D Loss Fake: 0.0001, \n",
      "Epoch [269/300], Step [200/234], D Loss: 0.0010, G Loss: 8.6253; D Loss Real: 0.0007, ; D Loss Fake: 0.0002, \n",
      "Epoch [269/300], Step [220/234], D Loss: 0.0038, G Loss: 10.1169; D Loss Real: 0.0037, ; D Loss Fake: 0.0001, \n",
      "Epoch [270/300], Step [20/234], D Loss: 0.1873, G Loss: 14.0276; D Loss Real: 0.1872, ; D Loss Fake: 0.0001, \n",
      "Epoch [270/300], Step [40/234], D Loss: 0.0059, G Loss: 6.3721; D Loss Real: 0.0036, ; D Loss Fake: 0.0023, \n",
      "Epoch [270/300], Step [60/234], D Loss: 0.0165, G Loss: 5.4533; D Loss Real: 0.0016, ; D Loss Fake: 0.0150, \n",
      "Epoch [270/300], Step [80/234], D Loss: 0.0086, G Loss: 6.7701; D Loss Real: 0.0017, ; D Loss Fake: 0.0069, \n",
      "Epoch [270/300], Step [100/234], D Loss: 0.0144, G Loss: 12.7201; D Loss Real: 0.0144, ; D Loss Fake: 0.0000, \n",
      "Epoch [270/300], Step [120/234], D Loss: 0.0590, G Loss: 4.6923; D Loss Real: 0.0430, ; D Loss Fake: 0.0160, \n",
      "Epoch [270/300], Step [140/234], D Loss: 0.0071, G Loss: 5.6969; D Loss Real: 0.0029, ; D Loss Fake: 0.0042, \n",
      "Epoch [270/300], Step [160/234], D Loss: 0.0285, G Loss: 5.7901; D Loss Real: 0.0012, ; D Loss Fake: 0.0273, \n",
      "Epoch [270/300], Step [180/234], D Loss: 0.0086, G Loss: 0.0080; D Loss Real: 0.0022, ; D Loss Fake: 0.0064, \n",
      "Epoch [270/300], Step [200/234], D Loss: 0.0135, G Loss: 7.4238; D Loss Real: 0.0129, ; D Loss Fake: 0.0006, \n",
      "Epoch [270/300], Step [220/234], D Loss: 0.0265, G Loss: 6.4843; D Loss Real: 0.0216, ; D Loss Fake: 0.0049, \n",
      "Epoch [271/300], Step [20/234], D Loss: 0.6253, G Loss: 8.1187; D Loss Real: 0.0001, ; D Loss Fake: 0.6252, \n",
      "Epoch [271/300], Step [40/234], D Loss: 0.0088, G Loss: 7.2500; D Loss Real: 0.0019, ; D Loss Fake: 0.0068, \n",
      "Epoch [271/300], Step [60/234], D Loss: 0.0661, G Loss: 8.4374; D Loss Real: 0.0089, ; D Loss Fake: 0.0571, \n",
      "Epoch [271/300], Step [80/234], D Loss: 0.0520, G Loss: 6.0778; D Loss Real: 0.0503, ; D Loss Fake: 0.0017, \n",
      "Epoch [271/300], Step [100/234], D Loss: 0.1098, G Loss: 6.9438; D Loss Real: 0.0008, ; D Loss Fake: 0.1090, \n",
      "Epoch [271/300], Step [120/234], D Loss: 0.0160, G Loss: 5.3802; D Loss Real: 0.0021, ; D Loss Fake: 0.0138, \n",
      "Epoch [271/300], Step [140/234], D Loss: 0.0035, G Loss: 7.2313; D Loss Real: 0.0031, ; D Loss Fake: 0.0005, \n",
      "Epoch [271/300], Step [160/234], D Loss: 0.0572, G Loss: 0.0079; D Loss Real: 0.0542, ; D Loss Fake: 0.0030, \n",
      "Epoch [271/300], Step [180/234], D Loss: 0.0061, G Loss: -0.0142; D Loss Real: 0.0060, ; D Loss Fake: 0.0002, \n",
      "Epoch [271/300], Step [200/234], D Loss: 0.0017, G Loss: 8.6781; D Loss Real: 0.0015, ; D Loss Fake: 0.0002, \n",
      "Epoch [271/300], Step [220/234], D Loss: 0.0304, G Loss: 7.4707; D Loss Real: 0.0263, ; D Loss Fake: 0.0042, \n",
      "Epoch [272/300], Step [20/234], D Loss: 0.0102, G Loss: 9.0390; D Loss Real: 0.0028, ; D Loss Fake: 0.0074, \n",
      "Epoch [272/300], Step [40/234], D Loss: 0.0625, G Loss: 10.6451; D Loss Real: 0.0625, ; D Loss Fake: 0.0000, \n",
      "Epoch [272/300], Step [60/234], D Loss: 0.0007, G Loss: 8.7741; D Loss Real: 0.0004, ; D Loss Fake: 0.0003, \n",
      "Epoch [272/300], Step [80/234], D Loss: 0.0389, G Loss: 6.3191; D Loss Real: 0.0023, ; D Loss Fake: 0.0365, \n",
      "Epoch [272/300], Step [100/234], D Loss: 0.0046, G Loss: 15.2258; D Loss Real: 0.0046, ; D Loss Fake: 0.0000, \n",
      "Epoch [272/300], Step [120/234], D Loss: 0.0026, G Loss: 9.2099; D Loss Real: 0.0017, ; D Loss Fake: 0.0009, \n",
      "Epoch [272/300], Step [140/234], D Loss: 0.0190, G Loss: 0.0024; D Loss Real: 0.0135, ; D Loss Fake: 0.0055, \n",
      "Epoch [272/300], Step [160/234], D Loss: 0.0320, G Loss: 6.9523; D Loss Real: 0.0091, ; D Loss Fake: 0.0229, \n",
      "Epoch [272/300], Step [180/234], D Loss: 0.0007, G Loss: 10.7851; D Loss Real: 0.0005, ; D Loss Fake: 0.0002, \n",
      "Epoch [272/300], Step [200/234], D Loss: 0.0081, G Loss: 7.5510; D Loss Real: 0.0040, ; D Loss Fake: 0.0041, \n",
      "Epoch [272/300], Step [220/234], D Loss: 0.0205, G Loss: 5.1943; D Loss Real: 0.0005, ; D Loss Fake: 0.0200, \n",
      "Epoch [273/300], Step [20/234], D Loss: 0.0077, G Loss: 7.1516; D Loss Real: 0.0001, ; D Loss Fake: 0.0076, \n",
      "Epoch [273/300], Step [40/234], D Loss: 0.0130, G Loss: 8.5850; D Loss Real: 0.0050, ; D Loss Fake: 0.0080, \n",
      "Epoch [273/300], Step [60/234], D Loss: 0.0032, G Loss: 10.2123; D Loss Real: 0.0032, ; D Loss Fake: 0.0001, \n",
      "Epoch [273/300], Step [80/234], D Loss: 0.0005, G Loss: 10.5611; D Loss Real: 0.0004, ; D Loss Fake: 0.0000, \n",
      "Epoch [273/300], Step [100/234], D Loss: 0.0341, G Loss: 9.3634; D Loss Real: 0.0340, ; D Loss Fake: 0.0001, \n",
      "Epoch [273/300], Step [120/234], D Loss: 0.0111, G Loss: 7.7901; D Loss Real: 0.0108, ; D Loss Fake: 0.0003, \n",
      "Epoch [273/300], Step [140/234], D Loss: 0.0433, G Loss: 6.1949; D Loss Real: 0.0014, ; D Loss Fake: 0.0419, \n",
      "Epoch [273/300], Step [160/234], D Loss: 0.0001, G Loss: 10.6244; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [273/300], Step [180/234], D Loss: 0.0688, G Loss: 7.1897; D Loss Real: 0.0003, ; D Loss Fake: 0.0686, \n",
      "Epoch [273/300], Step [200/234], D Loss: 0.0003, G Loss: 10.9348; D Loss Real: 0.0003, ; D Loss Fake: 0.0000, \n",
      "Epoch [273/300], Step [220/234], D Loss: 0.0076, G Loss: 6.5608; D Loss Real: 0.0031, ; D Loss Fake: 0.0045, \n",
      "Epoch [274/300], Step [20/234], D Loss: 0.0124, G Loss: 13.9183; D Loss Real: 0.0124, ; D Loss Fake: 0.0000, \n",
      "Epoch [274/300], Step [40/234], D Loss: 0.0068, G Loss: 0.0102; D Loss Real: 0.0009, ; D Loss Fake: 0.0058, \n",
      "Epoch [274/300], Step [60/234], D Loss: 0.0202, G Loss: 6.8916; D Loss Real: 0.0017, ; D Loss Fake: 0.0185, \n",
      "Epoch [274/300], Step [80/234], D Loss: 0.0021, G Loss: 8.2026; D Loss Real: 0.0000, ; D Loss Fake: 0.0021, \n",
      "Epoch [274/300], Step [100/234], D Loss: 0.0070, G Loss: 6.6423; D Loss Real: 0.0020, ; D Loss Fake: 0.0050, \n",
      "Epoch [274/300], Step [120/234], D Loss: 0.0008, G Loss: 7.9318; D Loss Real: 0.0003, ; D Loss Fake: 0.0005, \n",
      "Epoch [274/300], Step [140/234], D Loss: 0.0148, G Loss: 4.9678; D Loss Real: 0.0002, ; D Loss Fake: 0.0146, \n",
      "Epoch [274/300], Step [160/234], D Loss: 0.0352, G Loss: 9.9297; D Loss Real: 0.0351, ; D Loss Fake: 0.0000, \n",
      "Epoch [274/300], Step [180/234], D Loss: 0.0269, G Loss: 6.0803; D Loss Real: 0.0001, ; D Loss Fake: 0.0268, \n",
      "Epoch [274/300], Step [200/234], D Loss: 0.0058, G Loss: 6.8691; D Loss Real: 0.0013, ; D Loss Fake: 0.0045, \n",
      "Epoch [274/300], Step [220/234], D Loss: 0.0009, G Loss: 7.8192; D Loss Real: 0.0003, ; D Loss Fake: 0.0006, \n",
      "Epoch [275/300], Step [20/234], D Loss: 0.0085, G Loss: 20.1492; D Loss Real: 0.0085, ; D Loss Fake: -0.0000, \n",
      "Epoch [275/300], Step [40/234], D Loss: 0.0199, G Loss: 6.5313; D Loss Real: 0.0130, ; D Loss Fake: 0.0069, \n",
      "Epoch [275/300], Step [60/234], D Loss: 0.0064, G Loss: 6.6386; D Loss Real: 0.0044, ; D Loss Fake: 0.0020, \n",
      "Epoch [275/300], Step [80/234], D Loss: 0.0043, G Loss: 14.3090; D Loss Real: 0.0043, ; D Loss Fake: 0.0000, \n",
      "Epoch [275/300], Step [100/234], D Loss: 0.0016, G Loss: 0.0151; D Loss Real: 0.0014, ; D Loss Fake: 0.0002, \n",
      "Epoch [275/300], Step [120/234], D Loss: 0.0012, G Loss: 8.0497; D Loss Real: 0.0006, ; D Loss Fake: 0.0006, \n",
      "Epoch [275/300], Step [140/234], D Loss: 0.0278, G Loss: 11.6516; D Loss Real: 0.0278, ; D Loss Fake: 0.0000, \n",
      "Epoch [275/300], Step [160/234], D Loss: 0.0705, G Loss: 7.1636; D Loss Real: 0.0664, ; D Loss Fake: 0.0041, \n",
      "Epoch [275/300], Step [180/234], D Loss: 0.0617, G Loss: 8.5973; D Loss Real: 0.0013, ; D Loss Fake: 0.0604, \n",
      "Epoch [275/300], Step [200/234], D Loss: 0.0363, G Loss: 5.8149; D Loss Real: 0.0100, ; D Loss Fake: 0.0263, \n",
      "Epoch [275/300], Step [220/234], D Loss: 0.0431, G Loss: 6.3635; D Loss Real: 0.0033, ; D Loss Fake: 0.0398, \n",
      "Epoch [276/300], Step [20/234], D Loss: 0.0080, G Loss: -0.0033; D Loss Real: 0.0069, ; D Loss Fake: 0.0011, \n",
      "Epoch [276/300], Step [40/234], D Loss: 0.0007, G Loss: 10.5372; D Loss Real: 0.0005, ; D Loss Fake: 0.0002, \n",
      "Epoch [276/300], Step [60/234], D Loss: 0.1724, G Loss: 10.6782; D Loss Real: 0.0013, ; D Loss Fake: 0.1712, \n",
      "Epoch [276/300], Step [80/234], D Loss: 0.0075, G Loss: 7.0679; D Loss Real: 0.0015, ; D Loss Fake: 0.0060, \n",
      "Epoch [276/300], Step [100/234], D Loss: 0.0016, G Loss: 11.1483; D Loss Real: 0.0016, ; D Loss Fake: 0.0000, \n",
      "Epoch [276/300], Step [120/234], D Loss: 0.0204, G Loss: 8.3887; D Loss Real: 0.0169, ; D Loss Fake: 0.0035, \n",
      "Epoch [276/300], Step [140/234], D Loss: 0.0061, G Loss: 6.0704; D Loss Real: 0.0028, ; D Loss Fake: 0.0033, \n",
      "Epoch [276/300], Step [160/234], D Loss: 0.0130, G Loss: 5.4389; D Loss Real: 0.0034, ; D Loss Fake: 0.0096, \n",
      "Epoch [276/300], Step [180/234], D Loss: 0.0031, G Loss: 10.5661; D Loss Real: 0.0031, ; D Loss Fake: 0.0000, \n",
      "Epoch [276/300], Step [200/234], D Loss: 0.0099, G Loss: 6.1855; D Loss Real: 0.0019, ; D Loss Fake: 0.0081, \n",
      "Epoch [276/300], Step [220/234], D Loss: 0.0016, G Loss: 9.5369; D Loss Real: 0.0016, ; D Loss Fake: 0.0001, \n",
      "Epoch [277/300], Step [20/234], D Loss: 0.0460, G Loss: 17.9771; D Loss Real: 0.0460, ; D Loss Fake: 0.0000, \n",
      "Epoch [277/300], Step [40/234], D Loss: 0.0004, G Loss: 8.9316; D Loss Real: 0.0002, ; D Loss Fake: 0.0002, \n",
      "Epoch [277/300], Step [60/234], D Loss: 0.0055, G Loss: 7.7895; D Loss Real: 0.0036, ; D Loss Fake: 0.0018, \n",
      "Epoch [277/300], Step [80/234], D Loss: 0.0041, G Loss: 8.2452; D Loss Real: 0.0037, ; D Loss Fake: 0.0003, \n",
      "Epoch [277/300], Step [100/234], D Loss: 0.0025, G Loss: 0.0176; D Loss Real: 0.0022, ; D Loss Fake: 0.0004, \n",
      "Epoch [277/300], Step [120/234], D Loss: 0.0132, G Loss: 10.3139; D Loss Real: 0.0131, ; D Loss Fake: 0.0000, \n",
      "Epoch [277/300], Step [140/234], D Loss: 0.0332, G Loss: 5.9066; D Loss Real: 0.0067, ; D Loss Fake: 0.0265, \n",
      "Epoch [277/300], Step [160/234], D Loss: 0.0109, G Loss: 6.2664; D Loss Real: 0.0061, ; D Loss Fake: 0.0047, \n",
      "Epoch [277/300], Step [180/234], D Loss: 0.0086, G Loss: 6.9527; D Loss Real: 0.0075, ; D Loss Fake: 0.0011, \n",
      "Epoch [277/300], Step [200/234], D Loss: 0.0007, G Loss: 8.3595; D Loss Real: 0.0003, ; D Loss Fake: 0.0003, \n",
      "Epoch [277/300], Step [220/234], D Loss: 0.0061, G Loss: 6.0855; D Loss Real: 0.0031, ; D Loss Fake: 0.0031, \n",
      "Epoch [278/300], Step [20/234], D Loss: 0.0082, G Loss: 11.9682; D Loss Real: 0.0081, ; D Loss Fake: 0.0001, \n",
      "Epoch [278/300], Step [40/234], D Loss: 0.3887, G Loss: 11.5986; D Loss Real: 0.0056, ; D Loss Fake: 0.3830, \n",
      "Epoch [278/300], Step [60/234], D Loss: 0.0042, G Loss: 7.2168; D Loss Real: 0.0007, ; D Loss Fake: 0.0036, \n",
      "Epoch [278/300], Step [80/234], D Loss: 0.1660, G Loss: 13.3868; D Loss Real: 0.1660, ; D Loss Fake: 0.0000, \n",
      "Epoch [278/300], Step [100/234], D Loss: 0.0858, G Loss: 14.1964; D Loss Real: 0.0858, ; D Loss Fake: 0.0000, \n",
      "Epoch [278/300], Step [120/234], D Loss: 0.0053, G Loss: 10.0221; D Loss Real: 0.0052, ; D Loss Fake: 0.0000, \n",
      "Epoch [278/300], Step [140/234], D Loss: 0.0469, G Loss: 14.2042; D Loss Real: 0.0469, ; D Loss Fake: 0.0000, \n",
      "Epoch [278/300], Step [160/234], D Loss: 0.0096, G Loss: -0.0038; D Loss Real: 0.0084, ; D Loss Fake: 0.0012, \n",
      "Epoch [278/300], Step [180/234], D Loss: 0.0047, G Loss: 7.3614; D Loss Real: 0.0024, ; D Loss Fake: 0.0022, \n",
      "Epoch [278/300], Step [200/234], D Loss: 0.0176, G Loss: 9.7909; D Loss Real: 0.0175, ; D Loss Fake: 0.0001, \n",
      "Epoch [278/300], Step [220/234], D Loss: 0.0521, G Loss: 5.5802; D Loss Real: 0.0018, ; D Loss Fake: 0.0503, \n",
      "Epoch [279/300], Step [20/234], D Loss: 0.0015, G Loss: 7.1900; D Loss Real: 0.0000, ; D Loss Fake: 0.0015, \n",
      "Epoch [279/300], Step [40/234], D Loss: 0.0017, G Loss: 9.0224; D Loss Real: 0.0011, ; D Loss Fake: 0.0006, \n",
      "Epoch [279/300], Step [60/234], D Loss: 0.0034, G Loss: 6.5849; D Loss Real: 0.0019, ; D Loss Fake: 0.0014, \n",
      "Epoch [279/300], Step [80/234], D Loss: 0.0159, G Loss: 5.0800; D Loss Real: 0.0008, ; D Loss Fake: 0.0152, \n",
      "Epoch [279/300], Step [100/234], D Loss: 0.0246, G Loss: 5.4417; D Loss Real: 0.0203, ; D Loss Fake: 0.0042, \n",
      "Epoch [279/300], Step [120/234], D Loss: 0.0063, G Loss: 10.8030; D Loss Real: 0.0062, ; D Loss Fake: 0.0000, \n",
      "Epoch [279/300], Step [140/234], D Loss: 0.0046, G Loss: 7.9610; D Loss Real: 0.0028, ; D Loss Fake: 0.0018, \n",
      "Epoch [279/300], Step [160/234], D Loss: 0.0766, G Loss: 10.9311; D Loss Real: 0.0766, ; D Loss Fake: 0.0000, \n",
      "Epoch [279/300], Step [180/234], D Loss: 0.0019, G Loss: 0.0145; D Loss Real: 0.0019, ; D Loss Fake: 0.0000, \n",
      "Epoch [279/300], Step [200/234], D Loss: 0.0081, G Loss: 12.9917; D Loss Real: 0.0080, ; D Loss Fake: 0.0000, \n",
      "Epoch [279/300], Step [220/234], D Loss: 0.0035, G Loss: 7.1647; D Loss Real: 0.0017, ; D Loss Fake: 0.0018, \n",
      "Epoch [280/300], Step [20/234], D Loss: 0.0039, G Loss: 13.6315; D Loss Real: 0.0039, ; D Loss Fake: 0.0000, \n",
      "Epoch [280/300], Step [40/234], D Loss: 0.0302, G Loss: 6.9518; D Loss Real: 0.0019, ; D Loss Fake: 0.0284, \n",
      "Epoch [280/300], Step [60/234], D Loss: 0.0254, G Loss: 8.2510; D Loss Real: 0.0249, ; D Loss Fake: 0.0005, \n",
      "Epoch [280/300], Step [80/234], D Loss: 0.1047, G Loss: 7.7769; D Loss Real: 0.0001, ; D Loss Fake: 0.1046, \n",
      "Epoch [280/300], Step [100/234], D Loss: 0.0013, G Loss: 10.6501; D Loss Real: 0.0012, ; D Loss Fake: 0.0001, \n",
      "Epoch [280/300], Step [120/234], D Loss: 0.0195, G Loss: -0.0032; D Loss Real: 0.0192, ; D Loss Fake: 0.0003, \n",
      "Epoch [280/300], Step [140/234], D Loss: 0.0219, G Loss: 5.7771; D Loss Real: 0.0165, ; D Loss Fake: 0.0054, \n",
      "Epoch [280/300], Step [160/234], D Loss: 0.0136, G Loss: 6.9527; D Loss Real: 0.0113, ; D Loss Fake: 0.0023, \n",
      "Epoch [280/300], Step [180/234], D Loss: 0.0015, G Loss: 14.2995; D Loss Real: 0.0015, ; D Loss Fake: 0.0000, \n",
      "Epoch [280/300], Step [200/234], D Loss: 0.0001, G Loss: 10.6227; D Loss Real: 0.0000, ; D Loss Fake: 0.0001, \n",
      "Epoch [280/300], Step [220/234], D Loss: 0.0031, G Loss: 11.0861; D Loss Real: 0.0031, ; D Loss Fake: 0.0000, \n",
      "Epoch [281/300], Step [20/234], D Loss: 0.0039, G Loss: 8.9387; D Loss Real: 0.0003, ; D Loss Fake: 0.0036, \n",
      "Epoch [281/300], Step [40/234], D Loss: 0.0147, G Loss: 6.2160; D Loss Real: 0.0003, ; D Loss Fake: 0.0144, \n",
      "Epoch [281/300], Step [60/234], D Loss: 0.0109, G Loss: 12.4134; D Loss Real: 0.0109, ; D Loss Fake: 0.0000, \n",
      "Epoch [281/300], Step [80/234], D Loss: 0.0130, G Loss: 5.4113; D Loss Real: 0.0009, ; D Loss Fake: 0.0121, \n",
      "Epoch [281/300], Step [100/234], D Loss: 0.0046, G Loss: 8.5677; D Loss Real: 0.0042, ; D Loss Fake: 0.0004, \n",
      "Epoch [281/300], Step [120/234], D Loss: 0.0138, G Loss: 7.1548; D Loss Real: 0.0122, ; D Loss Fake: 0.0016, \n",
      "Epoch [281/300], Step [140/234], D Loss: 0.0179, G Loss: 9.0007; D Loss Real: 0.0165, ; D Loss Fake: 0.0014, \n",
      "Epoch [281/300], Step [160/234], D Loss: 0.0123, G Loss: 7.9162; D Loss Real: 0.0117, ; D Loss Fake: 0.0007, \n",
      "Epoch [281/300], Step [180/234], D Loss: 0.0024, G Loss: 7.1718; D Loss Real: 0.0015, ; D Loss Fake: 0.0009, \n",
      "Epoch [281/300], Step [200/234], D Loss: 0.0139, G Loss: 10.2641; D Loss Real: 0.0139, ; D Loss Fake: 0.0001, \n",
      "Epoch [281/300], Step [220/234], D Loss: 0.0056, G Loss: 0.0029; D Loss Real: 0.0056, ; D Loss Fake: 0.0000, \n",
      "Epoch [282/300], Step [20/234], D Loss: 0.0227, G Loss: 7.5188; D Loss Real: 0.0223, ; D Loss Fake: 0.0004, \n",
      "Epoch [282/300], Step [40/234], D Loss: 0.0002, G Loss: 12.3845; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [282/300], Step [60/234], D Loss: 0.0105, G Loss: 0.0034; D Loss Real: 0.0038, ; D Loss Fake: 0.0067, \n",
      "Epoch [282/300], Step [80/234], D Loss: 0.0111, G Loss: -0.0006; D Loss Real: 0.0111, ; D Loss Fake: 0.0000, \n",
      "Epoch [282/300], Step [100/234], D Loss: 0.0146, G Loss: 5.6719; D Loss Real: 0.0042, ; D Loss Fake: 0.0104, \n",
      "Epoch [282/300], Step [120/234], D Loss: 0.0006, G Loss: 10.7287; D Loss Real: 0.0006, ; D Loss Fake: 0.0000, \n",
      "Epoch [282/300], Step [140/234], D Loss: 0.0020, G Loss: 7.4140; D Loss Real: 0.0004, ; D Loss Fake: 0.0016, \n",
      "Epoch [282/300], Step [160/234], D Loss: 0.0133, G Loss: 5.4412; D Loss Real: 0.0003, ; D Loss Fake: 0.0129, \n",
      "Epoch [282/300], Step [180/234], D Loss: 0.0028, G Loss: 8.8993; D Loss Real: 0.0017, ; D Loss Fake: 0.0011, \n",
      "Epoch [282/300], Step [200/234], D Loss: 0.0729, G Loss: 5.2290; D Loss Real: 0.0465, ; D Loss Fake: 0.0263, \n",
      "Epoch [282/300], Step [220/234], D Loss: 0.0012, G Loss: 14.4557; D Loss Real: 0.0012, ; D Loss Fake: 0.0000, \n",
      "Epoch [283/300], Step [20/234], D Loss: 0.1481, G Loss: 7.6262; D Loss Real: 0.0230, ; D Loss Fake: 0.1252, \n",
      "Epoch [283/300], Step [40/234], D Loss: 0.0005, G Loss: 11.3816; D Loss Real: 0.0005, ; D Loss Fake: 0.0001, \n",
      "Epoch [283/300], Step [60/234], D Loss: 0.0125, G Loss: 7.9792; D Loss Real: 0.0001, ; D Loss Fake: 0.0124, \n",
      "Epoch [283/300], Step [80/234], D Loss: 0.0471, G Loss: 7.0021; D Loss Real: 0.0457, ; D Loss Fake: 0.0014, \n",
      "Epoch [283/300], Step [100/234], D Loss: 0.0069, G Loss: 11.7052; D Loss Real: 0.0069, ; D Loss Fake: 0.0000, \n",
      "Epoch [283/300], Step [120/234], D Loss: 0.0050, G Loss: 6.4767; D Loss Real: 0.0011, ; D Loss Fake: 0.0039, \n",
      "Epoch [283/300], Step [140/234], D Loss: 0.0241, G Loss: 9.4210; D Loss Real: 0.0240, ; D Loss Fake: 0.0002, \n",
      "Epoch [283/300], Step [160/234], D Loss: 0.0303, G Loss: 4.9558; D Loss Real: 0.0249, ; D Loss Fake: 0.0054, \n",
      "Epoch [283/300], Step [180/234], D Loss: 0.0110, G Loss: 10.3414; D Loss Real: 0.0108, ; D Loss Fake: 0.0002, \n",
      "Epoch [283/300], Step [200/234], D Loss: 0.0095, G Loss: 15.1512; D Loss Real: 0.0095, ; D Loss Fake: 0.0000, \n",
      "Epoch [283/300], Step [220/234], D Loss: 0.0065, G Loss: 5.8639; D Loss Real: 0.0018, ; D Loss Fake: 0.0047, \n",
      "Epoch [284/300], Step [20/234], D Loss: 0.0106, G Loss: 0.0188; D Loss Real: 0.0011, ; D Loss Fake: 0.0094, \n",
      "Epoch [284/300], Step [40/234], D Loss: 0.0043, G Loss: 7.4005; D Loss Real: 0.0000, ; D Loss Fake: 0.0043, \n",
      "Epoch [284/300], Step [60/234], D Loss: 0.0039, G Loss: 12.1157; D Loss Real: 0.0039, ; D Loss Fake: 0.0000, \n",
      "Epoch [284/300], Step [80/234], D Loss: 0.0027, G Loss: 7.5256; D Loss Real: 0.0022, ; D Loss Fake: 0.0005, \n",
      "Epoch [284/300], Step [100/234], D Loss: 0.0009, G Loss: 0.0001; D Loss Real: 0.0009, ; D Loss Fake: 0.0000, \n",
      "Epoch [284/300], Step [120/234], D Loss: 0.0136, G Loss: 8.1306; D Loss Real: 0.0117, ; D Loss Fake: 0.0018, \n",
      "Epoch [284/300], Step [140/234], D Loss: 0.0105, G Loss: 5.4816; D Loss Real: 0.0010, ; D Loss Fake: 0.0096, \n",
      "Epoch [284/300], Step [160/234], D Loss: 0.0129, G Loss: 9.5749; D Loss Real: 0.0128, ; D Loss Fake: 0.0001, \n",
      "Epoch [284/300], Step [180/234], D Loss: 0.0140, G Loss: 6.1163; D Loss Real: 0.0005, ; D Loss Fake: 0.0136, \n",
      "Epoch [284/300], Step [200/234], D Loss: 0.0368, G Loss: 5.7831; D Loss Real: 0.0013, ; D Loss Fake: 0.0356, \n",
      "Epoch [284/300], Step [220/234], D Loss: 0.0339, G Loss: 5.8262; D Loss Real: 0.0127, ; D Loss Fake: 0.0212, \n",
      "Epoch [285/300], Step [20/234], D Loss: 0.2607, G Loss: 12.1981; D Loss Real: 0.2607, ; D Loss Fake: 0.0000, \n",
      "Epoch [285/300], Step [40/234], D Loss: 0.0239, G Loss: 7.3972; D Loss Real: 0.0060, ; D Loss Fake: 0.0179, \n",
      "Epoch [285/300], Step [60/234], D Loss: 0.0019, G Loss: 9.8500; D Loss Real: 0.0017, ; D Loss Fake: 0.0002, \n",
      "Epoch [285/300], Step [80/234], D Loss: 0.0084, G Loss: 4.9716; D Loss Real: 0.0013, ; D Loss Fake: 0.0071, \n",
      "Epoch [285/300], Step [100/234], D Loss: 0.0095, G Loss: 13.1654; D Loss Real: 0.0095, ; D Loss Fake: 0.0000, \n",
      "Epoch [285/300], Step [120/234], D Loss: 0.0312, G Loss: 4.9572; D Loss Real: 0.0216, ; D Loss Fake: 0.0096, \n",
      "Epoch [285/300], Step [140/234], D Loss: 0.0006, G Loss: 11.2615; D Loss Real: 0.0005, ; D Loss Fake: 0.0000, \n",
      "Epoch [285/300], Step [160/234], D Loss: 0.0020, G Loss: 7.5638; D Loss Real: 0.0006, ; D Loss Fake: 0.0014, \n",
      "Epoch [285/300], Step [180/234], D Loss: 0.0049, G Loss: 6.4295; D Loss Real: 0.0023, ; D Loss Fake: 0.0026, \n",
      "Epoch [285/300], Step [200/234], D Loss: 0.0036, G Loss: 6.3069; D Loss Real: 0.0019, ; D Loss Fake: 0.0017, \n",
      "Epoch [285/300], Step [220/234], D Loss: 0.0365, G Loss: 5.3958; D Loss Real: 0.0002, ; D Loss Fake: 0.0363, \n",
      "Epoch [286/300], Step [20/234], D Loss: 0.0203, G Loss: 10.8811; D Loss Real: 0.0188, ; D Loss Fake: 0.0015, \n",
      "Epoch [286/300], Step [40/234], D Loss: 0.0106, G Loss: 7.9112; D Loss Real: 0.0083, ; D Loss Fake: 0.0024, \n",
      "Epoch [286/300], Step [60/234], D Loss: 0.0088, G Loss: 7.8397; D Loss Real: 0.0077, ; D Loss Fake: 0.0011, \n",
      "Epoch [286/300], Step [80/234], D Loss: 0.0240, G Loss: 6.3127; D Loss Real: 0.0014, ; D Loss Fake: 0.0226, \n",
      "Epoch [286/300], Step [100/234], D Loss: 0.0076, G Loss: 12.0890; D Loss Real: 0.0076, ; D Loss Fake: 0.0000, \n",
      "Epoch [286/300], Step [120/234], D Loss: 0.0444, G Loss: 6.2632; D Loss Real: 0.0427, ; D Loss Fake: 0.0017, \n",
      "Epoch [286/300], Step [140/234], D Loss: 0.0018, G Loss: 18.1146; D Loss Real: 0.0018, ; D Loss Fake: -0.0000, \n",
      "Epoch [286/300], Step [160/234], D Loss: 0.0026, G Loss: 15.2784; D Loss Real: 0.0026, ; D Loss Fake: 0.0000, \n",
      "Epoch [286/300], Step [180/234], D Loss: 0.0086, G Loss: 6.2275; D Loss Real: 0.0058, ; D Loss Fake: 0.0028, \n",
      "Epoch [286/300], Step [200/234], D Loss: 0.0006, G Loss: 10.0864; D Loss Real: 0.0006, ; D Loss Fake: 0.0000, \n",
      "Epoch [286/300], Step [220/234], D Loss: 0.0017, G Loss: 12.1297; D Loss Real: 0.0017, ; D Loss Fake: 0.0000, \n",
      "Epoch [287/300], Step [20/234], D Loss: 0.0025, G Loss: 9.3647; D Loss Real: 0.0020, ; D Loss Fake: 0.0005, \n",
      "Epoch [287/300], Step [40/234], D Loss: 0.0106, G Loss: -0.0075; D Loss Real: 0.0063, ; D Loss Fake: 0.0043, \n",
      "Epoch [287/300], Step [60/234], D Loss: 0.0036, G Loss: 12.1506; D Loss Real: 0.0036, ; D Loss Fake: 0.0000, \n",
      "Epoch [287/300], Step [80/234], D Loss: 0.0005, G Loss: 13.6585; D Loss Real: 0.0005, ; D Loss Fake: 0.0000, \n",
      "Epoch [287/300], Step [100/234], D Loss: 0.0173, G Loss: 5.3069; D Loss Real: 0.0015, ; D Loss Fake: 0.0158, \n",
      "Epoch [287/300], Step [120/234], D Loss: 0.0032, G Loss: 9.1817; D Loss Real: 0.0030, ; D Loss Fake: 0.0002, \n",
      "Epoch [287/300], Step [140/234], D Loss: 0.0055, G Loss: 6.0864; D Loss Real: 0.0004, ; D Loss Fake: 0.0051, \n",
      "Epoch [287/300], Step [160/234], D Loss: 0.1020, G Loss: 6.3374; D Loss Real: 0.0075, ; D Loss Fake: 0.0946, \n",
      "Epoch [287/300], Step [180/234], D Loss: 0.0001, G Loss: 11.2678; D Loss Real: 0.0001, ; D Loss Fake: 0.0000, \n",
      "Epoch [287/300], Step [200/234], D Loss: 0.0024, G Loss: 7.2152; D Loss Real: 0.0002, ; D Loss Fake: 0.0021, \n",
      "Epoch [287/300], Step [220/234], D Loss: 0.0314, G Loss: 0.0125; D Loss Real: 0.0001, ; D Loss Fake: 0.0314, \n",
      "Epoch [288/300], Step [20/234], D Loss: 0.0059, G Loss: 9.4223; D Loss Real: 0.0002, ; D Loss Fake: 0.0057, \n",
      "Epoch [288/300], Step [40/234], D Loss: 0.0276, G Loss: 8.6984; D Loss Real: 0.0256, ; D Loss Fake: 0.0020, \n",
      "Epoch [288/300], Step [60/234], D Loss: 0.0046, G Loss: 6.4284; D Loss Real: 0.0004, ; D Loss Fake: 0.0042, \n",
      "Epoch [288/300], Step [80/234], D Loss: 0.0083, G Loss: 5.5773; D Loss Real: 0.0004, ; D Loss Fake: 0.0079, \n",
      "Epoch [288/300], Step [100/234], D Loss: 0.0013, G Loss: 8.5686; D Loss Real: 0.0011, ; D Loss Fake: 0.0002, \n",
      "Epoch [288/300], Step [120/234], D Loss: 0.0185, G Loss: -0.0205; D Loss Real: 0.0185, ; D Loss Fake: 0.0000, \n",
      "Epoch [288/300], Step [140/234], D Loss: 0.0067, G Loss: -0.0063; D Loss Real: 0.0066, ; D Loss Fake: 0.0000, \n",
      "Epoch [288/300], Step [160/234], D Loss: 0.0077, G Loss: 5.9041; D Loss Real: 0.0012, ; D Loss Fake: 0.0065, \n",
      "Epoch [288/300], Step [180/234], D Loss: 0.0592, G Loss: 11.0660; D Loss Real: 0.0592, ; D Loss Fake: 0.0001, \n",
      "Epoch [288/300], Step [200/234], D Loss: 0.0324, G Loss: 13.3327; D Loss Real: 0.0324, ; D Loss Fake: 0.0000, \n",
      "Epoch [288/300], Step [220/234], D Loss: 0.0137, G Loss: 5.6446; D Loss Real: 0.0071, ; D Loss Fake: 0.0065, \n",
      "Epoch [289/300], Step [20/234], D Loss: 0.0035, G Loss: -0.0027; D Loss Real: 0.0035, ; D Loss Fake: 0.0001, \n",
      "Epoch [289/300], Step [40/234], D Loss: 0.0087, G Loss: 7.5894; D Loss Real: 0.0066, ; D Loss Fake: 0.0021, \n",
      "Epoch [289/300], Step [60/234], D Loss: 0.0026, G Loss: 7.4350; D Loss Real: 0.0019, ; D Loss Fake: 0.0007, \n",
      "Epoch [289/300], Step [80/234], D Loss: 0.0035, G Loss: 7.3466; D Loss Real: 0.0024, ; D Loss Fake: 0.0011, \n",
      "Epoch [289/300], Step [100/234], D Loss: 0.0096, G Loss: 7.5776; D Loss Real: 0.0029, ; D Loss Fake: 0.0068, \n",
      "Epoch [289/300], Step [120/234], D Loss: 0.0033, G Loss: 7.9269; D Loss Real: 0.0027, ; D Loss Fake: 0.0006, \n",
      "Epoch [289/300], Step [140/234], D Loss: 0.0173, G Loss: -0.0136; D Loss Real: 0.0160, ; D Loss Fake: 0.0013, \n",
      "Epoch [289/300], Step [160/234], D Loss: 0.0032, G Loss: 12.0452; D Loss Real: 0.0032, ; D Loss Fake: 0.0000, \n",
      "Epoch [289/300], Step [180/234], D Loss: 0.0120, G Loss: -0.0041; D Loss Real: 0.0095, ; D Loss Fake: 0.0025, \n",
      "Epoch [289/300], Step [200/234], D Loss: 0.0194, G Loss: 18.8706; D Loss Real: 0.0194, ; D Loss Fake: 0.0000, \n",
      "Epoch [289/300], Step [220/234], D Loss: 0.1246, G Loss: 0.0037; D Loss Real: 0.0012, ; D Loss Fake: 0.1234, \n",
      "Epoch [290/300], Step [20/234], D Loss: 0.0053, G Loss: 14.8076; D Loss Real: 0.0053, ; D Loss Fake: 0.0000, \n",
      "Epoch [290/300], Step [40/234], D Loss: 0.0003, G Loss: 0.0053; D Loss Real: 0.0002, ; D Loss Fake: 0.0001, \n",
      "Epoch [290/300], Step [60/234], D Loss: 0.0065, G Loss: 0.0055; D Loss Real: 0.0063, ; D Loss Fake: 0.0002, \n",
      "Epoch [290/300], Step [80/234], D Loss: 0.0115, G Loss: 6.8489; D Loss Real: 0.0086, ; D Loss Fake: 0.0029, \n",
      "Epoch [290/300], Step [100/234], D Loss: 0.0018, G Loss: 0.0039; D Loss Real: 0.0012, ; D Loss Fake: 0.0006, \n",
      "Epoch [290/300], Step [120/234], D Loss: 0.0001, G Loss: 11.5859; D Loss Real: 0.0000, ; D Loss Fake: 0.0000, \n",
      "Epoch [290/300], Step [140/234], D Loss: 0.0014, G Loss: 7.4486; D Loss Real: 0.0002, ; D Loss Fake: 0.0013, \n",
      "Epoch [290/300], Step [160/234], D Loss: 0.0015, G Loss: 8.5098; D Loss Real: 0.0002, ; D Loss Fake: 0.0013, \n",
      "Epoch [290/300], Step [180/234], D Loss: 0.0015, G Loss: 0.0081; D Loss Real: 0.0007, ; D Loss Fake: 0.0007, \n",
      "Epoch [290/300], Step [200/234], D Loss: 0.0010, G Loss: 10.8545; D Loss Real: 0.0010, ; D Loss Fake: 0.0000, \n",
      "Epoch [290/300], Step [220/234], D Loss: 0.0169, G Loss: 0.0005; D Loss Real: 0.0020, ; D Loss Fake: 0.0149, \n",
      "Epoch [291/300], Step [20/234], D Loss: 0.0626, G Loss: 9.1872; D Loss Real: 0.0029, ; D Loss Fake: 0.0597, \n",
      "Epoch [291/300], Step [40/234], D Loss: 0.0008, G Loss: 13.8854; D Loss Real: 0.0008, ; D Loss Fake: 0.0000, \n",
      "Epoch [291/300], Step [60/234], D Loss: 0.0111, G Loss: 6.7376; D Loss Real: 0.0011, ; D Loss Fake: 0.0100, \n",
      "Epoch [291/300], Step [80/234], D Loss: 0.0125, G Loss: 15.0319; D Loss Real: 0.0125, ; D Loss Fake: 0.0000, \n",
      "Epoch [291/300], Step [100/234], D Loss: 0.0093, G Loss: 6.5575; D Loss Real: 0.0070, ; D Loss Fake: 0.0023, \n",
      "Epoch [291/300], Step [120/234], D Loss: 0.0246, G Loss: 8.2283; D Loss Real: 0.0035, ; D Loss Fake: 0.0211, \n",
      "Epoch [291/300], Step [140/234], D Loss: 0.0826, G Loss: -0.0001; D Loss Real: 0.0826, ; D Loss Fake: 0.0000, \n",
      "Epoch [291/300], Step [160/234], D Loss: 0.0123, G Loss: 6.4367; D Loss Real: 0.0015, ; D Loss Fake: 0.0109, \n",
      "Epoch [291/300], Step [180/234], D Loss: 0.1793, G Loss: 10.2083; D Loss Real: 0.0094, ; D Loss Fake: 0.1700, \n",
      "Epoch [291/300], Step [200/234], D Loss: 0.0063, G Loss: 6.0695; D Loss Real: 0.0036, ; D Loss Fake: 0.0027, \n",
      "Epoch [291/300], Step [220/234], D Loss: 0.0008, G Loss: 10.5324; D Loss Real: 0.0008, ; D Loss Fake: 0.0001, \n",
      "Epoch [292/300], Step [20/234], D Loss: 0.0083, G Loss: 8.6194; D Loss Real: 0.0058, ; D Loss Fake: 0.0025, \n",
      "Epoch [292/300], Step [40/234], D Loss: 0.0304, G Loss: 6.2620; D Loss Real: 0.0264, ; D Loss Fake: 0.0041, \n",
      "Epoch [292/300], Step [60/234], D Loss: 0.0843, G Loss: 5.4634; D Loss Real: 0.0766, ; D Loss Fake: 0.0076, \n",
      "Epoch [292/300], Step [80/234], D Loss: 0.0070, G Loss: 7.6897; D Loss Real: 0.0001, ; D Loss Fake: 0.0069, \n",
      "Epoch [292/300], Step [100/234], D Loss: 0.0006, G Loss: 0.0108; D Loss Real: 0.0005, ; D Loss Fake: 0.0001, \n",
      "Epoch [292/300], Step [120/234], D Loss: 0.0984, G Loss: 8.0864; D Loss Real: 0.0027, ; D Loss Fake: 0.0957, \n",
      "Epoch [292/300], Step [140/234], D Loss: 0.0045, G Loss: 7.9734; D Loss Real: 0.0036, ; D Loss Fake: 0.0009, \n",
      "Epoch [292/300], Step [160/234], D Loss: 0.0031, G Loss: 8.0584; D Loss Real: 0.0028, ; D Loss Fake: 0.0003, \n",
      "Epoch [292/300], Step [180/234], D Loss: 0.0568, G Loss: 5.5929; D Loss Real: 0.0025, ; D Loss Fake: 0.0543, \n",
      "Epoch [292/300], Step [200/234], D Loss: 0.0016, G Loss: 7.3316; D Loss Real: 0.0010, ; D Loss Fake: 0.0005, \n",
      "Epoch [292/300], Step [220/234], D Loss: 0.0151, G Loss: 6.5579; D Loss Real: 0.0123, ; D Loss Fake: 0.0028, \n",
      "Epoch [293/300], Step [20/234], D Loss: 0.0173, G Loss: 11.8574; D Loss Real: 0.0165, ; D Loss Fake: 0.0008, \n",
      "Epoch [293/300], Step [40/234], D Loss: 0.0035, G Loss: 9.3056; D Loss Real: 0.0031, ; D Loss Fake: 0.0004, \n",
      "Epoch [293/300], Step [60/234], D Loss: 0.3213, G Loss: 11.5000; D Loss Real: 0.0031, ; D Loss Fake: 0.3182, \n",
      "Epoch [293/300], Step [80/234], D Loss: 0.0518, G Loss: 7.7107; D Loss Real: 0.0458, ; D Loss Fake: 0.0060, \n",
      "Epoch [293/300], Step [100/234], D Loss: 0.0314, G Loss: -0.0214; D Loss Real: 0.0313, ; D Loss Fake: 0.0000, \n",
      "Epoch [293/300], Step [120/234], D Loss: 0.0003, G Loss: 9.4908; D Loss Real: 0.0002, ; D Loss Fake: 0.0001, \n",
      "Epoch [293/300], Step [140/234], D Loss: 0.0138, G Loss: 13.4606; D Loss Real: 0.0138, ; D Loss Fake: 0.0000, \n",
      "Epoch [293/300], Step [160/234], D Loss: 0.0724, G Loss: 7.2953; D Loss Real: 0.0075, ; D Loss Fake: 0.0648, \n",
      "Epoch [293/300], Step [180/234], D Loss: 0.0025, G Loss: 7.8101; D Loss Real: 0.0017, ; D Loss Fake: 0.0008, \n",
      "Epoch [293/300], Step [200/234], D Loss: 0.0319, G Loss: 5.6408; D Loss Real: 0.0263, ; D Loss Fake: 0.0056, \n",
      "Epoch [293/300], Step [220/234], D Loss: 0.0101, G Loss: 5.7997; D Loss Real: 0.0021, ; D Loss Fake: 0.0080, \n",
      "Epoch [294/300], Step [20/234], D Loss: 0.1862, G Loss: 20.8856; D Loss Real: 0.1862, ; D Loss Fake: 0.0000, \n",
      "Epoch [294/300], Step [40/234], D Loss: 0.0720, G Loss: 6.6495; D Loss Real: 0.0221, ; D Loss Fake: 0.0499, \n",
      "Epoch [294/300], Step [60/234], D Loss: 0.0779, G Loss: 0.0035; D Loss Real: 0.0023, ; D Loss Fake: 0.0756, \n",
      "Epoch [294/300], Step [80/234], D Loss: 0.0335, G Loss: 6.1666; D Loss Real: 0.0017, ; D Loss Fake: 0.0318, \n",
      "Epoch [294/300], Step [100/234], D Loss: 0.0069, G Loss: 8.4576; D Loss Real: 0.0063, ; D Loss Fake: 0.0007, \n",
      "Epoch [294/300], Step [120/234], D Loss: 0.0106, G Loss: 5.0223; D Loss Real: 0.0009, ; D Loss Fake: 0.0097, \n",
      "Epoch [294/300], Step [140/234], D Loss: 0.0761, G Loss: 4.9535; D Loss Real: 0.0665, ; D Loss Fake: 0.0096, \n",
      "Epoch [294/300], Step [160/234], D Loss: 0.0090, G Loss: 5.5351; D Loss Real: 0.0026, ; D Loss Fake: 0.0064, \n",
      "Epoch [294/300], Step [180/234], D Loss: 0.0040, G Loss: 7.9061; D Loss Real: 0.0024, ; D Loss Fake: 0.0016, \n",
      "Epoch [294/300], Step [200/234], D Loss: 0.0043, G Loss: 6.9858; D Loss Real: 0.0017, ; D Loss Fake: 0.0026, \n",
      "Epoch [294/300], Step [220/234], D Loss: 0.0085, G Loss: 6.5815; D Loss Real: 0.0065, ; D Loss Fake: 0.0020, \n",
      "Epoch [295/300], Step [20/234], D Loss: 0.0385, G Loss: 9.0415; D Loss Real: 0.0123, ; D Loss Fake: 0.0262, \n",
      "Epoch [295/300], Step [40/234], D Loss: 0.0006, G Loss: 8.3189; D Loss Real: 0.0005, ; D Loss Fake: 0.0002, \n",
      "Epoch [295/300], Step [60/234], D Loss: 0.0734, G Loss: 8.6835; D Loss Real: 0.0732, ; D Loss Fake: 0.0002, \n",
      "Epoch [295/300], Step [80/234], D Loss: 0.0087, G Loss: 5.9319; D Loss Real: 0.0007, ; D Loss Fake: 0.0080, \n",
      "Epoch [295/300], Step [100/234], D Loss: 0.0080, G Loss: 6.6905; D Loss Real: 0.0038, ; D Loss Fake: 0.0042, \n",
      "Epoch [295/300], Step [120/234], D Loss: 0.0096, G Loss: 0.0174; D Loss Real: 0.0093, ; D Loss Fake: 0.0003, \n",
      "Epoch [295/300], Step [140/234], D Loss: 0.0097, G Loss: 6.7159; D Loss Real: 0.0035, ; D Loss Fake: 0.0061, \n",
      "Epoch [295/300], Step [160/234], D Loss: 0.0091, G Loss: 9.9888; D Loss Real: 0.0089, ; D Loss Fake: 0.0002, \n",
      "Epoch [295/300], Step [180/234], D Loss: 0.0345, G Loss: 5.4412; D Loss Real: 0.0010, ; D Loss Fake: 0.0335, \n",
      "Epoch [295/300], Step [200/234], D Loss: 0.0023, G Loss: 13.0258; D Loss Real: 0.0023, ; D Loss Fake: 0.0000, \n",
      "Epoch [295/300], Step [220/234], D Loss: 0.0522, G Loss: 7.1814; D Loss Real: 0.0518, ; D Loss Fake: 0.0004, \n",
      "Epoch [296/300], Step [20/234], D Loss: 0.0117, G Loss: 9.5220; D Loss Real: 0.0109, ; D Loss Fake: 0.0008, \n",
      "Epoch [296/300], Step [40/234], D Loss: 0.0020, G Loss: -0.0182; D Loss Real: 0.0019, ; D Loss Fake: 0.0001, \n",
      "Epoch [296/300], Step [60/234], D Loss: 0.0036, G Loss: 13.2961; D Loss Real: 0.0036, ; D Loss Fake: 0.0000, \n",
      "Epoch [296/300], Step [80/234], D Loss: 0.0111, G Loss: 7.0756; D Loss Real: 0.0102, ; D Loss Fake: 0.0009, \n",
      "Epoch [296/300], Step [100/234], D Loss: 0.0041, G Loss: 14.5349; D Loss Real: 0.0041, ; D Loss Fake: 0.0000, \n",
      "Epoch [296/300], Step [120/234], D Loss: 0.0081, G Loss: -0.0096; D Loss Real: 0.0002, ; D Loss Fake: 0.0079, \n",
      "Epoch [296/300], Step [140/234], D Loss: 0.0141, G Loss: 5.2986; D Loss Real: 0.0052, ; D Loss Fake: 0.0089, \n",
      "Epoch [296/300], Step [160/234], D Loss: 0.0017, G Loss: 8.9802; D Loss Real: 0.0013, ; D Loss Fake: 0.0003, \n",
      "Epoch [296/300], Step [180/234], D Loss: 0.0035, G Loss: 8.8994; D Loss Real: 0.0033, ; D Loss Fake: 0.0002, \n",
      "Epoch [296/300], Step [200/234], D Loss: 0.0077, G Loss: 0.0030; D Loss Real: 0.0034, ; D Loss Fake: 0.0043, \n",
      "Epoch [296/300], Step [220/234], D Loss: 0.0033, G Loss: 8.1668; D Loss Real: 0.0026, ; D Loss Fake: 0.0008, \n",
      "Epoch [297/300], Step [20/234], D Loss: 0.0128, G Loss: 11.0738; D Loss Real: 0.0128, ; D Loss Fake: 0.0000, \n",
      "Epoch [297/300], Step [40/234], D Loss: 0.0021, G Loss: 9.9887; D Loss Real: 0.0019, ; D Loss Fake: 0.0002, \n",
      "Epoch [297/300], Step [60/234], D Loss: 0.0077, G Loss: 10.8183; D Loss Real: 0.0077, ; D Loss Fake: 0.0000, \n",
      "Epoch [297/300], Step [80/234], D Loss: 0.0170, G Loss: 20.6069; D Loss Real: 0.0170, ; D Loss Fake: -0.0000, \n",
      "Epoch [297/300], Step [100/234], D Loss: 0.0083, G Loss: 9.5873; D Loss Real: 0.0082, ; D Loss Fake: 0.0001, \n",
      "Epoch [297/300], Step [120/234], D Loss: 0.0025, G Loss: 13.5499; D Loss Real: 0.0025, ; D Loss Fake: 0.0000, \n",
      "Epoch [297/300], Step [140/234], D Loss: 0.0225, G Loss: 7.7115; D Loss Real: 0.0223, ; D Loss Fake: 0.0002, \n",
      "Epoch [297/300], Step [160/234], D Loss: 0.0856, G Loss: 5.2572; D Loss Real: 0.0800, ; D Loss Fake: 0.0056, \n",
      "Epoch [297/300], Step [180/234], D Loss: 0.1336, G Loss: 7.7478; D Loss Real: 0.0086, ; D Loss Fake: 0.1250, \n",
      "Epoch [297/300], Step [200/234], D Loss: 0.0012, G Loss: 6.5148; D Loss Real: 0.0001, ; D Loss Fake: 0.0011, \n",
      "Epoch [297/300], Step [220/234], D Loss: 0.0013, G Loss: -0.0110; D Loss Real: 0.0013, ; D Loss Fake: 0.0000, \n",
      "Epoch [298/300], Step [20/234], D Loss: 0.1200, G Loss: 6.8988; D Loss Real: 0.0176, ; D Loss Fake: 0.1024, \n",
      "Epoch [298/300], Step [40/234], D Loss: 0.0056, G Loss: 6.6491; D Loss Real: 0.0040, ; D Loss Fake: 0.0017, \n",
      "Epoch [298/300], Step [60/234], D Loss: 0.0154, G Loss: 5.7968; D Loss Real: 0.0016, ; D Loss Fake: 0.0138, \n",
      "Epoch [298/300], Step [80/234], D Loss: 0.0167, G Loss: 0.0109; D Loss Real: 0.0032, ; D Loss Fake: 0.0135, \n",
      "Epoch [298/300], Step [100/234], D Loss: 0.0059, G Loss: 12.9683; D Loss Real: 0.0058, ; D Loss Fake: 0.0000, \n",
      "Epoch [298/300], Step [120/234], D Loss: 0.0006, G Loss: 9.2627; D Loss Real: 0.0004, ; D Loss Fake: 0.0002, \n",
      "Epoch [298/300], Step [140/234], D Loss: 0.0080, G Loss: 7.1252; D Loss Real: 0.0061, ; D Loss Fake: 0.0018, \n",
      "Epoch [298/300], Step [160/234], D Loss: 0.0128, G Loss: 14.6555; D Loss Real: 0.0128, ; D Loss Fake: 0.0000, \n",
      "Epoch [298/300], Step [180/234], D Loss: 0.9424, G Loss: 13.8840; D Loss Real: 0.9424, ; D Loss Fake: 0.0000, \n",
      "Epoch [298/300], Step [200/234], D Loss: 0.0006, G Loss: -0.0097; D Loss Real: 0.0006, ; D Loss Fake: 0.0000, \n",
      "Epoch [298/300], Step [220/234], D Loss: 0.0088, G Loss: 5.1591; D Loss Real: 0.0010, ; D Loss Fake: 0.0078, \n",
      "Epoch [299/300], Step [20/234], D Loss: 0.0012, G Loss: 0.0108; D Loss Real: 0.0012, ; D Loss Fake: 0.0000, \n",
      "Epoch [299/300], Step [40/234], D Loss: 0.0061, G Loss: 11.5806; D Loss Real: 0.0061, ; D Loss Fake: 0.0000, \n",
      "Epoch [299/300], Step [60/234], D Loss: 0.0061, G Loss: 7.9454; D Loss Real: 0.0031, ; D Loss Fake: 0.0030, \n",
      "Epoch [299/300], Step [80/234], D Loss: 0.0191, G Loss: 6.3022; D Loss Real: 0.0146, ; D Loss Fake: 0.0045, \n",
      "Epoch [299/300], Step [100/234], D Loss: 0.0043, G Loss: 8.1171; D Loss Real: 0.0038, ; D Loss Fake: 0.0006, \n",
      "Epoch [299/300], Step [120/234], D Loss: 0.0052, G Loss: 5.8047; D Loss Real: 0.0005, ; D Loss Fake: 0.0047, \n",
      "Epoch [299/300], Step [140/234], D Loss: 0.0397, G Loss: 7.9262; D Loss Real: 0.0395, ; D Loss Fake: 0.0002, \n",
      "Epoch [299/300], Step [160/234], D Loss: 0.0055, G Loss: -0.0067; D Loss Real: 0.0022, ; D Loss Fake: 0.0033, \n",
      "Epoch [299/300], Step [180/234], D Loss: 0.0008, G Loss: 8.0267; D Loss Real: 0.0004, ; D Loss Fake: 0.0004, \n",
      "Epoch [299/300], Step [200/234], D Loss: 0.0050, G Loss: 7.5332; D Loss Real: 0.0036, ; D Loss Fake: 0.0014, \n",
      "Epoch [299/300], Step [220/234], D Loss: 0.0256, G Loss: 14.0580; D Loss Real: 0.0255, ; D Loss Fake: 0.0001, \n",
      "Epoch [300/300], Step [20/234], D Loss: 0.0090, G Loss: 7.3518; D Loss Real: 0.0028, ; D Loss Fake: 0.0061, \n",
      "Epoch [300/300], Step [40/234], D Loss: 0.0007, G Loss: 8.6745; D Loss Real: 0.0005, ; D Loss Fake: 0.0002, \n",
      "Epoch [300/300], Step [60/234], D Loss: 0.0065, G Loss: 9.7704; D Loss Real: 0.0064, ; D Loss Fake: 0.0001, \n",
      "Epoch [300/300], Step [80/234], D Loss: 0.0357, G Loss: 8.2242; D Loss Real: 0.0335, ; D Loss Fake: 0.0023, \n",
      "Epoch [300/300], Step [100/234], D Loss: 0.0172, G Loss: 8.6916; D Loss Real: 0.0003, ; D Loss Fake: 0.0169, \n",
      "Epoch [300/300], Step [120/234], D Loss: 0.0069, G Loss: 10.8499; D Loss Real: 0.0068, ; D Loss Fake: 0.0002, \n",
      "Epoch [300/300], Step [140/234], D Loss: 0.0023, G Loss: 18.3379; D Loss Real: 0.0023, ; D Loss Fake: 0.0000, \n",
      "Epoch [300/300], Step [160/234], D Loss: 0.2167, G Loss: 13.5641; D Loss Real: 0.0009, ; D Loss Fake: 0.2158, \n",
      "Epoch [300/300], Step [180/234], D Loss: 0.0002, G Loss: 10.3009; D Loss Real: 0.0002, ; D Loss Fake: 0.0000, \n",
      "Epoch [300/300], Step [200/234], D Loss: 0.0010, G Loss: 8.8301; D Loss Real: 0.0007, ; D Loss Fake: 0.0002, \n",
      "Epoch [300/300], Step [220/234], D Loss: 0.0060, G Loss: 7.0217; D Loss Real: 0.0044, ; D Loss Fake: 0.0016, \n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:49:39.910416Z",
     "start_time": "2024-05-22T20:49:39.893891Z"
    }
   },
   "cell_type": "code",
   "source": "fake_images.shape",
   "id": "511314ac550caa2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 3, 64, 64])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:50:23.030628Z",
     "start_time": "2024-05-22T20:50:23.013603Z"
    }
   },
   "cell_type": "code",
   "source": "real_images.shape",
   "id": "e15ebebb6e19af35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 3, 64, 64])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_and_plot_images(n_images=9, epoch=0, plot=True):\n",
    "    \"\"\"\n",
    "    Generates and plots a grid of images using a trained generator model.\n",
    "\n",
    "    Parameters:\n",
    "    - generator: The trained generator model for generating images.\n",
    "    - device: The device (e.g., 'cuda' or 'cpu') the model should run on.\n",
    "    - n_images: The total number of images to generate and plot. Default is 9.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(9, 9))  # Create a 3x3 grid of subplots\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "    for i in range(n_images):\n",
    "        # Generate random noise\n",
    "        noise = torch.randn(1, 256, 1, 1, device=device) / 100\n",
    "\n",
    "        # Generate an image without updating gradients\n",
    "        with torch.no_grad():\n",
    "            generated_image = generator(noise)\n",
    "\n",
    "        # Process the image for visualization\n",
    "        generated_image = generated_image.to('cpu').clone().detach()\n",
    "        generated_image = generated_image.numpy().squeeze(0)\n",
    "\n",
    "        if generated_image.shape[0] == 3:  # Check if the image has 3 channels (RGB)\n",
    "            generated_image = generated_image.transpose(1, 2, 0)  # Convert from CxHxW to HxWxC\n",
    "            \n",
    "        elif generated_image.shape[0] == 1:  # Check if the image has 3 channels (RGB)\n",
    "            generated_image = generated_image.squeeze(0)  # Convert from CxHxW to HxWxC\n",
    "\n",
    "        # Normalize the image data to [0, 1]\n",
    "        generated_image = (generated_image + 1) / 2\n",
    "        generated_image = generated_image.clip(0, 1)  # Ensure pixel values are within the expected range\n",
    "\n",
    "        axes[i].imshow(generated_image, cmap='gray')\n",
    "        axes[i].axis('off')  # Turn off the axis to make the images look cleaner\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output/generated_images_grid_{epoch}.png')\n",
    "\n",
    "    if plot:\n",
    "        plt.show()\n"
   ],
   "id": "cce66bfde454b0f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T07:45:12.971386Z",
     "start_time": "2024-05-22T07:45:04.332888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    try:\n",
    "        for i, (real_images, _) in enumerate(dataloader):\n",
    "            real_images = real_images.to(device)\n",
    "            \n",
    "            # Labels for your batches\n",
    "            real_labels = torch.full((batch_size,), 0.9, device=device)  # Real labels smoothed to 0.9\n",
    "            # real_labels = torch.ones(real_images.size(0), device=device)\n",
    "            fake_labels = torch.zeros(real_images.size(0), device=device)\n",
    "        \n",
    "            ### Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            real_outputs = discriminator(real_images)\n",
    "            d_loss_real = criterion(real_outputs, real_labels)\n",
    "            d_loss_real.backward()\n",
    "        \n",
    "            noise = torch.randn(real_images.size(0), latent_size, 1, 1, device=device)\n",
    "            fake_images = generator(noise)\n",
    "            fake_outputs = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "            d_loss_fake.backward()\n",
    "            optimizer_D.step()\n",
    "        \n",
    "            ### Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            # Optionally regenerate fake images for freshness\n",
    "            noise = torch.randn(real_images.size(0), latent_size, 1, 1, device=device)\n",
    "            fake_images = generator(noise)\n",
    "            output = discriminator(fake_images)\n",
    "        \n",
    "            # Randomly decide whether to flip labels\n",
    "            if random.random() < flip_prob:\n",
    "                g_loss = criterion(output, fake_labels)  # Flipped labels\n",
    "            else:\n",
    "                g_loss = criterion(output, real_labels)  # Normal training\n",
    "        \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "    \n",
    "            if (i + 1) % 20 == 0:\n",
    "                d_losses.append(d_loss_real.item() + d_loss_fake.item())\n",
    "                g_losses.append(g_loss.item())\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], '\n",
    "                      f'D Loss: {d_loss_real.item() + d_loss_fake.item():.4f}, '\n",
    "                      f'G Loss: {g_loss.item():.4f}'\n",
    "                      f'; D Loss Real: {d_loss_real.item():.4f}, '\n",
    "                      f'; D Loss Fake: {d_loss_fake.item():.4f}, '\n",
    "                      )\n",
    "                \n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            # check_output(fake_images[0], epoch)\n",
    "            generate_and_plot_images(25, epoch=epoch, plot=False)\n",
    "            \n",
    "        if (epoch + 1) % 30 == 0:\n",
    "            checkpoint = {\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "                'epoch': epoch  # Optional, if you want to also save the epoch number\n",
    "            }\n",
    "            \n",
    "            torch.save(checkpoint, f'GAN_cat_{epoch}.pth')\n",
    "\n",
    "    except OSError:\n",
    "        print(f\"An error occurred while processing the image. Epoch: {epoch}, batch: {i}\")\n",
    "        continue\n"
   ],
   "id": "6701c6aa62fd5790",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [20/313], D Loss: 2.7489, G Loss: 5.7095; D Loss Real: 2.7414, ; D Loss Fake: 0.0075, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T14:16:26.918269Z",
     "start_time": "2024-05-21T14:16:26.813492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming 'generator' and 'discriminator' are your model instances\n",
    "# And 'optimizer_G' and 'optimizer_D' are the optimizers for the generator and discriminator respectively\n",
    "\n",
    "# Define checkpoint dictionary\n",
    "checkpoint = {\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'discriminator_state_dict': discriminator.state_dict(),\n",
    "    'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "    'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "    'epoch': epoch  # Optional, if you want to also save the epoch number\n",
    "}\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(checkpoint, f'GAN_checkpoint_main_128_{epoch}.pth')\n"
   ],
   "id": "61435395198a0aab",
   "outputs": [],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

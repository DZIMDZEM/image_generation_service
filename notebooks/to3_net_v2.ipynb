{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.091298Z",
     "start_time": "2024-06-03T09:35:28.491390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import datasets"
   ],
   "id": "b10883462b527219",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.106463Z",
     "start_time": "2024-06-03T09:35:34.094673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path to your dataset\n",
    "dataset_path = r'C:\\Users\\dzmit\\Downloads\\3d-objects\\2024-05-09_state\\tarin_3d\\images'"
   ],
   "id": "3f10b3d19164ed8c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "c856708d489aedb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.231533Z",
     "start_time": "2024-06-03T09:35:34.108459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize all images to 64x64\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)"
   ],
   "id": "ebdc6330df45d27b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.246848Z",
     "start_time": "2024-06-03T09:35:34.234517Z"
    }
   },
   "cell_type": "code",
   "source": "# dataset[0][0].shape",
   "id": "f2f2fa2a6eb066c3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.262051Z",
     "start_time": "2024-06-03T09:35:34.249556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path to your dataset\n",
    "targets_path = r'C:\\Users\\dzmit\\Downloads\\3d-objects\\2024-05-09_state\\tarin_3d\\scaled'"
   ],
   "id": "f647306a72e310b1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.385576Z",
     "start_time": "2024-06-03T09:35:34.266707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# transform_target = transforms.Compose([\n",
    "#     # transforms.Resize((64, 64)),  # Resize all images to 64x64\n",
    "#     # transforms.ToTensor(),\n",
    "#     # transforms.ToFloat(),\n",
    "#     # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "# ])\n",
    "\n",
    "def npy_loader(path):\n",
    "\n",
    "     # Load the data from a .npy file\n",
    "    sample = np.load(path)\n",
    "\n",
    "    # Convert the numpy array from int to float32\n",
    "    sample = sample.astype(np.float32)\n",
    "\n",
    "    # Convert numpy array to a PyTorch tensor\n",
    "    sample = torch.from_numpy(sample)\n",
    "\n",
    "    # Optionally, normalize the data here if required\n",
    "    # sample = (sample - sample.mean()) / sample.std()\n",
    "\n",
    "    return sample\n",
    "\n",
    "    # sample = torch.from_numpy(np.load(path))\n",
    "    # return sample\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "targets = datasets.DatasetFolder(root=targets_path, loader=npy_loader, extensions=['.npy'])"
   ],
   "id": "c7d441238732c7c2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.401286Z",
     "start_time": "2024-06-03T09:35:34.388558Z"
    }
   },
   "cell_type": "code",
   "source": "# targets[0][0]",
   "id": "9097d6f4814446f6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.417282Z",
     "start_time": "2024-06-03T09:35:34.404648Z"
    }
   },
   "cell_type": "code",
   "source": "len(targets)",
   "id": "eac56581d6689f93",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:35:34.432294Z",
     "start_time": "2024-06-03T09:35:34.420421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DataLoader\n",
    "batch_size = 24  # Batch size\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "targetloader = torch.utils.data.DataLoader(targets, batch_size=batch_size, shuffle=False)"
   ],
   "id": "460c215c96b56ded",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Architecture",
   "id": "3bf50b0eff34178b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T10:22:28.875361Z",
     "start_time": "2024-06-03T10:22:27.635886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class To3Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(To3Net, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.to3d = nn.ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=(0, 0, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 1, kernel_size=(2, 2, 2), stride=(1, 2, 2), padding=(1, 0, 0)),\n",
    "            nn.Sigmoid()  # Binary output via sigmoid activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.to3d(x))\n",
    "        x = x.unsqueeze(2)  # Add a depth dimension\n",
    "        x = x.expand(-1, -1, 32, -1, -1)  # Expand to [batch_size, 128, 8, 64, 64]\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n"
   ],
   "id": "9cd0e609b0d9e763",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device",
   "id": "e02790d7ef499666"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T08:11:17.009073Z",
     "start_time": "2024-05-10T08:11:16.991095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if CUDA is available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ],
   "id": "a2c6b74b77c58978",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:14:55.954709Z",
     "start_time": "2024-05-10T00:14:55.940809Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "e193b77c5f2fc5b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the model",
   "id": "b4a01cda95d1f5ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T10:22:31.150247Z",
     "start_time": "2024-06-03T10:22:31.132395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = To3Net()  #.to(device)\n",
    "# print(model)"
   ],
   "id": "47e95251fca331f6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T10:11:36.713987Z",
     "start_time": "2024-06-03T10:11:36.707969Z"
    }
   },
   "cell_type": "code",
   "source": "# dataset[0][0].unsqueeze(0).shape",
   "id": "6aac10332e74e7e5",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T10:11:36.977187Z",
     "start_time": "2024-06-03T10:11:36.964576Z"
    }
   },
   "cell_type": "code",
   "source": "# targets[0][0].unsqueeze(0).shape",
   "id": "1cd615b791359751",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model(dataset[0][0].unsqueeze(0)).shape",
   "id": "419c7988ee9997a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Logging function",
   "id": "9bb647428b303087"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:51:24.185540Z",
     "start_time": "2024-05-10T00:51:24.178187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import trimesh\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def check_output(generated_object, input_image, epoch=0):\n",
    "    generated_object = generated_object.to('cpu').clone().detach() # Move to CPU and detach from the computation graph\n",
    "    generated_object = (generated_object.numpy() > np.median(generated_object.numpy())).astype(np.uint8) # Convert to numpy array\n",
    "\n",
    "    # Save the mesh\n",
    "    voxel_mesh = trimesh.voxel.ops.matrix_to_marching_cubes(generated_object)\n",
    "    voxel_mesh.export(f'output/check_generated_object_{epoch}.obj')\n",
    "\n",
    "     # Normalize the image to [0, 1] if it's not already\n",
    "    image = input_image.to('cpu').clone().detach().numpy().transpose(1, 2, 0)\n",
    "    image = (image + 1) / 2  # Assuming that the output is in the range [-1, 1]\n",
    "    image = image.clip(0, 1)  # Ensure the values are within [0, 1]\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.savefig(f'output/check_generated_image_{epoch}.png')\n"
   ],
   "id": "4c0455a8c9cc8289",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:51:53.363028Z",
     "start_time": "2024-05-10T00:51:53.349195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00002, betas=(0.5, 0.999))\n",
    "# optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()"
   ],
   "id": "79e3ca6230018c26",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train loop",
   "id": "c093c7a855c4609"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:55:14.188229Z",
     "start_time": "2024-05-10T00:55:14.172222Z"
    }
   },
   "cell_type": "code",
   "source": "num_epochs = 500",
   "id": "11a1971908ad53d7",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T01:05:19.930648Z",
     "start_time": "2024-05-10T00:55:16.831511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(100, num_epochs):\n",
    "    try:\n",
    "        for i, ((images, _), (objects, _)) in enumerate(zip(dataloader, targetloader)):\n",
    "            # Move data to the appropriate device\n",
    "            images = images.to(device)\n",
    "            objects = objects.to(device)\n",
    "\n",
    "            ### Train Generator\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(images).squeeze(1)\n",
    "            loss = criterion(output, objects)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            check_output(output[4], images[4], epoch=epoch)\n",
    "        #     # check_output(fake_images[0], epoch)\n",
    "        #     generate_and_plot_images(25, epoch=epoch)\n",
    "\n",
    "        if (epoch + 1) % 30 == 0:\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch  # Optional, if you want to also save the epoch number\n",
    "            }\n",
    "\n",
    "            torch.save(checkpoint, f'GAN_ass_{epoch}.pth')\n",
    "\n",
    "    except OSError:\n",
    "        print(f\"An error occurred while processing the image. Epoch: {epoch}, batch: {i}\")\n",
    "        continue\n"
   ],
   "id": "6701c6aa62fd5790",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/500], Step [20/44], Loss: 0.4379\n",
      "Epoch [101/500], Step [40/44], Loss: 0.3103\n",
      "Epoch [102/500], Step [20/44], Loss: 0.4377\n",
      "Epoch [102/500], Step [40/44], Loss: 0.3103\n",
      "Epoch [103/500], Step [20/44], Loss: 0.4377\n",
      "Epoch [103/500], Step [40/44], Loss: 0.3102\n",
      "Epoch [104/500], Step [20/44], Loss: 0.4377\n",
      "Epoch [104/500], Step [40/44], Loss: 0.3101\n",
      "Epoch [105/500], Step [20/44], Loss: 0.4372\n",
      "Epoch [105/500], Step [40/44], Loss: 0.3101\n",
      "Epoch [106/500], Step [20/44], Loss: 0.4372\n",
      "Epoch [106/500], Step [40/44], Loss: 0.3101\n",
      "Epoch [107/500], Step [20/44], Loss: 0.4370\n",
      "Epoch [107/500], Step [40/44], Loss: 0.3100\n",
      "Epoch [108/500], Step [20/44], Loss: 0.4370\n",
      "Epoch [108/500], Step [40/44], Loss: 0.3099\n",
      "Epoch [109/500], Step [20/44], Loss: 0.4369\n",
      "Epoch [109/500], Step [40/44], Loss: 0.3099\n",
      "Epoch [110/500], Step [20/44], Loss: 0.4363\n",
      "Epoch [110/500], Step [40/44], Loss: 0.3098\n",
      "Epoch [111/500], Step [20/44], Loss: 0.4366\n",
      "Epoch [111/500], Step [40/44], Loss: 0.3097\n",
      "Epoch [112/500], Step [20/44], Loss: 0.4364\n",
      "Epoch [112/500], Step [40/44], Loss: 0.3097\n",
      "Epoch [113/500], Step [20/44], Loss: 0.4364\n",
      "Epoch [113/500], Step [40/44], Loss: 0.3096\n",
      "Epoch [114/500], Step [20/44], Loss: 0.4361\n",
      "Epoch [114/500], Step [40/44], Loss: 0.3096\n",
      "Epoch [115/500], Step [20/44], Loss: 0.4361\n",
      "Epoch [115/500], Step [40/44], Loss: 0.3095\n",
      "Epoch [116/500], Step [20/44], Loss: 0.4362\n",
      "Epoch [116/500], Step [40/44], Loss: 0.3095\n",
      "Epoch [117/500], Step [20/44], Loss: 0.4359\n",
      "Epoch [117/500], Step [40/44], Loss: 0.3094\n",
      "Epoch [118/500], Step [20/44], Loss: 0.4356\n",
      "Epoch [118/500], Step [40/44], Loss: 0.3094\n",
      "Epoch [119/500], Step [20/44], Loss: 0.4354\n",
      "Epoch [119/500], Step [40/44], Loss: 0.3093\n",
      "Epoch [120/500], Step [20/44], Loss: 0.4353\n",
      "Epoch [120/500], Step [40/44], Loss: 0.3092\n",
      "Epoch [121/500], Step [20/44], Loss: 0.4353\n",
      "Epoch [121/500], Step [40/44], Loss: 0.3092\n",
      "Epoch [122/500], Step [20/44], Loss: 0.4352\n",
      "Epoch [122/500], Step [40/44], Loss: 0.3091\n",
      "Epoch [123/500], Step [20/44], Loss: 0.4351\n",
      "Epoch [123/500], Step [40/44], Loss: 0.3091\n",
      "Epoch [124/500], Step [20/44], Loss: 0.4350\n",
      "Epoch [124/500], Step [40/44], Loss: 0.3090\n",
      "Epoch [125/500], Step [20/44], Loss: 0.4350\n",
      "Epoch [125/500], Step [40/44], Loss: 0.3090\n",
      "Epoch [126/500], Step [20/44], Loss: 0.4347\n",
      "Epoch [126/500], Step [40/44], Loss: 0.3091\n",
      "Epoch [127/500], Step [20/44], Loss: 0.4342\n",
      "Epoch [127/500], Step [40/44], Loss: 0.3088\n",
      "Epoch [128/500], Step [20/44], Loss: 0.4344\n",
      "Epoch [128/500], Step [40/44], Loss: 0.3088\n",
      "Epoch [129/500], Step [20/44], Loss: 0.4344\n",
      "Epoch [129/500], Step [40/44], Loss: 0.3088\n",
      "Epoch [130/500], Step [20/44], Loss: 0.4341\n",
      "Epoch [130/500], Step [40/44], Loss: 0.3088\n",
      "Epoch [131/500], Step [20/44], Loss: 0.4338\n",
      "Epoch [131/500], Step [40/44], Loss: 0.3087\n",
      "Epoch [132/500], Step [20/44], Loss: 0.4337\n",
      "Epoch [132/500], Step [40/44], Loss: 0.3086\n",
      "Epoch [133/500], Step [20/44], Loss: 0.4338\n",
      "Epoch [133/500], Step [40/44], Loss: 0.3086\n",
      "Epoch [134/500], Step [20/44], Loss: 0.4335\n",
      "Epoch [134/500], Step [40/44], Loss: 0.3086\n",
      "Epoch [135/500], Step [20/44], Loss: 0.4335\n",
      "Epoch [135/500], Step [40/44], Loss: 0.3085\n",
      "Epoch [136/500], Step [20/44], Loss: 0.4329\n",
      "Epoch [136/500], Step [40/44], Loss: 0.3084\n",
      "Epoch [137/500], Step [20/44], Loss: 0.4330\n",
      "Epoch [137/500], Step [40/44], Loss: 0.3084\n",
      "Epoch [138/500], Step [20/44], Loss: 0.4328\n",
      "Epoch [138/500], Step [40/44], Loss: 0.3084\n",
      "Epoch [139/500], Step [20/44], Loss: 0.4329\n",
      "Epoch [139/500], Step [40/44], Loss: 0.3083\n",
      "Epoch [140/500], Step [20/44], Loss: 0.4327\n",
      "Epoch [140/500], Step [40/44], Loss: 0.3083\n",
      "Epoch [141/500], Step [20/44], Loss: 0.4324\n",
      "Epoch [141/500], Step [40/44], Loss: 0.3082\n",
      "Epoch [142/500], Step [20/44], Loss: 0.4324\n",
      "Epoch [142/500], Step [40/44], Loss: 0.3082\n",
      "Epoch [143/500], Step [20/44], Loss: 0.4321\n",
      "Epoch [143/500], Step [40/44], Loss: 0.3081\n",
      "Epoch [144/500], Step [20/44], Loss: 0.4320\n",
      "Epoch [144/500], Step [40/44], Loss: 0.3080\n",
      "Epoch [145/500], Step [20/44], Loss: 0.4320\n",
      "Epoch [145/500], Step [40/44], Loss: 0.3081\n",
      "Epoch [146/500], Step [20/44], Loss: 0.4316\n",
      "Epoch [146/500], Step [40/44], Loss: 0.3080\n",
      "Epoch [147/500], Step [20/44], Loss: 0.4316\n",
      "Epoch [147/500], Step [40/44], Loss: 0.3079\n",
      "Epoch [148/500], Step [20/44], Loss: 0.4316\n",
      "Epoch [148/500], Step [40/44], Loss: 0.3079\n",
      "Epoch [149/500], Step [20/44], Loss: 0.4312\n",
      "Epoch [149/500], Step [40/44], Loss: 0.3079\n",
      "Epoch [150/500], Step [20/44], Loss: 0.4313\n",
      "Epoch [150/500], Step [40/44], Loss: 0.3078\n",
      "Epoch [151/500], Step [20/44], Loss: 0.4309\n",
      "Epoch [151/500], Step [40/44], Loss: 0.3078\n",
      "Epoch [152/500], Step [20/44], Loss: 0.4308\n",
      "Epoch [152/500], Step [40/44], Loss: 0.3077\n",
      "Epoch [153/500], Step [20/44], Loss: 0.4307\n",
      "Epoch [153/500], Step [40/44], Loss: 0.3077\n",
      "Epoch [154/500], Step [20/44], Loss: 0.4306\n",
      "Epoch [154/500], Step [40/44], Loss: 0.3077\n",
      "Epoch [155/500], Step [20/44], Loss: 0.4303\n",
      "Epoch [155/500], Step [40/44], Loss: 0.3076\n",
      "Epoch [156/500], Step [20/44], Loss: 0.4304\n",
      "Epoch [156/500], Step [40/44], Loss: 0.3076\n",
      "Epoch [157/500], Step [20/44], Loss: 0.4299\n",
      "Epoch [157/500], Step [40/44], Loss: 0.3075\n",
      "Epoch [158/500], Step [20/44], Loss: 0.4301\n",
      "Epoch [158/500], Step [40/44], Loss: 0.3076\n",
      "Epoch [159/500], Step [20/44], Loss: 0.4298\n",
      "Epoch [159/500], Step [40/44], Loss: 0.3075\n",
      "Epoch [160/500], Step [20/44], Loss: 0.4296\n",
      "Epoch [160/500], Step [40/44], Loss: 0.3074\n",
      "Epoch [161/500], Step [20/44], Loss: 0.4296\n",
      "Epoch [161/500], Step [40/44], Loss: 0.3074\n",
      "Epoch [162/500], Step [20/44], Loss: 0.4294\n",
      "Epoch [162/500], Step [40/44], Loss: 0.3074\n",
      "Epoch [163/500], Step [20/44], Loss: 0.4293\n",
      "Epoch [163/500], Step [40/44], Loss: 0.3073\n",
      "Epoch [164/500], Step [20/44], Loss: 0.4291\n",
      "Epoch [164/500], Step [40/44], Loss: 0.3073\n",
      "Epoch [165/500], Step [20/44], Loss: 0.4290\n",
      "Epoch [165/500], Step [40/44], Loss: 0.3073\n",
      "Epoch [166/500], Step [20/44], Loss: 0.4286\n",
      "Epoch [166/500], Step [40/44], Loss: 0.3072\n",
      "Epoch [167/500], Step [20/44], Loss: 0.4287\n",
      "Epoch [167/500], Step [40/44], Loss: 0.3072\n",
      "Epoch [168/500], Step [20/44], Loss: 0.4284\n",
      "Epoch [168/500], Step [40/44], Loss: 0.3072\n",
      "Epoch [169/500], Step [20/44], Loss: 0.4286\n",
      "Epoch [169/500], Step [40/44], Loss: 0.3071\n",
      "Epoch [170/500], Step [20/44], Loss: 0.4284\n",
      "Epoch [170/500], Step [40/44], Loss: 0.3071\n",
      "Epoch [171/500], Step [20/44], Loss: 0.4280\n",
      "Epoch [171/500], Step [40/44], Loss: 0.3070\n",
      "Epoch [172/500], Step [20/44], Loss: 0.4282\n",
      "Epoch [172/500], Step [40/44], Loss: 0.3071\n",
      "Epoch [173/500], Step [20/44], Loss: 0.4280\n",
      "Epoch [173/500], Step [40/44], Loss: 0.3070\n",
      "Epoch [174/500], Step [20/44], Loss: 0.4277\n",
      "Epoch [174/500], Step [40/44], Loss: 0.3070\n",
      "Epoch [175/500], Step [20/44], Loss: 0.4277\n",
      "Epoch [175/500], Step [40/44], Loss: 0.3069\n",
      "Epoch [176/500], Step [20/44], Loss: 0.4270\n",
      "Epoch [176/500], Step [40/44], Loss: 0.3069\n",
      "Epoch [177/500], Step [20/44], Loss: 0.4273\n",
      "Epoch [177/500], Step [40/44], Loss: 0.3069\n",
      "Epoch [178/500], Step [20/44], Loss: 0.4271\n",
      "Epoch [178/500], Step [40/44], Loss: 0.3068\n",
      "Epoch [179/500], Step [20/44], Loss: 0.4271\n",
      "Epoch [179/500], Step [40/44], Loss: 0.3068\n",
      "Epoch [180/500], Step [20/44], Loss: 0.4269\n",
      "Epoch [180/500], Step [40/44], Loss: 0.3068\n",
      "Epoch [181/500], Step [20/44], Loss: 0.4267\n",
      "Epoch [181/500], Step [40/44], Loss: 0.3068\n",
      "Epoch [182/500], Step [20/44], Loss: 0.4267\n",
      "Epoch [182/500], Step [40/44], Loss: 0.3068\n",
      "Epoch [183/500], Step [20/44], Loss: 0.4264\n",
      "Epoch [183/500], Step [40/44], Loss: 0.3067\n",
      "Epoch [184/500], Step [20/44], Loss: 0.4263\n",
      "Epoch [184/500], Step [40/44], Loss: 0.3067\n",
      "Epoch [185/500], Step [20/44], Loss: 0.4262\n",
      "Epoch [185/500], Step [40/44], Loss: 0.3067\n",
      "Epoch [186/500], Step [20/44], Loss: 0.4261\n",
      "Epoch [186/500], Step [40/44], Loss: 0.3066\n",
      "Epoch [187/500], Step [20/44], Loss: 0.4260\n",
      "Epoch [187/500], Step [40/44], Loss: 0.3067\n",
      "Epoch [188/500], Step [20/44], Loss: 0.4258\n",
      "Epoch [188/500], Step [40/44], Loss: 0.3066\n",
      "Epoch [189/500], Step [20/44], Loss: 0.4258\n",
      "Epoch [189/500], Step [40/44], Loss: 0.3066\n",
      "Epoch [190/500], Step [20/44], Loss: 0.4256\n",
      "Epoch [190/500], Step [40/44], Loss: 0.3066\n",
      "Epoch [191/500], Step [20/44], Loss: 0.4255\n",
      "Epoch [191/500], Step [40/44], Loss: 0.3066\n",
      "Epoch [192/500], Step [20/44], Loss: 0.4251\n",
      "Epoch [192/500], Step [40/44], Loss: 0.3066\n",
      "Epoch [193/500], Step [20/44], Loss: 0.4253\n",
      "Epoch [193/500], Step [40/44], Loss: 0.3065\n",
      "Epoch [194/500], Step [20/44], Loss: 0.4251\n",
      "Epoch [194/500], Step [40/44], Loss: 0.3065\n",
      "Epoch [195/500], Step [20/44], Loss: 0.4250\n",
      "Epoch [195/500], Step [40/44], Loss: 0.3065\n",
      "Epoch [196/500], Step [20/44], Loss: 0.4249\n",
      "Epoch [196/500], Step [40/44], Loss: 0.3065\n",
      "Epoch [197/500], Step [20/44], Loss: 0.4248\n",
      "Epoch [197/500], Step [40/44], Loss: 0.3065\n",
      "Epoch [198/500], Step [20/44], Loss: 0.4245\n",
      "Epoch [198/500], Step [40/44], Loss: 0.3064\n",
      "Epoch [199/500], Step [20/44], Loss: 0.4244\n",
      "Epoch [199/500], Step [40/44], Loss: 0.3064\n",
      "Epoch [200/500], Step [20/44], Loss: 0.4243\n",
      "Epoch [200/500], Step [40/44], Loss: 0.3064\n",
      "Epoch [201/500], Step [20/44], Loss: 0.4239\n",
      "Epoch [201/500], Step [40/44], Loss: 0.3064\n",
      "Epoch [202/500], Step [20/44], Loss: 0.4239\n",
      "Epoch [202/500], Step [40/44], Loss: 0.3064\n",
      "Epoch [203/500], Step [20/44], Loss: 0.4236\n",
      "Epoch [203/500], Step [40/44], Loss: 0.3064\n",
      "Epoch [204/500], Step [20/44], Loss: 0.4236\n",
      "Epoch [204/500], Step [40/44], Loss: 0.3064\n",
      "Epoch [205/500], Step [20/44], Loss: 0.4232\n",
      "Epoch [205/500], Step [40/44], Loss: 0.3063\n",
      "Epoch [206/500], Step [20/44], Loss: 0.4234\n",
      "Epoch [206/500], Step [40/44], Loss: 0.3064\n",
      "Epoch [207/500], Step [20/44], Loss: 0.4230\n",
      "Epoch [207/500], Step [40/44], Loss: 0.3063\n",
      "Epoch [208/500], Step [20/44], Loss: 0.4229\n",
      "Epoch [208/500], Step [40/44], Loss: 0.3063\n",
      "Epoch [209/500], Step [20/44], Loss: 0.4225\n",
      "Epoch [209/500], Step [40/44], Loss: 0.3063\n",
      "Epoch [210/500], Step [20/44], Loss: 0.4224\n",
      "Epoch [210/500], Step [40/44], Loss: 0.3062\n",
      "Epoch [211/500], Step [20/44], Loss: 0.4223\n",
      "Epoch [211/500], Step [40/44], Loss: 0.3063\n",
      "Epoch [212/500], Step [20/44], Loss: 0.4223\n",
      "Epoch [212/500], Step [40/44], Loss: 0.3062\n",
      "Epoch [213/500], Step [20/44], Loss: 0.4219\n",
      "Epoch [213/500], Step [40/44], Loss: 0.3062\n",
      "Epoch [214/500], Step [20/44], Loss: 0.4220\n",
      "Epoch [214/500], Step [40/44], Loss: 0.3062\n",
      "Epoch [215/500], Step [20/44], Loss: 0.4218\n",
      "Epoch [215/500], Step [40/44], Loss: 0.3062\n",
      "Epoch [216/500], Step [20/44], Loss: 0.4215\n",
      "Epoch [216/500], Step [40/44], Loss: 0.3062\n",
      "Epoch [217/500], Step [20/44], Loss: 0.4212\n",
      "Epoch [217/500], Step [40/44], Loss: 0.3061\n",
      "Epoch [218/500], Step [20/44], Loss: 0.4211\n",
      "Epoch [218/500], Step [40/44], Loss: 0.3061\n",
      "Epoch [219/500], Step [20/44], Loss: 0.4210\n",
      "Epoch [219/500], Step [40/44], Loss: 0.3061\n",
      "Epoch [220/500], Step [20/44], Loss: 0.4210\n",
      "Epoch [220/500], Step [40/44], Loss: 0.3061\n",
      "Epoch [221/500], Step [20/44], Loss: 0.4208\n",
      "Epoch [221/500], Step [40/44], Loss: 0.3060\n",
      "Epoch [222/500], Step [20/44], Loss: 0.4209\n",
      "Epoch [222/500], Step [40/44], Loss: 0.3060\n",
      "Epoch [223/500], Step [20/44], Loss: 0.4205\n",
      "Epoch [223/500], Step [40/44], Loss: 0.3060\n",
      "Epoch [224/500], Step [20/44], Loss: 0.4205\n",
      "Epoch [224/500], Step [40/44], Loss: 0.3060\n",
      "Epoch [225/500], Step [20/44], Loss: 0.4203\n",
      "Epoch [225/500], Step [40/44], Loss: 0.3060\n",
      "Epoch [226/500], Step [20/44], Loss: 0.4203\n",
      "Epoch [226/500], Step [40/44], Loss: 0.3060\n",
      "Epoch [227/500], Step [20/44], Loss: 0.4201\n",
      "Epoch [227/500], Step [40/44], Loss: 0.3059\n",
      "Epoch [228/500], Step [20/44], Loss: 0.4200\n",
      "Epoch [228/500], Step [40/44], Loss: 0.3059\n",
      "Epoch [229/500], Step [20/44], Loss: 0.4197\n",
      "Epoch [229/500], Step [40/44], Loss: 0.3059\n",
      "Epoch [230/500], Step [20/44], Loss: 0.4195\n",
      "Epoch [230/500], Step [40/44], Loss: 0.3059\n",
      "Epoch [231/500], Step [20/44], Loss: 0.4196\n",
      "Epoch [231/500], Step [40/44], Loss: 0.3058\n",
      "Epoch [232/500], Step [20/44], Loss: 0.4194\n",
      "Epoch [232/500], Step [40/44], Loss: 0.3058\n",
      "Epoch [233/500], Step [20/44], Loss: 0.4192\n",
      "Epoch [233/500], Step [40/44], Loss: 0.3058\n",
      "Epoch [234/500], Step [20/44], Loss: 0.4194\n",
      "Epoch [234/500], Step [40/44], Loss: 0.3058\n",
      "Epoch [235/500], Step [20/44], Loss: 0.4191\n",
      "Epoch [235/500], Step [40/44], Loss: 0.3058\n",
      "Epoch [236/500], Step [20/44], Loss: 0.4190\n",
      "Epoch [236/500], Step [40/44], Loss: 0.3058\n",
      "Epoch [237/500], Step [20/44], Loss: 0.4190\n",
      "Epoch [237/500], Step [40/44], Loss: 0.3057\n",
      "Epoch [238/500], Step [20/44], Loss: 0.4187\n",
      "Epoch [238/500], Step [40/44], Loss: 0.3057\n",
      "Epoch [239/500], Step [20/44], Loss: 0.4185\n",
      "Epoch [239/500], Step [40/44], Loss: 0.3057\n",
      "Epoch [240/500], Step [20/44], Loss: 0.4182\n",
      "Epoch [240/500], Step [40/44], Loss: 0.3057\n",
      "Epoch [241/500], Step [20/44], Loss: 0.4184\n",
      "Epoch [241/500], Step [40/44], Loss: 0.3057\n",
      "Epoch [242/500], Step [20/44], Loss: 0.4184\n",
      "Epoch [242/500], Step [40/44], Loss: 0.3057\n",
      "Epoch [243/500], Step [20/44], Loss: 0.4179\n",
      "Epoch [243/500], Step [40/44], Loss: 0.3056\n",
      "Epoch [244/500], Step [20/44], Loss: 0.4180\n",
      "Epoch [244/500], Step [40/44], Loss: 0.3056\n",
      "Epoch [245/500], Step [20/44], Loss: 0.4175\n",
      "Epoch [245/500], Step [40/44], Loss: 0.3056\n",
      "Epoch [246/500], Step [20/44], Loss: 0.4176\n",
      "Epoch [246/500], Step [40/44], Loss: 0.3056\n",
      "Epoch [247/500], Step [20/44], Loss: 0.4175\n",
      "Epoch [247/500], Step [40/44], Loss: 0.3056\n",
      "Epoch [248/500], Step [20/44], Loss: 0.4174\n",
      "Epoch [248/500], Step [40/44], Loss: 0.3056\n",
      "Epoch [249/500], Step [20/44], Loss: 0.4173\n",
      "Epoch [249/500], Step [40/44], Loss: 0.3055\n",
      "Epoch [250/500], Step [20/44], Loss: 0.4169\n",
      "Epoch [250/500], Step [40/44], Loss: 0.3055\n",
      "Epoch [251/500], Step [20/44], Loss: 0.4169\n",
      "Epoch [251/500], Step [40/44], Loss: 0.3055\n",
      "Epoch [252/500], Step [20/44], Loss: 0.4166\n",
      "Epoch [252/500], Step [40/44], Loss: 0.3055\n",
      "Epoch [253/500], Step [20/44], Loss: 0.4165\n",
      "Epoch [253/500], Step [40/44], Loss: 0.3055\n",
      "Epoch [254/500], Step [20/44], Loss: 0.4165\n",
      "Epoch [254/500], Step [40/44], Loss: 0.3054\n",
      "Epoch [255/500], Step [20/44], Loss: 0.4163\n",
      "Epoch [255/500], Step [40/44], Loss: 0.3054\n",
      "Epoch [256/500], Step [20/44], Loss: 0.4159\n",
      "Epoch [256/500], Step [40/44], Loss: 0.3054\n",
      "Epoch [257/500], Step [20/44], Loss: 0.4159\n",
      "Epoch [257/500], Step [40/44], Loss: 0.3054\n",
      "Epoch [258/500], Step [20/44], Loss: 0.4161\n",
      "Epoch [258/500], Step [40/44], Loss: 0.3054\n",
      "Epoch [259/500], Step [20/44], Loss: 0.4159\n",
      "Epoch [259/500], Step [40/44], Loss: 0.3054\n",
      "Epoch [260/500], Step [20/44], Loss: 0.4157\n",
      "Epoch [260/500], Step [40/44], Loss: 0.3054\n",
      "Epoch [261/500], Step [20/44], Loss: 0.4156\n",
      "Epoch [261/500], Step [40/44], Loss: 0.3053\n",
      "Epoch [262/500], Step [20/44], Loss: 0.4154\n",
      "Epoch [262/500], Step [40/44], Loss: 0.3053\n",
      "Epoch [263/500], Step [20/44], Loss: 0.4153\n",
      "Epoch [263/500], Step [40/44], Loss: 0.3053\n",
      "Epoch [264/500], Step [20/44], Loss: 0.4153\n",
      "Epoch [264/500], Step [40/44], Loss: 0.3053\n",
      "Epoch [265/500], Step [20/44], Loss: 0.4150\n",
      "Epoch [265/500], Step [40/44], Loss: 0.3053\n",
      "Epoch [266/500], Step [20/44], Loss: 0.4148\n",
      "Epoch [266/500], Step [40/44], Loss: 0.3053\n",
      "Epoch [267/500], Step [20/44], Loss: 0.4149\n",
      "Epoch [267/500], Step [40/44], Loss: 0.3052\n",
      "Epoch [268/500], Step [20/44], Loss: 0.4147\n",
      "Epoch [268/500], Step [40/44], Loss: 0.3053\n",
      "Epoch [269/500], Step [20/44], Loss: 0.4145\n",
      "Epoch [269/500], Step [40/44], Loss: 0.3052\n",
      "Epoch [270/500], Step [20/44], Loss: 0.4144\n",
      "Epoch [270/500], Step [40/44], Loss: 0.3052\n",
      "Epoch [271/500], Step [20/44], Loss: 0.4141\n",
      "Epoch [271/500], Step [40/44], Loss: 0.3052\n",
      "Epoch [272/500], Step [20/44], Loss: 0.4139\n",
      "Epoch [272/500], Step [40/44], Loss: 0.3051\n",
      "Epoch [273/500], Step [20/44], Loss: 0.4139\n",
      "Epoch [273/500], Step [40/44], Loss: 0.3051\n",
      "Epoch [274/500], Step [20/44], Loss: 0.4139\n",
      "Epoch [274/500], Step [40/44], Loss: 0.3051\n",
      "Epoch [275/500], Step [20/44], Loss: 0.4136\n",
      "Epoch [275/500], Step [40/44], Loss: 0.3051\n",
      "Epoch [276/500], Step [20/44], Loss: 0.4136\n",
      "Epoch [276/500], Step [40/44], Loss: 0.3051\n",
      "Epoch [277/500], Step [20/44], Loss: 0.4132\n",
      "Epoch [277/500], Step [40/44], Loss: 0.3051\n",
      "Epoch [278/500], Step [20/44], Loss: 0.4131\n",
      "Epoch [278/500], Step [40/44], Loss: 0.3050\n",
      "Epoch [279/500], Step [20/44], Loss: 0.4131\n",
      "Epoch [279/500], Step [40/44], Loss: 0.3050\n",
      "Epoch [280/500], Step [20/44], Loss: 0.4128\n",
      "Epoch [280/500], Step [40/44], Loss: 0.3050\n",
      "Epoch [281/500], Step [20/44], Loss: 0.4125\n",
      "Epoch [281/500], Step [40/44], Loss: 0.3050\n",
      "Epoch [282/500], Step [20/44], Loss: 0.4125\n",
      "Epoch [282/500], Step [40/44], Loss: 0.3050\n",
      "Epoch [283/500], Step [20/44], Loss: 0.4126\n",
      "Epoch [283/500], Step [40/44], Loss: 0.3050\n",
      "Epoch [284/500], Step [20/44], Loss: 0.4122\n",
      "Epoch [284/500], Step [40/44], Loss: 0.3050\n",
      "Epoch [285/500], Step [20/44], Loss: 0.4122\n",
      "Epoch [285/500], Step [40/44], Loss: 0.3049\n",
      "Epoch [286/500], Step [20/44], Loss: 0.4118\n",
      "Epoch [286/500], Step [40/44], Loss: 0.3050\n",
      "Epoch [287/500], Step [20/44], Loss: 0.4120\n",
      "Epoch [287/500], Step [40/44], Loss: 0.3049\n",
      "Epoch [288/500], Step [20/44], Loss: 0.4118\n",
      "Epoch [288/500], Step [40/44], Loss: 0.3049\n",
      "Epoch [289/500], Step [20/44], Loss: 0.4116\n",
      "Epoch [289/500], Step [40/44], Loss: 0.3049\n",
      "Epoch [290/500], Step [20/44], Loss: 0.4114\n",
      "Epoch [290/500], Step [40/44], Loss: 0.3049\n",
      "Epoch [291/500], Step [20/44], Loss: 0.4115\n",
      "Epoch [291/500], Step [40/44], Loss: 0.3049\n",
      "Epoch [292/500], Step [20/44], Loss: 0.4110\n",
      "Epoch [292/500], Step [40/44], Loss: 0.3048\n",
      "Epoch [293/500], Step [20/44], Loss: 0.4111\n",
      "Epoch [293/500], Step [40/44], Loss: 0.3048\n",
      "Epoch [294/500], Step [20/44], Loss: 0.4106\n",
      "Epoch [294/500], Step [40/44], Loss: 0.3048\n",
      "Epoch [295/500], Step [20/44], Loss: 0.4108\n",
      "Epoch [295/500], Step [40/44], Loss: 0.3048\n",
      "Epoch [296/500], Step [20/44], Loss: 0.4104\n",
      "Epoch [296/500], Step [40/44], Loss: 0.3048\n",
      "Epoch [297/500], Step [20/44], Loss: 0.4105\n",
      "Epoch [297/500], Step [40/44], Loss: 0.3047\n",
      "Epoch [298/500], Step [20/44], Loss: 0.4103\n",
      "Epoch [298/500], Step [40/44], Loss: 0.3047\n",
      "Epoch [299/500], Step [20/44], Loss: 0.4104\n",
      "Epoch [299/500], Step [40/44], Loss: 0.3047\n",
      "Epoch [300/500], Step [20/44], Loss: 0.4100\n",
      "Epoch [300/500], Step [40/44], Loss: 0.3047\n",
      "Epoch [301/500], Step [20/44], Loss: 0.4101\n",
      "Epoch [301/500], Step [40/44], Loss: 0.3047\n",
      "Epoch [302/500], Step [20/44], Loss: 0.4097\n",
      "Epoch [302/500], Step [40/44], Loss: 0.3047\n",
      "Epoch [303/500], Step [20/44], Loss: 0.4097\n",
      "Epoch [303/500], Step [40/44], Loss: 0.3046\n",
      "Epoch [304/500], Step [20/44], Loss: 0.4096\n",
      "Epoch [304/500], Step [40/44], Loss: 0.3046\n",
      "Epoch [305/500], Step [20/44], Loss: 0.4095\n",
      "Epoch [305/500], Step [40/44], Loss: 0.3046\n",
      "Epoch [306/500], Step [20/44], Loss: 0.4094\n",
      "Epoch [306/500], Step [40/44], Loss: 0.3046\n",
      "Epoch [307/500], Step [20/44], Loss: 0.4093\n",
      "Epoch [307/500], Step [40/44], Loss: 0.3046\n",
      "Epoch [308/500], Step [20/44], Loss: 0.4090\n",
      "Epoch [308/500], Step [40/44], Loss: 0.3045\n",
      "Epoch [309/500], Step [20/44], Loss: 0.4090\n",
      "Epoch [309/500], Step [40/44], Loss: 0.3045\n",
      "Epoch [310/500], Step [20/44], Loss: 0.4090\n",
      "Epoch [310/500], Step [40/44], Loss: 0.3045\n",
      "Epoch [311/500], Step [20/44], Loss: 0.4089\n",
      "Epoch [311/500], Step [40/44], Loss: 0.3045\n",
      "Epoch [312/500], Step [20/44], Loss: 0.4086\n",
      "Epoch [312/500], Step [40/44], Loss: 0.3045\n",
      "Epoch [313/500], Step [20/44], Loss: 0.4086\n",
      "Epoch [313/500], Step [40/44], Loss: 0.3045\n",
      "Epoch [314/500], Step [20/44], Loss: 0.4082\n",
      "Epoch [314/500], Step [40/44], Loss: 0.3045\n",
      "Epoch [315/500], Step [20/44], Loss: 0.4084\n",
      "Epoch [315/500], Step [40/44], Loss: 0.3044\n",
      "Epoch [316/500], Step [20/44], Loss: 0.4079\n",
      "Epoch [316/500], Step [40/44], Loss: 0.3044\n",
      "Epoch [317/500], Step [20/44], Loss: 0.4080\n",
      "Epoch [317/500], Step [40/44], Loss: 0.3044\n",
      "Epoch [318/500], Step [20/44], Loss: 0.4079\n",
      "Epoch [318/500], Step [40/44], Loss: 0.3044\n",
      "Epoch [319/500], Step [20/44], Loss: 0.4077\n",
      "Epoch [319/500], Step [40/44], Loss: 0.3043\n",
      "Epoch [320/500], Step [20/44], Loss: 0.4077\n",
      "Epoch [320/500], Step [40/44], Loss: 0.3043\n",
      "Epoch [321/500], Step [20/44], Loss: 0.4078\n",
      "Epoch [321/500], Step [40/44], Loss: 0.3043\n",
      "Epoch [322/500], Step [20/44], Loss: 0.4073\n",
      "Epoch [322/500], Step [40/44], Loss: 0.3043\n",
      "Epoch [323/500], Step [20/44], Loss: 0.4074\n",
      "Epoch [323/500], Step [40/44], Loss: 0.3043\n",
      "Epoch [324/500], Step [20/44], Loss: 0.4072\n",
      "Epoch [324/500], Step [40/44], Loss: 0.3043\n",
      "Epoch [325/500], Step [20/44], Loss: 0.4068\n",
      "Epoch [325/500], Step [40/44], Loss: 0.3042\n",
      "Epoch [326/500], Step [20/44], Loss: 0.4071\n",
      "Epoch [326/500], Step [40/44], Loss: 0.3043\n",
      "Epoch [327/500], Step [20/44], Loss: 0.4070\n",
      "Epoch [327/500], Step [40/44], Loss: 0.3042\n",
      "Epoch [328/500], Step [20/44], Loss: 0.4066\n",
      "Epoch [328/500], Step [40/44], Loss: 0.3042\n",
      "Epoch [329/500], Step [20/44], Loss: 0.4067\n",
      "Epoch [329/500], Step [40/44], Loss: 0.3042\n",
      "Epoch [330/500], Step [20/44], Loss: 0.4064\n",
      "Epoch [330/500], Step [40/44], Loss: 0.3042\n",
      "Epoch [331/500], Step [20/44], Loss: 0.4062\n",
      "Epoch [331/500], Step [40/44], Loss: 0.3042\n",
      "Epoch [332/500], Step [20/44], Loss: 0.4061\n",
      "Epoch [332/500], Step [40/44], Loss: 0.3042\n",
      "Epoch [333/500], Step [20/44], Loss: 0.4060\n",
      "Epoch [333/500], Step [40/44], Loss: 0.3042\n",
      "Epoch [334/500], Step [20/44], Loss: 0.4059\n",
      "Epoch [334/500], Step [40/44], Loss: 0.3041\n",
      "Epoch [335/500], Step [20/44], Loss: 0.4057\n",
      "Epoch [335/500], Step [40/44], Loss: 0.3041\n",
      "Epoch [336/500], Step [20/44], Loss: 0.4057\n",
      "Epoch [336/500], Step [40/44], Loss: 0.3041\n",
      "Epoch [337/500], Step [20/44], Loss: 0.4056\n",
      "Epoch [337/500], Step [40/44], Loss: 0.3041\n",
      "Epoch [338/500], Step [20/44], Loss: 0.4054\n",
      "Epoch [338/500], Step [40/44], Loss: 0.3041\n",
      "Epoch [339/500], Step [20/44], Loss: 0.4054\n",
      "Epoch [339/500], Step [40/44], Loss: 0.3041\n",
      "Epoch [340/500], Step [20/44], Loss: 0.4052\n",
      "Epoch [340/500], Step [40/44], Loss: 0.3041\n",
      "Epoch [341/500], Step [20/44], Loss: 0.4050\n",
      "Epoch [341/500], Step [40/44], Loss: 0.3040\n",
      "Epoch [342/500], Step [20/44], Loss: 0.4050\n",
      "Epoch [342/500], Step [40/44], Loss: 0.3040\n",
      "Epoch [343/500], Step [20/44], Loss: 0.4049\n",
      "Epoch [343/500], Step [40/44], Loss: 0.3040\n",
      "Epoch [344/500], Step [20/44], Loss: 0.4048\n",
      "Epoch [344/500], Step [40/44], Loss: 0.3040\n",
      "Epoch [345/500], Step [20/44], Loss: 0.4045\n",
      "Epoch [345/500], Step [40/44], Loss: 0.3040\n",
      "Epoch [346/500], Step [20/44], Loss: 0.4046\n",
      "Epoch [346/500], Step [40/44], Loss: 0.3040\n",
      "Epoch [347/500], Step [20/44], Loss: 0.4042\n",
      "Epoch [347/500], Step [40/44], Loss: 0.3040\n",
      "Epoch [348/500], Step [20/44], Loss: 0.4044\n",
      "Epoch [348/500], Step [40/44], Loss: 0.3039\n",
      "Epoch [349/500], Step [20/44], Loss: 0.4040\n",
      "Epoch [349/500], Step [40/44], Loss: 0.3039\n",
      "Epoch [350/500], Step [20/44], Loss: 0.4038\n",
      "Epoch [350/500], Step [40/44], Loss: 0.3039\n",
      "Epoch [351/500], Step [20/44], Loss: 0.4038\n",
      "Epoch [351/500], Step [40/44], Loss: 0.3039\n",
      "Epoch [352/500], Step [20/44], Loss: 0.4037\n",
      "Epoch [352/500], Step [40/44], Loss: 0.3039\n",
      "Epoch [353/500], Step [20/44], Loss: 0.4036\n",
      "Epoch [353/500], Step [40/44], Loss: 0.3039\n",
      "Epoch [354/500], Step [20/44], Loss: 0.4033\n",
      "Epoch [354/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [355/500], Step [20/44], Loss: 0.4035\n",
      "Epoch [355/500], Step [40/44], Loss: 0.3039\n",
      "Epoch [356/500], Step [20/44], Loss: 0.4033\n",
      "Epoch [356/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [357/500], Step [20/44], Loss: 0.4031\n",
      "Epoch [357/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [358/500], Step [20/44], Loss: 0.4029\n",
      "Epoch [358/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [359/500], Step [20/44], Loss: 0.4029\n",
      "Epoch [359/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [360/500], Step [20/44], Loss: 0.4026\n",
      "Epoch [360/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [361/500], Step [20/44], Loss: 0.4028\n",
      "Epoch [361/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [362/500], Step [20/44], Loss: 0.4023\n",
      "Epoch [362/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [363/500], Step [20/44], Loss: 0.4022\n",
      "Epoch [363/500], Step [40/44], Loss: 0.3038\n",
      "Epoch [364/500], Step [20/44], Loss: 0.4021\n",
      "Epoch [364/500], Step [40/44], Loss: 0.3037\n",
      "Epoch [365/500], Step [20/44], Loss: 0.4021\n",
      "Epoch [365/500], Step [40/44], Loss: 0.3037\n",
      "Epoch [366/500], Step [20/44], Loss: 0.4019\n",
      "Epoch [366/500], Step [40/44], Loss: 0.3037\n",
      "Epoch [367/500], Step [20/44], Loss: 0.4018\n",
      "Epoch [367/500], Step [40/44], Loss: 0.3037\n",
      "Epoch [368/500], Step [20/44], Loss: 0.4015\n",
      "Epoch [368/500], Step [40/44], Loss: 0.3037\n",
      "Epoch [369/500], Step [20/44], Loss: 0.4017\n",
      "Epoch [369/500], Step [40/44], Loss: 0.3036\n",
      "Epoch [370/500], Step [20/44], Loss: 0.4016\n",
      "Epoch [370/500], Step [40/44], Loss: 0.3037\n",
      "Epoch [371/500], Step [20/44], Loss: 0.4014\n",
      "Epoch [371/500], Step [40/44], Loss: 0.3036\n",
      "Epoch [372/500], Step [20/44], Loss: 0.4014\n",
      "Epoch [372/500], Step [40/44], Loss: 0.3036\n",
      "Epoch [373/500], Step [20/44], Loss: 0.4013\n",
      "Epoch [373/500], Step [40/44], Loss: 0.3036\n",
      "Epoch [374/500], Step [20/44], Loss: 0.4012\n",
      "Epoch [374/500], Step [40/44], Loss: 0.3035\n",
      "Epoch [375/500], Step [20/44], Loss: 0.4011\n",
      "Epoch [375/500], Step [40/44], Loss: 0.3036\n",
      "Epoch [376/500], Step [20/44], Loss: 0.4009\n",
      "Epoch [376/500], Step [40/44], Loss: 0.3035\n",
      "Epoch [377/500], Step [20/44], Loss: 0.4008\n",
      "Epoch [377/500], Step [40/44], Loss: 0.3036\n",
      "Epoch [378/500], Step [20/44], Loss: 0.4007\n",
      "Epoch [378/500], Step [40/44], Loss: 0.3035\n",
      "Epoch [379/500], Step [20/44], Loss: 0.4004\n",
      "Epoch [379/500], Step [40/44], Loss: 0.3036\n",
      "Epoch [380/500], Step [20/44], Loss: 0.4003\n",
      "Epoch [380/500], Step [40/44], Loss: 0.3035\n",
      "Epoch [381/500], Step [20/44], Loss: 0.4002\n",
      "Epoch [381/500], Step [40/44], Loss: 0.3035\n",
      "Epoch [382/500], Step [20/44], Loss: 0.4003\n",
      "Epoch [382/500], Step [40/44], Loss: 0.3034\n",
      "Epoch [383/500], Step [20/44], Loss: 0.4000\n",
      "Epoch [383/500], Step [40/44], Loss: 0.3035\n",
      "Epoch [384/500], Step [20/44], Loss: 0.4000\n",
      "Epoch [384/500], Step [40/44], Loss: 0.3034\n",
      "Epoch [385/500], Step [20/44], Loss: 0.3999\n",
      "Epoch [385/500], Step [40/44], Loss: 0.3034\n",
      "Epoch [386/500], Step [20/44], Loss: 0.3998\n",
      "Epoch [386/500], Step [40/44], Loss: 0.3034\n",
      "Epoch [387/500], Step [20/44], Loss: 0.3993\n",
      "Epoch [387/500], Step [40/44], Loss: 0.3034\n",
      "Epoch [388/500], Step [20/44], Loss: 0.3996\n",
      "Epoch [388/500], Step [40/44], Loss: 0.3034\n",
      "Epoch [389/500], Step [20/44], Loss: 0.3993\n",
      "Epoch [389/500], Step [40/44], Loss: 0.3034\n",
      "Epoch [390/500], Step [20/44], Loss: 0.3992\n",
      "Epoch [390/500], Step [40/44], Loss: 0.3033\n",
      "Epoch [391/500], Step [20/44], Loss: 0.3992\n",
      "Epoch [391/500], Step [40/44], Loss: 0.3033\n",
      "Epoch [392/500], Step [20/44], Loss: 0.3992\n",
      "Epoch [392/500], Step [40/44], Loss: 0.3033\n",
      "Epoch [393/500], Step [20/44], Loss: 0.3988\n",
      "Epoch [393/500], Step [40/44], Loss: 0.3033\n",
      "Epoch [394/500], Step [20/44], Loss: 0.3989\n",
      "Epoch [394/500], Step [40/44], Loss: 0.3033\n",
      "Epoch [395/500], Step [20/44], Loss: 0.3989\n",
      "Epoch [395/500], Step [40/44], Loss: 0.3032\n",
      "Epoch [396/500], Step [20/44], Loss: 0.3986\n",
      "Epoch [396/500], Step [40/44], Loss: 0.3032\n",
      "Epoch [397/500], Step [20/44], Loss: 0.3986\n",
      "Epoch [397/500], Step [40/44], Loss: 0.3032\n",
      "Epoch [398/500], Step [20/44], Loss: 0.3982\n",
      "Epoch [398/500], Step [40/44], Loss: 0.3032\n",
      "Epoch [399/500], Step [20/44], Loss: 0.3983\n",
      "Epoch [399/500], Step [40/44], Loss: 0.3032\n",
      "Epoch [400/500], Step [20/44], Loss: 0.3980\n",
      "Epoch [400/500], Step [40/44], Loss: 0.3032\n",
      "Epoch [401/500], Step [20/44], Loss: 0.3979\n",
      "Epoch [401/500], Step [40/44], Loss: 0.3031\n",
      "Epoch [402/500], Step [20/44], Loss: 0.3979\n",
      "Epoch [402/500], Step [40/44], Loss: 0.3031\n",
      "Epoch [403/500], Step [20/44], Loss: 0.3976\n",
      "Epoch [403/500], Step [40/44], Loss: 0.3031\n",
      "Epoch [404/500], Step [20/44], Loss: 0.3974\n",
      "Epoch [404/500], Step [40/44], Loss: 0.3031\n",
      "Epoch [405/500], Step [20/44], Loss: 0.3974\n",
      "Epoch [405/500], Step [40/44], Loss: 0.3031\n",
      "Epoch [406/500], Step [20/44], Loss: 0.3973\n",
      "Epoch [406/500], Step [40/44], Loss: 0.3030\n",
      "Epoch [407/500], Step [20/44], Loss: 0.3973\n",
      "Epoch [407/500], Step [40/44], Loss: 0.3031\n",
      "Epoch [408/500], Step [20/44], Loss: 0.3969\n",
      "Epoch [408/500], Step [40/44], Loss: 0.3031\n",
      "Epoch [409/500], Step [20/44], Loss: 0.3969\n",
      "Epoch [409/500], Step [40/44], Loss: 0.3030\n",
      "Epoch [410/500], Step [20/44], Loss: 0.3968\n",
      "Epoch [410/500], Step [40/44], Loss: 0.3030\n",
      "Epoch [411/500], Step [20/44], Loss: 0.3967\n",
      "Epoch [411/500], Step [40/44], Loss: 0.3030\n",
      "Epoch [412/500], Step [20/44], Loss: 0.3965\n",
      "Epoch [412/500], Step [40/44], Loss: 0.3030\n",
      "Epoch [413/500], Step [20/44], Loss: 0.3965\n",
      "Epoch [413/500], Step [40/44], Loss: 0.3030\n",
      "Epoch [414/500], Step [20/44], Loss: 0.3964\n",
      "Epoch [414/500], Step [40/44], Loss: 0.3029\n",
      "Epoch [415/500], Step [20/44], Loss: 0.3963\n",
      "Epoch [415/500], Step [40/44], Loss: 0.3029\n",
      "Epoch [416/500], Step [20/44], Loss: 0.3961\n",
      "Epoch [416/500], Step [40/44], Loss: 0.3029\n",
      "Epoch [417/500], Step [20/44], Loss: 0.3960\n",
      "Epoch [417/500], Step [40/44], Loss: 0.3029\n",
      "Epoch [418/500], Step [20/44], Loss: 0.3960\n",
      "Epoch [418/500], Step [40/44], Loss: 0.3029\n",
      "Epoch [419/500], Step [20/44], Loss: 0.3959\n",
      "Epoch [419/500], Step [40/44], Loss: 0.3028\n",
      "Epoch [420/500], Step [20/44], Loss: 0.3957\n",
      "Epoch [420/500], Step [40/44], Loss: 0.3028\n",
      "Epoch [421/500], Step [20/44], Loss: 0.3956\n",
      "Epoch [421/500], Step [40/44], Loss: 0.3028\n",
      "Epoch [422/500], Step [20/44], Loss: 0.3953\n",
      "Epoch [422/500], Step [40/44], Loss: 0.3028\n",
      "Epoch [423/500], Step [20/44], Loss: 0.3954\n",
      "Epoch [423/500], Step [40/44], Loss: 0.3028\n",
      "Epoch [424/500], Step [20/44], Loss: 0.3953\n",
      "Epoch [424/500], Step [40/44], Loss: 0.3028\n",
      "Epoch [425/500], Step [20/44], Loss: 0.3952\n",
      "Epoch [425/500], Step [40/44], Loss: 0.3027\n",
      "Epoch [426/500], Step [20/44], Loss: 0.3951\n",
      "Epoch [426/500], Step [40/44], Loss: 0.3027\n",
      "Epoch [427/500], Step [20/44], Loss: 0.3947\n",
      "Epoch [427/500], Step [40/44], Loss: 0.3027\n",
      "Epoch [428/500], Step [20/44], Loss: 0.3947\n",
      "Epoch [428/500], Step [40/44], Loss: 0.3027\n",
      "Epoch [429/500], Step [20/44], Loss: 0.3947\n",
      "Epoch [429/500], Step [40/44], Loss: 0.3027\n",
      "Epoch [430/500], Step [20/44], Loss: 0.3946\n",
      "Epoch [430/500], Step [40/44], Loss: 0.3027\n",
      "Epoch [431/500], Step [20/44], Loss: 0.3945\n",
      "Epoch [431/500], Step [40/44], Loss: 0.3026\n",
      "Epoch [432/500], Step [20/44], Loss: 0.3943\n",
      "Epoch [432/500], Step [40/44], Loss: 0.3026\n",
      "Epoch [433/500], Step [20/44], Loss: 0.3942\n",
      "Epoch [433/500], Step [40/44], Loss: 0.3025\n",
      "Epoch [434/500], Step [20/44], Loss: 0.3941\n",
      "Epoch [434/500], Step [40/44], Loss: 0.3026\n",
      "Epoch [435/500], Step [20/44], Loss: 0.3942\n",
      "Epoch [435/500], Step [40/44], Loss: 0.3025\n",
      "Epoch [436/500], Step [20/44], Loss: 0.3942\n",
      "Epoch [436/500], Step [40/44], Loss: 0.3025\n",
      "Epoch [437/500], Step [20/44], Loss: 0.3939\n",
      "Epoch [437/500], Step [40/44], Loss: 0.3025\n",
      "Epoch [438/500], Step [20/44], Loss: 0.3939\n",
      "Epoch [438/500], Step [40/44], Loss: 0.3025\n",
      "Epoch [439/500], Step [20/44], Loss: 0.3936\n",
      "Epoch [439/500], Step [40/44], Loss: 0.3024\n",
      "Epoch [440/500], Step [20/44], Loss: 0.3936\n",
      "Epoch [440/500], Step [40/44], Loss: 0.3024\n",
      "Epoch [441/500], Step [20/44], Loss: 0.3935\n",
      "Epoch [441/500], Step [40/44], Loss: 0.3024\n",
      "Epoch [442/500], Step [20/44], Loss: 0.3934\n",
      "Epoch [442/500], Step [40/44], Loss: 0.3024\n",
      "Epoch [443/500], Step [20/44], Loss: 0.3933\n",
      "Epoch [443/500], Step [40/44], Loss: 0.3024\n",
      "Epoch [444/500], Step [20/44], Loss: 0.3934\n",
      "Epoch [444/500], Step [40/44], Loss: 0.3023\n",
      "Epoch [445/500], Step [20/44], Loss: 0.3930\n",
      "Epoch [445/500], Step [40/44], Loss: 0.3023\n",
      "Epoch [446/500], Step [20/44], Loss: 0.3929\n",
      "Epoch [446/500], Step [40/44], Loss: 0.3023\n",
      "Epoch [447/500], Step [20/44], Loss: 0.3929\n",
      "Epoch [447/500], Step [40/44], Loss: 0.3023\n",
      "Epoch [448/500], Step [20/44], Loss: 0.3927\n",
      "Epoch [448/500], Step [40/44], Loss: 0.3022\n",
      "Epoch [449/500], Step [20/44], Loss: 0.3926\n",
      "Epoch [449/500], Step [40/44], Loss: 0.3022\n",
      "Epoch [450/500], Step [20/44], Loss: 0.3926\n",
      "Epoch [450/500], Step [40/44], Loss: 0.3022\n",
      "Epoch [451/500], Step [20/44], Loss: 0.3923\n",
      "Epoch [451/500], Step [40/44], Loss: 0.3022\n",
      "Epoch [452/500], Step [20/44], Loss: 0.3923\n",
      "Epoch [452/500], Step [40/44], Loss: 0.3022\n",
      "Epoch [453/500], Step [20/44], Loss: 0.3923\n",
      "Epoch [453/500], Step [40/44], Loss: 0.3021\n",
      "Epoch [454/500], Step [20/44], Loss: 0.3921\n",
      "Epoch [454/500], Step [40/44], Loss: 0.3021\n",
      "Epoch [455/500], Step [20/44], Loss: 0.3920\n",
      "Epoch [455/500], Step [40/44], Loss: 0.3021\n",
      "Epoch [456/500], Step [20/44], Loss: 0.3920\n",
      "Epoch [456/500], Step [40/44], Loss: 0.3020\n",
      "Epoch [457/500], Step [20/44], Loss: 0.3919\n",
      "Epoch [457/500], Step [40/44], Loss: 0.3020\n",
      "Epoch [458/500], Step [20/44], Loss: 0.3916\n",
      "Epoch [458/500], Step [40/44], Loss: 0.3020\n",
      "Epoch [459/500], Step [20/44], Loss: 0.3915\n",
      "Epoch [459/500], Step [40/44], Loss: 0.3020\n",
      "Epoch [460/500], Step [20/44], Loss: 0.3916\n",
      "Epoch [460/500], Step [40/44], Loss: 0.3020\n",
      "Epoch [461/500], Step [20/44], Loss: 0.3913\n",
      "Epoch [461/500], Step [40/44], Loss: 0.3019\n",
      "Epoch [462/500], Step [20/44], Loss: 0.3912\n",
      "Epoch [462/500], Step [40/44], Loss: 0.3019\n",
      "Epoch [463/500], Step [20/44], Loss: 0.3913\n",
      "Epoch [463/500], Step [40/44], Loss: 0.3019\n",
      "Epoch [464/500], Step [20/44], Loss: 0.3911\n",
      "Epoch [464/500], Step [40/44], Loss: 0.3019\n",
      "Epoch [465/500], Step [20/44], Loss: 0.3910\n",
      "Epoch [465/500], Step [40/44], Loss: 0.3018\n",
      "Epoch [466/500], Step [20/44], Loss: 0.3910\n",
      "Epoch [466/500], Step [40/44], Loss: 0.3018\n",
      "Epoch [467/500], Step [20/44], Loss: 0.3907\n",
      "Epoch [467/500], Step [40/44], Loss: 0.3018\n",
      "Epoch [468/500], Step [20/44], Loss: 0.3906\n",
      "Epoch [468/500], Step [40/44], Loss: 0.3018\n",
      "Epoch [469/500], Step [20/44], Loss: 0.3905\n",
      "Epoch [469/500], Step [40/44], Loss: 0.3018\n",
      "Epoch [470/500], Step [20/44], Loss: 0.3904\n",
      "Epoch [470/500], Step [40/44], Loss: 0.3017\n",
      "Epoch [471/500], Step [20/44], Loss: 0.3902\n",
      "Epoch [471/500], Step [40/44], Loss: 0.3017\n",
      "Epoch [472/500], Step [20/44], Loss: 0.3902\n",
      "Epoch [472/500], Step [40/44], Loss: 0.3017\n",
      "Epoch [473/500], Step [20/44], Loss: 0.3900\n",
      "Epoch [473/500], Step [40/44], Loss: 0.3017\n",
      "Epoch [474/500], Step [20/44], Loss: 0.3899\n",
      "Epoch [474/500], Step [40/44], Loss: 0.3016\n",
      "Epoch [475/500], Step [20/44], Loss: 0.3900\n",
      "Epoch [475/500], Step [40/44], Loss: 0.3016\n",
      "Epoch [476/500], Step [20/44], Loss: 0.3898\n",
      "Epoch [476/500], Step [40/44], Loss: 0.3016\n",
      "Epoch [477/500], Step [20/44], Loss: 0.3895\n",
      "Epoch [477/500], Step [40/44], Loss: 0.3016\n",
      "Epoch [478/500], Step [20/44], Loss: 0.3894\n",
      "Epoch [478/500], Step [40/44], Loss: 0.3016\n",
      "Epoch [479/500], Step [20/44], Loss: 0.3895\n",
      "Epoch [479/500], Step [40/44], Loss: 0.3015\n",
      "Epoch [480/500], Step [20/44], Loss: 0.3894\n",
      "Epoch [480/500], Step [40/44], Loss: 0.3015\n",
      "Epoch [481/500], Step [20/44], Loss: 0.3891\n",
      "Epoch [481/500], Step [40/44], Loss: 0.3015\n",
      "Epoch [482/500], Step [20/44], Loss: 0.3892\n",
      "Epoch [482/500], Step [40/44], Loss: 0.3015\n",
      "Epoch [483/500], Step [20/44], Loss: 0.3890\n",
      "Epoch [483/500], Step [40/44], Loss: 0.3014\n",
      "Epoch [484/500], Step [20/44], Loss: 0.3889\n",
      "Epoch [484/500], Step [40/44], Loss: 0.3014\n",
      "Epoch [485/500], Step [20/44], Loss: 0.3888\n",
      "Epoch [485/500], Step [40/44], Loss: 0.3014\n",
      "Epoch [486/500], Step [20/44], Loss: 0.3888\n",
      "Epoch [486/500], Step [40/44], Loss: 0.3014\n",
      "Epoch [487/500], Step [20/44], Loss: 0.3883\n",
      "Epoch [487/500], Step [40/44], Loss: 0.3014\n",
      "Epoch [488/500], Step [20/44], Loss: 0.3884\n",
      "Epoch [488/500], Step [40/44], Loss: 0.3014\n",
      "Epoch [489/500], Step [20/44], Loss: 0.3883\n",
      "Epoch [489/500], Step [40/44], Loss: 0.3014\n",
      "Epoch [490/500], Step [20/44], Loss: 0.3881\n",
      "Epoch [490/500], Step [40/44], Loss: 0.3013\n",
      "Epoch [491/500], Step [20/44], Loss: 0.3882\n",
      "Epoch [491/500], Step [40/44], Loss: 0.3013\n",
      "Epoch [492/500], Step [20/44], Loss: 0.3879\n",
      "Epoch [492/500], Step [40/44], Loss: 0.3013\n",
      "Epoch [493/500], Step [20/44], Loss: 0.3878\n",
      "Epoch [493/500], Step [40/44], Loss: 0.3013\n",
      "Epoch [494/500], Step [20/44], Loss: 0.3878\n",
      "Epoch [494/500], Step [40/44], Loss: 0.3013\n",
      "Epoch [495/500], Step [20/44], Loss: 0.3876\n",
      "Epoch [495/500], Step [40/44], Loss: 0.3012\n",
      "Epoch [496/500], Step [20/44], Loss: 0.3875\n",
      "Epoch [496/500], Step [40/44], Loss: 0.3012\n",
      "Epoch [497/500], Step [20/44], Loss: 0.3874\n",
      "Epoch [497/500], Step [40/44], Loss: 0.3012\n",
      "Epoch [498/500], Step [20/44], Loss: 0.3872\n",
      "Epoch [498/500], Step [40/44], Loss: 0.3012\n",
      "Epoch [499/500], Step [20/44], Loss: 0.3873\n",
      "Epoch [499/500], Step [40/44], Loss: 0.3011\n",
      "Epoch [500/500], Step [20/44], Loss: 0.3871\n",
      "Epoch [500/500], Step [40/44], Loss: 0.3011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T01:05:20.103203Z",
     "start_time": "2024-05-10T01:05:19.932650Z"
    }
   },
   "cell_type": "code",
   "source": "check_output(output[4], images[4], epoch=0)",
   "id": "fc5f1e58d3dff28d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T01:05:20.414592Z",
     "start_time": "2024-05-10T01:05:20.385038Z"
    }
   },
   "cell_type": "code",
   "source": "output[4]",
   "id": "17f90926de44140",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8.8006e-02, 2.0144e-01, 2.9009e-01,  ..., 8.9391e-02,\n",
       "          7.4145e-02, 3.3514e-02],\n",
       "         [1.3633e-01, 2.3901e-01, 2.7001e-01,  ..., 7.4983e-02,\n",
       "          7.2419e-02, 3.8240e-02],\n",
       "         [1.6877e-01, 2.6712e-01, 2.8253e-01,  ..., 6.7611e-02,\n",
       "          9.0792e-02, 3.1234e-02],\n",
       "         ...,\n",
       "         [3.1964e-02, 5.0868e-02, 5.6639e-02,  ..., 3.3566e-04,\n",
       "          1.1422e-03, 3.9571e-04],\n",
       "         [2.1923e-02, 2.8927e-02, 4.5737e-02,  ..., 2.8116e-04,\n",
       "          5.6690e-03, 5.9631e-03],\n",
       "         [5.7261e-03, 1.4686e-02, 1.9347e-02,  ..., 2.8720e-04,\n",
       "          4.6226e-03, 5.4296e-03]],\n",
       "\n",
       "        [[9.8284e-02, 1.8116e-01, 2.5352e-01,  ..., 1.0125e-01,\n",
       "          7.2335e-02, 3.6770e-02],\n",
       "         [1.5201e-01, 2.3681e-01, 3.1123e-01,  ..., 9.2363e-02,\n",
       "          7.7043e-02, 4.3951e-02],\n",
       "         [1.8236e-01, 3.0570e-01, 2.8118e-01,  ..., 5.4563e-02,\n",
       "          7.2248e-02, 3.4171e-02],\n",
       "         ...,\n",
       "         [2.5424e-02, 4.2590e-02, 6.6943e-02,  ..., 3.1306e-04,\n",
       "          6.4491e-04, 8.9639e-05],\n",
       "         [1.8536e-02, 3.7929e-02, 4.7517e-02,  ..., 1.4510e-04,\n",
       "          4.0019e-03, 4.9133e-03],\n",
       "         [6.1722e-03, 2.5516e-02, 1.3822e-02,  ..., 7.5239e-05,\n",
       "          4.4656e-03, 2.1932e-03]],\n",
       "\n",
       "        [[8.8006e-02, 2.0144e-01, 2.9009e-01,  ..., 8.9391e-02,\n",
       "          7.4145e-02, 3.3514e-02],\n",
       "         [1.3633e-01, 2.3901e-01, 2.7001e-01,  ..., 7.4983e-02,\n",
       "          7.2419e-02, 3.8240e-02],\n",
       "         [1.6877e-01, 2.6712e-01, 2.8253e-01,  ..., 6.7611e-02,\n",
       "          9.0792e-02, 3.1234e-02],\n",
       "         ...,\n",
       "         [3.1964e-02, 5.0868e-02, 5.6639e-02,  ..., 3.3566e-04,\n",
       "          1.1422e-03, 3.9571e-04],\n",
       "         [2.1923e-02, 2.8927e-02, 4.5737e-02,  ..., 2.8116e-04,\n",
       "          5.6690e-03, 5.9631e-03],\n",
       "         [5.7261e-03, 1.4686e-02, 1.9347e-02,  ..., 2.8720e-04,\n",
       "          4.6226e-03, 5.4296e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.8284e-02, 1.8116e-01, 2.5352e-01,  ..., 1.0125e-01,\n",
       "          7.2335e-02, 3.6770e-02],\n",
       "         [1.5201e-01, 2.3681e-01, 3.1123e-01,  ..., 9.2363e-02,\n",
       "          7.7043e-02, 4.3951e-02],\n",
       "         [1.8236e-01, 3.0570e-01, 2.8118e-01,  ..., 5.4563e-02,\n",
       "          7.2248e-02, 3.4171e-02],\n",
       "         ...,\n",
       "         [2.5424e-02, 4.2590e-02, 6.6943e-02,  ..., 3.1306e-04,\n",
       "          6.4491e-04, 8.9639e-05],\n",
       "         [1.8536e-02, 3.7929e-02, 4.7517e-02,  ..., 1.4510e-04,\n",
       "          4.0019e-03, 4.9133e-03],\n",
       "         [6.1722e-03, 2.5516e-02, 1.3822e-02,  ..., 7.5239e-05,\n",
       "          4.4656e-03, 2.1932e-03]],\n",
       "\n",
       "        [[8.8006e-02, 2.0144e-01, 2.9009e-01,  ..., 8.9391e-02,\n",
       "          7.4145e-02, 3.3514e-02],\n",
       "         [1.3633e-01, 2.3901e-01, 2.7001e-01,  ..., 7.4983e-02,\n",
       "          7.2419e-02, 3.8240e-02],\n",
       "         [1.6877e-01, 2.6712e-01, 2.8253e-01,  ..., 6.7611e-02,\n",
       "          9.0792e-02, 3.1234e-02],\n",
       "         ...,\n",
       "         [3.1964e-02, 5.0868e-02, 5.6639e-02,  ..., 3.3566e-04,\n",
       "          1.1422e-03, 3.9571e-04],\n",
       "         [2.1923e-02, 2.8927e-02, 4.5737e-02,  ..., 2.8116e-04,\n",
       "          5.6690e-03, 5.9631e-03],\n",
       "         [5.7261e-03, 1.4686e-02, 1.9347e-02,  ..., 2.8720e-04,\n",
       "          4.6226e-03, 5.4296e-03]],\n",
       "\n",
       "        [[9.8284e-02, 1.8116e-01, 2.5352e-01,  ..., 1.0125e-01,\n",
       "          7.2335e-02, 3.6770e-02],\n",
       "         [1.5201e-01, 2.3681e-01, 3.1123e-01,  ..., 9.2363e-02,\n",
       "          7.7043e-02, 4.3951e-02],\n",
       "         [1.8236e-01, 3.0570e-01, 2.8118e-01,  ..., 5.4563e-02,\n",
       "          7.2248e-02, 3.4171e-02],\n",
       "         ...,\n",
       "         [2.5424e-02, 4.2590e-02, 6.6943e-02,  ..., 3.1306e-04,\n",
       "          6.4491e-04, 8.9639e-05],\n",
       "         [1.8536e-02, 3.7929e-02, 4.7517e-02,  ..., 1.4510e-04,\n",
       "          4.0019e-03, 4.9133e-03],\n",
       "         [6.1722e-03, 2.5516e-02, 1.3822e-02,  ..., 7.5239e-05,\n",
       "          4.4656e-03, 2.1932e-03]]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:05:52.014910Z",
     "start_time": "2024-05-10T00:05:51.959799Z"
    }
   },
   "cell_type": "code",
   "source": "objects[0][0]",
   "id": "a0a2cfa72d326eea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 144
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
